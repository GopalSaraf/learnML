<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 14.0.0"/>
    <title>learnML.regression API documentation</title>
            <link rel="icon" href="https://github-production-user-asset-6210df.s3.amazonaws.com/83419951/261991976-577f071d-b3d7-4a3c-8000-41e1c0275669.png"/>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../learnML.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;learnML</a>

<a href="https://learnml.gopalsaraf.com/">            <img src="https://github.com/GopalSaraf/learnML/assets/83419951/d41ec63f-8cac-436c-8e92-8c86e3ede9c0" class="logo" alt="project logo"/>
</a>
            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#UnivariateLinearRegression">UnivariateLinearRegression</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#UnivariateLinearRegression.__init__">UnivariateLinearRegression</a>
                        </li>
                        <li>
                                <a class="function" href="#UnivariateLinearRegression.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#UnivariateLinearRegression.predict">predict</a>
                        </li>
                        <li>
                                <a class="function" href="#UnivariateLinearRegression.score">score</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#LinearRegression">LinearRegression</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#LinearRegression.__init__">LinearRegression</a>
                        </li>
                        <li>
                                <a class="function" href="#LinearRegression.fit">fit</a>
                        </li>
                        <li>
                                <a class="function" href="#LinearRegression.predict">predict</a>
                        </li>
                        <li>
                                <a class="function" href="#LinearRegression.score">score</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#PolynomialRegression">PolynomialRegression</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#PolynomialRegression.__init__">PolynomialRegression</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../learnML.html">learnML</a><wbr>.regression    </h1>

                
                        <input id="mod-regression-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-regression-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">1</span></a><span class="kn">from</span> <span class="nn">.univariate_regression</span> <span class="kn">import</span> <span class="n">UnivariateLinearRegression</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">2</span></a><span class="kn">from</span> <span class="nn">.linear_regression</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">3</span></a><span class="kn">from</span> <span class="nn">.polynomial_regression</span> <span class="kn">import</span> <span class="n">PolynomialRegression</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos">5</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">6</span></a>    <span class="s2">&quot;UnivariateLinearRegression&quot;</span><span class="p">,</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">7</span></a>    <span class="s2">&quot;LinearRegression&quot;</span><span class="p">,</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">8</span></a>    <span class="s2">&quot;PolynomialRegression&quot;</span><span class="p">,</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">9</span></a><span class="p">]</span>
</span></pre></div>


            </section>
                <section id="UnivariateLinearRegression">
                            <input id="UnivariateLinearRegression-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">UnivariateLinearRegression</span><wbr>(<span class="base">learnML.interfaces.iregression.IRegression</span>):

                <label class="view-source-button" for="UnivariateLinearRegression-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#UnivariateLinearRegression"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="UnivariateLinearRegression-9"><a href="#UnivariateLinearRegression-9"><span class="linenos">  9</span></a><span class="k">class</span> <span class="nc">UnivariateLinearRegression</span><span class="p">(</span><span class="n">IRegression</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-10"><a href="#UnivariateLinearRegression-10"><span class="linenos"> 10</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-11"><a href="#UnivariateLinearRegression-11"><span class="linenos"> 11</span></a><span class="sd">    # Univariate Linear Regression model.</span>
</span><span id="UnivariateLinearRegression-12"><a href="#UnivariateLinearRegression-12"><span class="linenos"> 12</span></a>
</span><span id="UnivariateLinearRegression-13"><a href="#UnivariateLinearRegression-13"><span class="linenos"> 13</span></a><span class="sd">    Linear regression is a fundamental supervised machine learning algorithm that models the relationship between a dependent variable and a single independent variable. It approximates this relationship using a linear equation. Univariate Linear Regression is particularly useful when there is a clear linear correlation between the input and output variables.</span>
</span><span id="UnivariateLinearRegression-14"><a href="#UnivariateLinearRegression-14"><span class="linenos"> 14</span></a>
</span><span id="UnivariateLinearRegression-15"><a href="#UnivariateLinearRegression-15"><span class="linenos"> 15</span></a><span class="sd">    ---</span>
</span><span id="UnivariateLinearRegression-16"><a href="#UnivariateLinearRegression-16"><span class="linenos"> 16</span></a>
</span><span id="UnivariateLinearRegression-17"><a href="#UnivariateLinearRegression-17"><span class="linenos"> 17</span></a><span class="sd">    ## Mathematical Approach</span>
</span><span id="UnivariateLinearRegression-18"><a href="#UnivariateLinearRegression-18"><span class="linenos"> 18</span></a>
</span><span id="UnivariateLinearRegression-19"><a href="#UnivariateLinearRegression-19"><span class="linenos"> 19</span></a><span class="sd">    Univariate Linear Regression aims to find the best-fitting line that predicts the output variable based on the input feature. The linear equation is represented as:</span>
</span><span id="UnivariateLinearRegression-20"><a href="#UnivariateLinearRegression-20"><span class="linenos"> 20</span></a>
</span><span id="UnivariateLinearRegression-21"><a href="#UnivariateLinearRegression-21"><span class="linenos"> 21</span></a><span class="sd">    ```</span>
</span><span id="UnivariateLinearRegression-22"><a href="#UnivariateLinearRegression-22"><span class="linenos"> 22</span></a><span class="sd">    y = mx + b</span>
</span><span id="UnivariateLinearRegression-23"><a href="#UnivariateLinearRegression-23"><span class="linenos"> 23</span></a><span class="sd">    ```</span>
</span><span id="UnivariateLinearRegression-24"><a href="#UnivariateLinearRegression-24"><span class="linenos"> 24</span></a>
</span><span id="UnivariateLinearRegression-25"><a href="#UnivariateLinearRegression-25"><span class="linenos"> 25</span></a><span class="sd">    Where:</span>
</span><span id="UnivariateLinearRegression-26"><a href="#UnivariateLinearRegression-26"><span class="linenos"> 26</span></a>
</span><span id="UnivariateLinearRegression-27"><a href="#UnivariateLinearRegression-27"><span class="linenos"> 27</span></a><span class="sd">    - `y` is the predicted output (target variable).</span>
</span><span id="UnivariateLinearRegression-28"><a href="#UnivariateLinearRegression-28"><span class="linenos"> 28</span></a><span class="sd">    - `x` is the input feature (independent variable).</span>
</span><span id="UnivariateLinearRegression-29"><a href="#UnivariateLinearRegression-29"><span class="linenos"> 29</span></a><span class="sd">    - `m` is the slope of the line (weight).</span>
</span><span id="UnivariateLinearRegression-30"><a href="#UnivariateLinearRegression-30"><span class="linenos"> 30</span></a><span class="sd">    - `b` is the y-intercept.</span>
</span><span id="UnivariateLinearRegression-31"><a href="#UnivariateLinearRegression-31"><span class="linenos"> 31</span></a>
</span><span id="UnivariateLinearRegression-32"><a href="#UnivariateLinearRegression-32"><span class="linenos"> 32</span></a><span class="sd">    The goal is to determine the optimal values of `m` and `b` that minimize the difference between predicted values and actual target values.</span>
</span><span id="UnivariateLinearRegression-33"><a href="#UnivariateLinearRegression-33"><span class="linenos"> 33</span></a>
</span><span id="UnivariateLinearRegression-34"><a href="#UnivariateLinearRegression-34"><span class="linenos"> 34</span></a><span class="sd">    ---</span>
</span><span id="UnivariateLinearRegression-35"><a href="#UnivariateLinearRegression-35"><span class="linenos"> 35</span></a>
</span><span id="UnivariateLinearRegression-36"><a href="#UnivariateLinearRegression-36"><span class="linenos"> 36</span></a><span class="sd">    ## Usage</span>
</span><span id="UnivariateLinearRegression-37"><a href="#UnivariateLinearRegression-37"><span class="linenos"> 37</span></a>
</span><span id="UnivariateLinearRegression-38"><a href="#UnivariateLinearRegression-38"><span class="linenos"> 38</span></a><span class="sd">    To utilize the Univariate Linear Regression model, follow these steps:</span>
</span><span id="UnivariateLinearRegression-39"><a href="#UnivariateLinearRegression-39"><span class="linenos"> 39</span></a>
</span><span id="UnivariateLinearRegression-40"><a href="#UnivariateLinearRegression-40"><span class="linenos"> 40</span></a><span class="sd">    1. Import the `UnivariateLinearRegression` class from the appropriate module.</span>
</span><span id="UnivariateLinearRegression-41"><a href="#UnivariateLinearRegression-41"><span class="linenos"> 41</span></a><span class="sd">    2. Create an instance of the `UnivariateLinearRegression` class, specifying hyperparameters.</span>
</span><span id="UnivariateLinearRegression-42"><a href="#UnivariateLinearRegression-42"><span class="linenos"> 42</span></a><span class="sd">    3. Fit the model to your training data using the `fit` method.</span>
</span><span id="UnivariateLinearRegression-43"><a href="#UnivariateLinearRegression-43"><span class="linenos"> 43</span></a><span class="sd">    4. Make predictions on new data using the `predict` method.</span>
</span><span id="UnivariateLinearRegression-44"><a href="#UnivariateLinearRegression-44"><span class="linenos"> 44</span></a><span class="sd">    5. Evaluate the model&#39;s performance using the `score` method.</span>
</span><span id="UnivariateLinearRegression-45"><a href="#UnivariateLinearRegression-45"><span class="linenos"> 45</span></a>
</span><span id="UnivariateLinearRegression-46"><a href="#UnivariateLinearRegression-46"><span class="linenos"> 46</span></a><span class="sd">    ```python</span>
</span><span id="UnivariateLinearRegression-47"><a href="#UnivariateLinearRegression-47"><span class="linenos"> 47</span></a><span class="sd">    from learnML.regression import UnivariateLinearRegression</span>
</span><span id="UnivariateLinearRegression-48"><a href="#UnivariateLinearRegression-48"><span class="linenos"> 48</span></a>
</span><span id="UnivariateLinearRegression-49"><a href="#UnivariateLinearRegression-49"><span class="linenos"> 49</span></a><span class="sd">    # Create an instance of UnivariateLinearRegression</span>
</span><span id="UnivariateLinearRegression-50"><a href="#UnivariateLinearRegression-50"><span class="linenos"> 50</span></a><span class="sd">    model = UnivariateLinearRegression(learning_rate=0.01, n_iterations=1000)</span>
</span><span id="UnivariateLinearRegression-51"><a href="#UnivariateLinearRegression-51"><span class="linenos"> 51</span></a>
</span><span id="UnivariateLinearRegression-52"><a href="#UnivariateLinearRegression-52"><span class="linenos"> 52</span></a><span class="sd">    # Fit the model to training data</span>
</span><span id="UnivariateLinearRegression-53"><a href="#UnivariateLinearRegression-53"><span class="linenos"> 53</span></a><span class="sd">    model.fit(X_train, Y_train)</span>
</span><span id="UnivariateLinearRegression-54"><a href="#UnivariateLinearRegression-54"><span class="linenos"> 54</span></a>
</span><span id="UnivariateLinearRegression-55"><a href="#UnivariateLinearRegression-55"><span class="linenos"> 55</span></a><span class="sd">    # Make predictions on new data</span>
</span><span id="UnivariateLinearRegression-56"><a href="#UnivariateLinearRegression-56"><span class="linenos"> 56</span></a><span class="sd">    predictions = model.predict(X_test)</span>
</span><span id="UnivariateLinearRegression-57"><a href="#UnivariateLinearRegression-57"><span class="linenos"> 57</span></a>
</span><span id="UnivariateLinearRegression-58"><a href="#UnivariateLinearRegression-58"><span class="linenos"> 58</span></a><span class="sd">    # Calculate the model&#39;s score</span>
</span><span id="UnivariateLinearRegression-59"><a href="#UnivariateLinearRegression-59"><span class="linenos"> 59</span></a><span class="sd">    model_score = model.score(X_test, Y_test)</span>
</span><span id="UnivariateLinearRegression-60"><a href="#UnivariateLinearRegression-60"><span class="linenos"> 60</span></a><span class="sd">    ```</span>
</span><span id="UnivariateLinearRegression-61"><a href="#UnivariateLinearRegression-61"><span class="linenos"> 61</span></a>
</span><span id="UnivariateLinearRegression-62"><a href="#UnivariateLinearRegression-62"><span class="linenos"> 62</span></a><span class="sd">    ---</span>
</span><span id="UnivariateLinearRegression-63"><a href="#UnivariateLinearRegression-63"><span class="linenos"> 63</span></a>
</span><span id="UnivariateLinearRegression-64"><a href="#UnivariateLinearRegression-64"><span class="linenos"> 64</span></a><span class="sd">    ## Advantages</span>
</span><span id="UnivariateLinearRegression-65"><a href="#UnivariateLinearRegression-65"><span class="linenos"> 65</span></a>
</span><span id="UnivariateLinearRegression-66"><a href="#UnivariateLinearRegression-66"><span class="linenos"> 66</span></a><span class="sd">    - Easy to implement</span>
</span><span id="UnivariateLinearRegression-67"><a href="#UnivariateLinearRegression-67"><span class="linenos"> 67</span></a><span class="sd">    - Easy to interpret the output</span>
</span><span id="UnivariateLinearRegression-68"><a href="#UnivariateLinearRegression-68"><span class="linenos"> 68</span></a><span class="sd">    - Computationally cheap</span>
</span><span id="UnivariateLinearRegression-69"><a href="#UnivariateLinearRegression-69"><span class="linenos"> 69</span></a>
</span><span id="UnivariateLinearRegression-70"><a href="#UnivariateLinearRegression-70"><span class="linenos"> 70</span></a><span class="sd">    ## Disadvantages</span>
</span><span id="UnivariateLinearRegression-71"><a href="#UnivariateLinearRegression-71"><span class="linenos"> 71</span></a>
</span><span id="UnivariateLinearRegression-72"><a href="#UnivariateLinearRegression-72"><span class="linenos"> 72</span></a><span class="sd">    - Poor performance on non-linear data</span>
</span><span id="UnivariateLinearRegression-73"><a href="#UnivariateLinearRegression-73"><span class="linenos"> 73</span></a><span class="sd">    - Sensitive to outliers</span>
</span><span id="UnivariateLinearRegression-74"><a href="#UnivariateLinearRegression-74"><span class="linenos"> 74</span></a><span class="sd">    - Sensitive to overfitting</span>
</span><span id="UnivariateLinearRegression-75"><a href="#UnivariateLinearRegression-75"><span class="linenos"> 75</span></a>
</span><span id="UnivariateLinearRegression-76"><a href="#UnivariateLinearRegression-76"><span class="linenos"> 76</span></a><span class="sd">    ---</span>
</span><span id="UnivariateLinearRegression-77"><a href="#UnivariateLinearRegression-77"><span class="linenos"> 77</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-78"><a href="#UnivariateLinearRegression-78"><span class="linenos"> 78</span></a>
</span><span id="UnivariateLinearRegression-79"><a href="#UnivariateLinearRegression-79"><span class="linenos"> 79</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-80"><a href="#UnivariateLinearRegression-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-81"><a href="#UnivariateLinearRegression-81"><span class="linenos"> 81</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-82"><a href="#UnivariateLinearRegression-82"><span class="linenos"> 82</span></a>        <span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-83"><a href="#UnivariateLinearRegression-83"><span class="linenos"> 83</span></a>        <span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-84"><a href="#UnivariateLinearRegression-84"><span class="linenos"> 84</span></a>        <span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-85"><a href="#UnivariateLinearRegression-85"><span class="linenos"> 85</span></a>        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-86"><a href="#UnivariateLinearRegression-86"><span class="linenos"> 86</span></a>        <span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-87"><a href="#UnivariateLinearRegression-87"><span class="linenos"> 87</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-88"><a href="#UnivariateLinearRegression-88"><span class="linenos"> 88</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-89"><a href="#UnivariateLinearRegression-89"><span class="linenos"> 89</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-90"><a href="#UnivariateLinearRegression-90"><span class="linenos"> 90</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-91"><a href="#UnivariateLinearRegression-91"><span class="linenos"> 91</span></a>
</span><span id="UnivariateLinearRegression-92"><a href="#UnivariateLinearRegression-92"><span class="linenos"> 92</span></a><span class="sd">        `learning_rate` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression-93"><a href="#UnivariateLinearRegression-93"><span class="linenos"> 93</span></a><span class="sd">        - The learning rate, by default 0.001</span>
</span><span id="UnivariateLinearRegression-94"><a href="#UnivariateLinearRegression-94"><span class="linenos"> 94</span></a><span class="sd">        - The learning rate determines how much the weights are updated at each iteration</span>
</span><span id="UnivariateLinearRegression-95"><a href="#UnivariateLinearRegression-95"><span class="linenos"> 95</span></a><span class="sd">        - A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</span>
</span><span id="UnivariateLinearRegression-96"><a href="#UnivariateLinearRegression-96"><span class="linenos"> 96</span></a>
</span><span id="UnivariateLinearRegression-97"><a href="#UnivariateLinearRegression-97"><span class="linenos"> 97</span></a><span class="sd">        `n_iterations` : int, optional</span>
</span><span id="UnivariateLinearRegression-98"><a href="#UnivariateLinearRegression-98"><span class="linenos"> 98</span></a><span class="sd">        - The number of iterations, by default 1000</span>
</span><span id="UnivariateLinearRegression-99"><a href="#UnivariateLinearRegression-99"><span class="linenos"> 99</span></a><span class="sd">        - The number of iterations determines how many times the weights are updated</span>
</span><span id="UnivariateLinearRegression-100"><a href="#UnivariateLinearRegression-100"><span class="linenos">100</span></a><span class="sd">        - A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</span>
</span><span id="UnivariateLinearRegression-101"><a href="#UnivariateLinearRegression-101"><span class="linenos">101</span></a>
</span><span id="UnivariateLinearRegression-102"><a href="#UnivariateLinearRegression-102"><span class="linenos">102</span></a><span class="sd">        `x_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="UnivariateLinearRegression-103"><a href="#UnivariateLinearRegression-103"><span class="linenos">103</span></a><span class="sd">        - The feature engineering for the input data, by default None</span>
</span><span id="UnivariateLinearRegression-104"><a href="#UnivariateLinearRegression-104"><span class="linenos">104</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="UnivariateLinearRegression-105"><a href="#UnivariateLinearRegression-105"><span class="linenos">105</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all input data</span>
</span><span id="UnivariateLinearRegression-106"><a href="#UnivariateLinearRegression-106"><span class="linenos">106</span></a>
</span><span id="UnivariateLinearRegression-107"><a href="#UnivariateLinearRegression-107"><span class="linenos">107</span></a><span class="sd">        `y_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="UnivariateLinearRegression-108"><a href="#UnivariateLinearRegression-108"><span class="linenos">108</span></a><span class="sd">        - The feature engineering for the output data, by default None</span>
</span><span id="UnivariateLinearRegression-109"><a href="#UnivariateLinearRegression-109"><span class="linenos">109</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="UnivariateLinearRegression-110"><a href="#UnivariateLinearRegression-110"><span class="linenos">110</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all output data</span>
</span><span id="UnivariateLinearRegression-111"><a href="#UnivariateLinearRegression-111"><span class="linenos">111</span></a>
</span><span id="UnivariateLinearRegression-112"><a href="#UnivariateLinearRegression-112"><span class="linenos">112</span></a><span class="sd">        `debug` : bool, optional</span>
</span><span id="UnivariateLinearRegression-113"><a href="#UnivariateLinearRegression-113"><span class="linenos">113</span></a><span class="sd">        - Whether to print debug messages, by default True</span>
</span><span id="UnivariateLinearRegression-114"><a href="#UnivariateLinearRegression-114"><span class="linenos">114</span></a><span class="sd">        - Debug messages include the cost at each iteration</span>
</span><span id="UnivariateLinearRegression-115"><a href="#UnivariateLinearRegression-115"><span class="linenos">115</span></a>
</span><span id="UnivariateLinearRegression-116"><a href="#UnivariateLinearRegression-116"><span class="linenos">116</span></a><span class="sd">        `copy_x` : bool, optional</span>
</span><span id="UnivariateLinearRegression-117"><a href="#UnivariateLinearRegression-117"><span class="linenos">117</span></a><span class="sd">        - Whether to copy the input array, by default True</span>
</span><span id="UnivariateLinearRegression-118"><a href="#UnivariateLinearRegression-118"><span class="linenos">118</span></a><span class="sd">        - If False, the input array will be overwritten</span>
</span><span id="UnivariateLinearRegression-119"><a href="#UnivariateLinearRegression-119"><span class="linenos">119</span></a>
</span><span id="UnivariateLinearRegression-120"><a href="#UnivariateLinearRegression-120"><span class="linenos">120</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-121"><a href="#UnivariateLinearRegression-121"><span class="linenos">121</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-122"><a href="#UnivariateLinearRegression-122"><span class="linenos">122</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-123"><a href="#UnivariateLinearRegression-123"><span class="linenos">123</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-124"><a href="#UnivariateLinearRegression-124"><span class="linenos">124</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-125"><a href="#UnivariateLinearRegression-125"><span class="linenos">125</span></a>            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-126"><a href="#UnivariateLinearRegression-126"><span class="linenos">126</span></a>            <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-127"><a href="#UnivariateLinearRegression-127"><span class="linenos">127</span></a>        <span class="p">)</span>
</span><span id="UnivariateLinearRegression-128"><a href="#UnivariateLinearRegression-128"><span class="linenos">128</span></a>
</span><span id="UnivariateLinearRegression-129"><a href="#UnivariateLinearRegression-129"><span class="linenos">129</span></a>        <span class="k">if</span> <span class="n">x_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-130"><a href="#UnivariateLinearRegression-130"><span class="linenos">130</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="UnivariateLinearRegression-131"><a href="#UnivariateLinearRegression-131"><span class="linenos">131</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-132"><a href="#UnivariateLinearRegression-132"><span class="linenos">132</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_scalar</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-133"><a href="#UnivariateLinearRegression-133"><span class="linenos">133</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span> <span class="o">=</span> <span class="n">x_scalar</span>
</span><span id="UnivariateLinearRegression-134"><a href="#UnivariateLinearRegression-134"><span class="linenos">134</span></a>
</span><span id="UnivariateLinearRegression-135"><a href="#UnivariateLinearRegression-135"><span class="linenos">135</span></a>        <span class="k">if</span> <span class="n">y_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-136"><a href="#UnivariateLinearRegression-136"><span class="linenos">136</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="UnivariateLinearRegression-137"><a href="#UnivariateLinearRegression-137"><span class="linenos">137</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-138"><a href="#UnivariateLinearRegression-138"><span class="linenos">138</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_scalar</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-139"><a href="#UnivariateLinearRegression-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span> <span class="o">=</span> <span class="n">y_scalar</span>
</span><span id="UnivariateLinearRegression-140"><a href="#UnivariateLinearRegression-140"><span class="linenos">140</span></a>
</span><span id="UnivariateLinearRegression-141"><a href="#UnivariateLinearRegression-141"><span class="linenos">141</span></a>    <span class="k">def</span> <span class="nf">_y_hat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-142"><a href="#UnivariateLinearRegression-142"><span class="linenos">142</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-143"><a href="#UnivariateLinearRegression-143"><span class="linenos">143</span></a><span class="sd">        ### Return the predicted value given x, w, and b.</span>
</span><span id="UnivariateLinearRegression-144"><a href="#UnivariateLinearRegression-144"><span class="linenos">144</span></a>
</span><span id="UnivariateLinearRegression-145"><a href="#UnivariateLinearRegression-145"><span class="linenos">145</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-146"><a href="#UnivariateLinearRegression-146"><span class="linenos">146</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-147"><a href="#UnivariateLinearRegression-147"><span class="linenos">147</span></a>
</span><span id="UnivariateLinearRegression-148"><a href="#UnivariateLinearRegression-148"><span class="linenos">148</span></a><span class="sd">        `x` : np.float64</span>
</span><span id="UnivariateLinearRegression-149"><a href="#UnivariateLinearRegression-149"><span class="linenos">149</span></a><span class="sd">        - The input value</span>
</span><span id="UnivariateLinearRegression-150"><a href="#UnivariateLinearRegression-150"><span class="linenos">150</span></a>
</span><span id="UnivariateLinearRegression-151"><a href="#UnivariateLinearRegression-151"><span class="linenos">151</span></a><span class="sd">        `w` : np.float64</span>
</span><span id="UnivariateLinearRegression-152"><a href="#UnivariateLinearRegression-152"><span class="linenos">152</span></a><span class="sd">        - The weight</span>
</span><span id="UnivariateLinearRegression-153"><a href="#UnivariateLinearRegression-153"><span class="linenos">153</span></a>
</span><span id="UnivariateLinearRegression-154"><a href="#UnivariateLinearRegression-154"><span class="linenos">154</span></a><span class="sd">        `b` : np.float64</span>
</span><span id="UnivariateLinearRegression-155"><a href="#UnivariateLinearRegression-155"><span class="linenos">155</span></a><span class="sd">        - The intercept</span>
</span><span id="UnivariateLinearRegression-156"><a href="#UnivariateLinearRegression-156"><span class="linenos">156</span></a>
</span><span id="UnivariateLinearRegression-157"><a href="#UnivariateLinearRegression-157"><span class="linenos">157</span></a>
</span><span id="UnivariateLinearRegression-158"><a href="#UnivariateLinearRegression-158"><span class="linenos">158</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-159"><a href="#UnivariateLinearRegression-159"><span class="linenos">159</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-160"><a href="#UnivariateLinearRegression-160"><span class="linenos">160</span></a>
</span><span id="UnivariateLinearRegression-161"><a href="#UnivariateLinearRegression-161"><span class="linenos">161</span></a><span class="sd">        `np.float64`</span>
</span><span id="UnivariateLinearRegression-162"><a href="#UnivariateLinearRegression-162"><span class="linenos">162</span></a><span class="sd">        - The predicted value</span>
</span><span id="UnivariateLinearRegression-163"><a href="#UnivariateLinearRegression-163"><span class="linenos">163</span></a>
</span><span id="UnivariateLinearRegression-164"><a href="#UnivariateLinearRegression-164"><span class="linenos">164</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-165"><a href="#UnivariateLinearRegression-165"><span class="linenos">165</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-166"><a href="#UnivariateLinearRegression-166"><span class="linenos">166</span></a>        <span class="k">return</span> <span class="n">w</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span>
</span><span id="UnivariateLinearRegression-167"><a href="#UnivariateLinearRegression-167"><span class="linenos">167</span></a>
</span><span id="UnivariateLinearRegression-168"><a href="#UnivariateLinearRegression-168"><span class="linenos">168</span></a>    <span class="k">def</span> <span class="nf">_cost</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-169"><a href="#UnivariateLinearRegression-169"><span class="linenos">169</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span>
</span><span id="UnivariateLinearRegression-170"><a href="#UnivariateLinearRegression-170"><span class="linenos">170</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-171"><a href="#UnivariateLinearRegression-171"><span class="linenos">171</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-172"><a href="#UnivariateLinearRegression-172"><span class="linenos">172</span></a><span class="sd">        ### Return the cost function given X, Y, w, and b.</span>
</span><span id="UnivariateLinearRegression-173"><a href="#UnivariateLinearRegression-173"><span class="linenos">173</span></a><span class="sd">        (Mean Squared Error)</span>
</span><span id="UnivariateLinearRegression-174"><a href="#UnivariateLinearRegression-174"><span class="linenos">174</span></a>
</span><span id="UnivariateLinearRegression-175"><a href="#UnivariateLinearRegression-175"><span class="linenos">175</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-176"><a href="#UnivariateLinearRegression-176"><span class="linenos">176</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-177"><a href="#UnivariateLinearRegression-177"><span class="linenos">177</span></a>
</span><span id="UnivariateLinearRegression-178"><a href="#UnivariateLinearRegression-178"><span class="linenos">178</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-179"><a href="#UnivariateLinearRegression-179"><span class="linenos">179</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-180"><a href="#UnivariateLinearRegression-180"><span class="linenos">180</span></a>
</span><span id="UnivariateLinearRegression-181"><a href="#UnivariateLinearRegression-181"><span class="linenos">181</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-182"><a href="#UnivariateLinearRegression-182"><span class="linenos">182</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-183"><a href="#UnivariateLinearRegression-183"><span class="linenos">183</span></a>
</span><span id="UnivariateLinearRegression-184"><a href="#UnivariateLinearRegression-184"><span class="linenos">184</span></a><span class="sd">        `w` : np.float64</span>
</span><span id="UnivariateLinearRegression-185"><a href="#UnivariateLinearRegression-185"><span class="linenos">185</span></a><span class="sd">        - The weight</span>
</span><span id="UnivariateLinearRegression-186"><a href="#UnivariateLinearRegression-186"><span class="linenos">186</span></a>
</span><span id="UnivariateLinearRegression-187"><a href="#UnivariateLinearRegression-187"><span class="linenos">187</span></a><span class="sd">        `b` : np.float64</span>
</span><span id="UnivariateLinearRegression-188"><a href="#UnivariateLinearRegression-188"><span class="linenos">188</span></a><span class="sd">        - The intercept</span>
</span><span id="UnivariateLinearRegression-189"><a href="#UnivariateLinearRegression-189"><span class="linenos">189</span></a>
</span><span id="UnivariateLinearRegression-190"><a href="#UnivariateLinearRegression-190"><span class="linenos">190</span></a>
</span><span id="UnivariateLinearRegression-191"><a href="#UnivariateLinearRegression-191"><span class="linenos">191</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-192"><a href="#UnivariateLinearRegression-192"><span class="linenos">192</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-193"><a href="#UnivariateLinearRegression-193"><span class="linenos">193</span></a>
</span><span id="UnivariateLinearRegression-194"><a href="#UnivariateLinearRegression-194"><span class="linenos">194</span></a><span class="sd">        `np.float64`</span>
</span><span id="UnivariateLinearRegression-195"><a href="#UnivariateLinearRegression-195"><span class="linenos">195</span></a><span class="sd">        - The computed cost</span>
</span><span id="UnivariateLinearRegression-196"><a href="#UnivariateLinearRegression-196"><span class="linenos">196</span></a>
</span><span id="UnivariateLinearRegression-197"><a href="#UnivariateLinearRegression-197"><span class="linenos">197</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-198"><a href="#UnivariateLinearRegression-198"><span class="linenos">198</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-199"><a href="#UnivariateLinearRegression-199"><span class="linenos">199</span></a>        <span class="c1"># Number of samples</span>
</span><span id="UnivariateLinearRegression-200"><a href="#UnivariateLinearRegression-200"><span class="linenos">200</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-201"><a href="#UnivariateLinearRegression-201"><span class="linenos">201</span></a>        <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="UnivariateLinearRegression-202"><a href="#UnivariateLinearRegression-202"><span class="linenos">202</span></a>
</span><span id="UnivariateLinearRegression-203"><a href="#UnivariateLinearRegression-203"><span class="linenos">203</span></a>        <span class="c1"># cost = 1 / 2m * sum((y_hat_i - y_i) ^ 2)</span>
</span><span id="UnivariateLinearRegression-204"><a href="#UnivariateLinearRegression-204"><span class="linenos">204</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-205"><a href="#UnivariateLinearRegression-205"><span class="linenos">205</span></a>            <span class="n">y_hat_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-206"><a href="#UnivariateLinearRegression-206"><span class="linenos">206</span></a>            <span class="n">cost_i</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_hat_i</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span>
</span><span id="UnivariateLinearRegression-207"><a href="#UnivariateLinearRegression-207"><span class="linenos">207</span></a>            <span class="n">cost</span> <span class="o">+=</span> <span class="n">cost_i</span>
</span><span id="UnivariateLinearRegression-208"><a href="#UnivariateLinearRegression-208"><span class="linenos">208</span></a>        <span class="n">cost</span> <span class="o">/=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">m</span>
</span><span id="UnivariateLinearRegression-209"><a href="#UnivariateLinearRegression-209"><span class="linenos">209</span></a>        <span class="k">return</span> <span class="n">cost</span>
</span><span id="UnivariateLinearRegression-210"><a href="#UnivariateLinearRegression-210"><span class="linenos">210</span></a>
</span><span id="UnivariateLinearRegression-211"><a href="#UnivariateLinearRegression-211"><span class="linenos">211</span></a>    <span class="k">def</span> <span class="nf">_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="UnivariateLinearRegression-212"><a href="#UnivariateLinearRegression-212"><span class="linenos">212</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-213"><a href="#UnivariateLinearRegression-213"><span class="linenos">213</span></a><span class="sd">        ### Return the gradient of the cost function given X and Y.</span>
</span><span id="UnivariateLinearRegression-214"><a href="#UnivariateLinearRegression-214"><span class="linenos">214</span></a>
</span><span id="UnivariateLinearRegression-215"><a href="#UnivariateLinearRegression-215"><span class="linenos">215</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-216"><a href="#UnivariateLinearRegression-216"><span class="linenos">216</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-217"><a href="#UnivariateLinearRegression-217"><span class="linenos">217</span></a>
</span><span id="UnivariateLinearRegression-218"><a href="#UnivariateLinearRegression-218"><span class="linenos">218</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-219"><a href="#UnivariateLinearRegression-219"><span class="linenos">219</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-220"><a href="#UnivariateLinearRegression-220"><span class="linenos">220</span></a>
</span><span id="UnivariateLinearRegression-221"><a href="#UnivariateLinearRegression-221"><span class="linenos">221</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-222"><a href="#UnivariateLinearRegression-222"><span class="linenos">222</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-223"><a href="#UnivariateLinearRegression-223"><span class="linenos">223</span></a>
</span><span id="UnivariateLinearRegression-224"><a href="#UnivariateLinearRegression-224"><span class="linenos">224</span></a>
</span><span id="UnivariateLinearRegression-225"><a href="#UnivariateLinearRegression-225"><span class="linenos">225</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-226"><a href="#UnivariateLinearRegression-226"><span class="linenos">226</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-227"><a href="#UnivariateLinearRegression-227"><span class="linenos">227</span></a>
</span><span id="UnivariateLinearRegression-228"><a href="#UnivariateLinearRegression-228"><span class="linenos">228</span></a><span class="sd">        `Tuple[np.float64, np.float64]`</span>
</span><span id="UnivariateLinearRegression-229"><a href="#UnivariateLinearRegression-229"><span class="linenos">229</span></a><span class="sd">        - The gradient of the cost function with respect to w and b</span>
</span><span id="UnivariateLinearRegression-230"><a href="#UnivariateLinearRegression-230"><span class="linenos">230</span></a>
</span><span id="UnivariateLinearRegression-231"><a href="#UnivariateLinearRegression-231"><span class="linenos">231</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-232"><a href="#UnivariateLinearRegression-232"><span class="linenos">232</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-233"><a href="#UnivariateLinearRegression-233"><span class="linenos">233</span></a>        <span class="c1"># Number of samples</span>
</span><span id="UnivariateLinearRegression-234"><a href="#UnivariateLinearRegression-234"><span class="linenos">234</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-235"><a href="#UnivariateLinearRegression-235"><span class="linenos">235</span></a>        <span class="n">dw</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="UnivariateLinearRegression-236"><a href="#UnivariateLinearRegression-236"><span class="linenos">236</span></a>        <span class="n">db</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="UnivariateLinearRegression-237"><a href="#UnivariateLinearRegression-237"><span class="linenos">237</span></a>
</span><span id="UnivariateLinearRegression-238"><a href="#UnivariateLinearRegression-238"><span class="linenos">238</span></a>        <span class="c1"># dw = 1 / m * sum((y_hat_i - y_i) * x_i)</span>
</span><span id="UnivariateLinearRegression-239"><a href="#UnivariateLinearRegression-239"><span class="linenos">239</span></a>        <span class="c1"># db = 1 / m * sum(y_hat_i - y_i)</span>
</span><span id="UnivariateLinearRegression-240"><a href="#UnivariateLinearRegression-240"><span class="linenos">240</span></a>
</span><span id="UnivariateLinearRegression-241"><a href="#UnivariateLinearRegression-241"><span class="linenos">241</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-242"><a href="#UnivariateLinearRegression-242"><span class="linenos">242</span></a>            <span class="n">y_hat_i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-243"><a href="#UnivariateLinearRegression-243"><span class="linenos">243</span></a>            <span class="n">dw_i</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_hat_i</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-244"><a href="#UnivariateLinearRegression-244"><span class="linenos">244</span></a>            <span class="n">dw</span> <span class="o">+=</span> <span class="n">dw_i</span>
</span><span id="UnivariateLinearRegression-245"><a href="#UnivariateLinearRegression-245"><span class="linenos">245</span></a>            <span class="n">db_i</span> <span class="o">=</span> <span class="n">y_hat_i</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-246"><a href="#UnivariateLinearRegression-246"><span class="linenos">246</span></a>            <span class="n">db</span> <span class="o">+=</span> <span class="n">db_i</span>
</span><span id="UnivariateLinearRegression-247"><a href="#UnivariateLinearRegression-247"><span class="linenos">247</span></a>
</span><span id="UnivariateLinearRegression-248"><a href="#UnivariateLinearRegression-248"><span class="linenos">248</span></a>        <span class="k">return</span> <span class="n">dw</span> <span class="o">/</span> <span class="n">m</span><span class="p">,</span> <span class="n">db</span> <span class="o">/</span> <span class="n">m</span>
</span><span id="UnivariateLinearRegression-249"><a href="#UnivariateLinearRegression-249"><span class="linenos">249</span></a>
</span><span id="UnivariateLinearRegression-250"><a href="#UnivariateLinearRegression-250"><span class="linenos">250</span></a>    <span class="k">def</span> <span class="nf">_validate_data</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-251"><a href="#UnivariateLinearRegression-251"><span class="linenos">251</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="UnivariateLinearRegression-252"><a href="#UnivariateLinearRegression-252"><span class="linenos">252</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="UnivariateLinearRegression-253"><a href="#UnivariateLinearRegression-253"><span class="linenos">253</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-254"><a href="#UnivariateLinearRegression-254"><span class="linenos">254</span></a><span class="sd">        ### Return the input and output arrays.</span>
</span><span id="UnivariateLinearRegression-255"><a href="#UnivariateLinearRegression-255"><span class="linenos">255</span></a>
</span><span id="UnivariateLinearRegression-256"><a href="#UnivariateLinearRegression-256"><span class="linenos">256</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-257"><a href="#UnivariateLinearRegression-257"><span class="linenos">257</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-258"><a href="#UnivariateLinearRegression-258"><span class="linenos">258</span></a>
</span><span id="UnivariateLinearRegression-259"><a href="#UnivariateLinearRegression-259"><span class="linenos">259</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-260"><a href="#UnivariateLinearRegression-260"><span class="linenos">260</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-261"><a href="#UnivariateLinearRegression-261"><span class="linenos">261</span></a>
</span><span id="UnivariateLinearRegression-262"><a href="#UnivariateLinearRegression-262"><span class="linenos">262</span></a><span class="sd">        `Y` : np.ndarray or None, optional</span>
</span><span id="UnivariateLinearRegression-263"><a href="#UnivariateLinearRegression-263"><span class="linenos">263</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-264"><a href="#UnivariateLinearRegression-264"><span class="linenos">264</span></a>
</span><span id="UnivariateLinearRegression-265"><a href="#UnivariateLinearRegression-265"><span class="linenos">265</span></a>
</span><span id="UnivariateLinearRegression-266"><a href="#UnivariateLinearRegression-266"><span class="linenos">266</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-267"><a href="#UnivariateLinearRegression-267"><span class="linenos">267</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-268"><a href="#UnivariateLinearRegression-268"><span class="linenos">268</span></a>
</span><span id="UnivariateLinearRegression-269"><a href="#UnivariateLinearRegression-269"><span class="linenos">269</span></a><span class="sd">        `Tuple[np.ndarray, np.ndarray]`</span>
</span><span id="UnivariateLinearRegression-270"><a href="#UnivariateLinearRegression-270"><span class="linenos">270</span></a><span class="sd">        - The input and output arrays</span>
</span><span id="UnivariateLinearRegression-271"><a href="#UnivariateLinearRegression-271"><span class="linenos">271</span></a>
</span><span id="UnivariateLinearRegression-272"><a href="#UnivariateLinearRegression-272"><span class="linenos">272</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-273"><a href="#UnivariateLinearRegression-273"><span class="linenos">273</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-274"><a href="#UnivariateLinearRegression-274"><span class="linenos">274</span></a>        <span class="c1"># Copy the arrays if necessary</span>
</span><span id="UnivariateLinearRegression-275"><a href="#UnivariateLinearRegression-275"><span class="linenos">275</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_copy_x</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-276"><a href="#UnivariateLinearRegression-276"><span class="linenos">276</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-277"><a href="#UnivariateLinearRegression-277"><span class="linenos">277</span></a>
</span><span id="UnivariateLinearRegression-278"><a href="#UnivariateLinearRegression-278"><span class="linenos">278</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_numpy_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-279"><a href="#UnivariateLinearRegression-279"><span class="linenos">279</span></a>        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_numpy_array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="UnivariateLinearRegression-280"><a href="#UnivariateLinearRegression-280"><span class="linenos">280</span></a>
</span><span id="UnivariateLinearRegression-281"><a href="#UnivariateLinearRegression-281"><span class="linenos">281</span></a>        <span class="c1"># Check the shape of X and Y</span>
</span><span id="UnivariateLinearRegression-282"><a href="#UnivariateLinearRegression-282"><span class="linenos">282</span></a>        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span>
</span><span id="UnivariateLinearRegression-283"><a href="#UnivariateLinearRegression-283"><span class="linenos">283</span></a>            <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="UnivariateLinearRegression-284"><a href="#UnivariateLinearRegression-284"><span class="linenos">284</span></a>        <span class="p">),</span> <span class="s2">&quot;X must be a 1D or 2D array with shape (n_samples,) or (n_samples, 1)&quot;</span>
</span><span id="UnivariateLinearRegression-285"><a href="#UnivariateLinearRegression-285"><span class="linenos">285</span></a>
</span><span id="UnivariateLinearRegression-286"><a href="#UnivariateLinearRegression-286"><span class="linenos">286</span></a>        <span class="c1"># Reshape the arrays if necessary</span>
</span><span id="UnivariateLinearRegression-287"><a href="#UnivariateLinearRegression-287"><span class="linenos">287</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-288"><a href="#UnivariateLinearRegression-288"><span class="linenos">288</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-289"><a href="#UnivariateLinearRegression-289"><span class="linenos">289</span></a>
</span><span id="UnivariateLinearRegression-290"><a href="#UnivariateLinearRegression-290"><span class="linenos">290</span></a>        <span class="c1"># Scale input and output if necessary</span>
</span><span id="UnivariateLinearRegression-291"><a href="#UnivariateLinearRegression-291"><span class="linenos">291</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-292"><a href="#UnivariateLinearRegression-292"><span class="linenos">292</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-293"><a href="#UnivariateLinearRegression-293"><span class="linenos">293</span></a>
</span><span id="UnivariateLinearRegression-294"><a href="#UnivariateLinearRegression-294"><span class="linenos">294</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-295"><a href="#UnivariateLinearRegression-295"><span class="linenos">295</span></a>            <span class="k">assert</span> <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span>
</span><span id="UnivariateLinearRegression-296"><a href="#UnivariateLinearRegression-296"><span class="linenos">296</span></a>                <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="UnivariateLinearRegression-297"><a href="#UnivariateLinearRegression-297"><span class="linenos">297</span></a>            <span class="p">),</span> <span class="s2">&quot;Y must be a 1D or 2D array with shape (n_samples,) or (n_samples, 1)&quot;</span>
</span><span id="UnivariateLinearRegression-298"><a href="#UnivariateLinearRegression-298"><span class="linenos">298</span></a>
</span><span id="UnivariateLinearRegression-299"><a href="#UnivariateLinearRegression-299"><span class="linenos">299</span></a>            <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-300"><a href="#UnivariateLinearRegression-300"><span class="linenos">300</span></a>                <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-301"><a href="#UnivariateLinearRegression-301"><span class="linenos">301</span></a>
</span><span id="UnivariateLinearRegression-302"><a href="#UnivariateLinearRegression-302"><span class="linenos">302</span></a>            <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-303"><a href="#UnivariateLinearRegression-303"><span class="linenos">303</span></a>                <span class="n">Y</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-304"><a href="#UnivariateLinearRegression-304"><span class="linenos">304</span></a>
</span><span id="UnivariateLinearRegression-305"><a href="#UnivariateLinearRegression-305"><span class="linenos">305</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-306"><a href="#UnivariateLinearRegression-306"><span class="linenos">306</span></a>            <span class="k">return</span> <span class="n">X</span>
</span><span id="UnivariateLinearRegression-307"><a href="#UnivariateLinearRegression-307"><span class="linenos">307</span></a>        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</span><span id="UnivariateLinearRegression-308"><a href="#UnivariateLinearRegression-308"><span class="linenos">308</span></a>
</span><span id="UnivariateLinearRegression-309"><a href="#UnivariateLinearRegression-309"><span class="linenos">309</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-310"><a href="#UnivariateLinearRegression-310"><span class="linenos">310</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="UnivariateLinearRegression-311"><a href="#UnivariateLinearRegression-311"><span class="linenos">311</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-312"><a href="#UnivariateLinearRegression-312"><span class="linenos">312</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-313"><a href="#UnivariateLinearRegression-313"><span class="linenos">313</span></a><span class="sd">        ### Train the model given X and Y.</span>
</span><span id="UnivariateLinearRegression-314"><a href="#UnivariateLinearRegression-314"><span class="linenos">314</span></a>
</span><span id="UnivariateLinearRegression-315"><a href="#UnivariateLinearRegression-315"><span class="linenos">315</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-316"><a href="#UnivariateLinearRegression-316"><span class="linenos">316</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-317"><a href="#UnivariateLinearRegression-317"><span class="linenos">317</span></a>
</span><span id="UnivariateLinearRegression-318"><a href="#UnivariateLinearRegression-318"><span class="linenos">318</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-319"><a href="#UnivariateLinearRegression-319"><span class="linenos">319</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-320"><a href="#UnivariateLinearRegression-320"><span class="linenos">320</span></a>
</span><span id="UnivariateLinearRegression-321"><a href="#UnivariateLinearRegression-321"><span class="linenos">321</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-322"><a href="#UnivariateLinearRegression-322"><span class="linenos">322</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-323"><a href="#UnivariateLinearRegression-323"><span class="linenos">323</span></a>
</span><span id="UnivariateLinearRegression-324"><a href="#UnivariateLinearRegression-324"><span class="linenos">324</span></a><span class="sd">        `w` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression-325"><a href="#UnivariateLinearRegression-325"><span class="linenos">325</span></a><span class="sd">        - The initial weight, by default 0.0</span>
</span><span id="UnivariateLinearRegression-326"><a href="#UnivariateLinearRegression-326"><span class="linenos">326</span></a>
</span><span id="UnivariateLinearRegression-327"><a href="#UnivariateLinearRegression-327"><span class="linenos">327</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression-328"><a href="#UnivariateLinearRegression-328"><span class="linenos">328</span></a><span class="sd">        - The initial intercept, by default 0.0</span>
</span><span id="UnivariateLinearRegression-329"><a href="#UnivariateLinearRegression-329"><span class="linenos">329</span></a>
</span><span id="UnivariateLinearRegression-330"><a href="#UnivariateLinearRegression-330"><span class="linenos">330</span></a>
</span><span id="UnivariateLinearRegression-331"><a href="#UnivariateLinearRegression-331"><span class="linenos">331</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-332"><a href="#UnivariateLinearRegression-332"><span class="linenos">332</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-333"><a href="#UnivariateLinearRegression-333"><span class="linenos">333</span></a>
</span><span id="UnivariateLinearRegression-334"><a href="#UnivariateLinearRegression-334"><span class="linenos">334</span></a><span class="sd">        None</span>
</span><span id="UnivariateLinearRegression-335"><a href="#UnivariateLinearRegression-335"><span class="linenos">335</span></a>
</span><span id="UnivariateLinearRegression-336"><a href="#UnivariateLinearRegression-336"><span class="linenos">336</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-337"><a href="#UnivariateLinearRegression-337"><span class="linenos">337</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-338"><a href="#UnivariateLinearRegression-338"><span class="linenos">338</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-339"><a href="#UnivariateLinearRegression-339"><span class="linenos">339</span></a>
</span><span id="UnivariateLinearRegression-340"><a href="#UnivariateLinearRegression-340"><span class="linenos">340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">w</span>
</span><span id="UnivariateLinearRegression-341"><a href="#UnivariateLinearRegression-341"><span class="linenos">341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">=</span> <span class="n">b</span>
</span><span id="UnivariateLinearRegression-342"><a href="#UnivariateLinearRegression-342"><span class="linenos">342</span></a>
</span><span id="UnivariateLinearRegression-343"><a href="#UnivariateLinearRegression-343"><span class="linenos">343</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-344"><a href="#UnivariateLinearRegression-344"><span class="linenos">344</span></a>            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)]</span>
</span><span id="UnivariateLinearRegression-345"><a href="#UnivariateLinearRegression-345"><span class="linenos">345</span></a>        <span class="p">)</span>
</span><span id="UnivariateLinearRegression-346"><a href="#UnivariateLinearRegression-346"><span class="linenos">346</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">])])</span>
</span><span id="UnivariateLinearRegression-347"><a href="#UnivariateLinearRegression-347"><span class="linenos">347</span></a>
</span><span id="UnivariateLinearRegression-348"><a href="#UnivariateLinearRegression-348"><span class="linenos">348</span></a>        <span class="c1"># Gradient descent</span>
</span><span id="UnivariateLinearRegression-349"><a href="#UnivariateLinearRegression-349"><span class="linenos">349</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-350"><a href="#UnivariateLinearRegression-350"><span class="linenos">350</span></a>            <span class="c1"># Compute the gradient</span>
</span><span id="UnivariateLinearRegression-351"><a href="#UnivariateLinearRegression-351"><span class="linenos">351</span></a>            <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-352"><a href="#UnivariateLinearRegression-352"><span class="linenos">352</span></a>
</span><span id="UnivariateLinearRegression-353"><a href="#UnivariateLinearRegression-353"><span class="linenos">353</span></a>            <span class="c1"># Update the weight and intercept</span>
</span><span id="UnivariateLinearRegression-354"><a href="#UnivariateLinearRegression-354"><span class="linenos">354</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
</span><span id="UnivariateLinearRegression-355"><a href="#UnivariateLinearRegression-355"><span class="linenos">355</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">db</span>
</span><span id="UnivariateLinearRegression-356"><a href="#UnivariateLinearRegression-356"><span class="linenos">356</span></a>
</span><span id="UnivariateLinearRegression-357"><a href="#UnivariateLinearRegression-357"><span class="linenos">357</span></a>            <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-358"><a href="#UnivariateLinearRegression-358"><span class="linenos">358</span></a>
</span><span id="UnivariateLinearRegression-359"><a href="#UnivariateLinearRegression-359"><span class="linenos">359</span></a>            <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="ow">or</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-360"><a href="#UnivariateLinearRegression-360"><span class="linenos">360</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-361"><a href="#UnivariateLinearRegression-361"><span class="linenos">361</span></a>                    <span class="s2">&quot;Gradient descent failed. Try normalizing the input array or reducing the learning rate. &quot;</span>
</span><span id="UnivariateLinearRegression-362"><a href="#UnivariateLinearRegression-362"><span class="linenos">362</span></a>                    <span class="s2">&quot;If the problem persists, try reducing the number of iterations.&quot;</span>
</span><span id="UnivariateLinearRegression-363"><a href="#UnivariateLinearRegression-363"><span class="linenos">363</span></a>                <span class="p">)</span>
</span><span id="UnivariateLinearRegression-364"><a href="#UnivariateLinearRegression-364"><span class="linenos">364</span></a>
</span><span id="UnivariateLinearRegression-365"><a href="#UnivariateLinearRegression-365"><span class="linenos">365</span></a>            <span class="c1"># Save the cost and parameters</span>
</span><span id="UnivariateLinearRegression-366"><a href="#UnivariateLinearRegression-366"><span class="linenos">366</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-367"><a href="#UnivariateLinearRegression-367"><span class="linenos">367</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-368"><a href="#UnivariateLinearRegression-368"><span class="linenos">368</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-369"><a href="#UnivariateLinearRegression-369"><span class="linenos">369</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">]]),</span>
</span><span id="UnivariateLinearRegression-370"><a href="#UnivariateLinearRegression-370"><span class="linenos">370</span></a>                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression-371"><a href="#UnivariateLinearRegression-371"><span class="linenos">371</span></a>            <span class="p">)</span>
</span><span id="UnivariateLinearRegression-372"><a href="#UnivariateLinearRegression-372"><span class="linenos">372</span></a>
</span><span id="UnivariateLinearRegression-373"><a href="#UnivariateLinearRegression-373"><span class="linenos">373</span></a>            <span class="c1"># Print the cost and parameters</span>
</span><span id="UnivariateLinearRegression-374"><a href="#UnivariateLinearRegression-374"><span class="linenos">374</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-375"><a href="#UnivariateLinearRegression-375"><span class="linenos">375</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-376"><a href="#UnivariateLinearRegression-376"><span class="linenos">376</span></a>
</span><span id="UnivariateLinearRegression-377"><a href="#UnivariateLinearRegression-377"><span class="linenos">377</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-378"><a href="#UnivariateLinearRegression-378"><span class="linenos">378</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-379"><a href="#UnivariateLinearRegression-379"><span class="linenos">379</span></a>
</span><span id="UnivariateLinearRegression-380"><a href="#UnivariateLinearRegression-380"><span class="linenos">380</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-381"><a href="#UnivariateLinearRegression-381"><span class="linenos">381</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-382"><a href="#UnivariateLinearRegression-382"><span class="linenos">382</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="UnivariateLinearRegression-383"><a href="#UnivariateLinearRegression-383"><span class="linenos">383</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-384"><a href="#UnivariateLinearRegression-384"><span class="linenos">384</span></a><span class="sd">        ### Return the predicted value of y given x.</span>
</span><span id="UnivariateLinearRegression-385"><a href="#UnivariateLinearRegression-385"><span class="linenos">385</span></a>
</span><span id="UnivariateLinearRegression-386"><a href="#UnivariateLinearRegression-386"><span class="linenos">386</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-387"><a href="#UnivariateLinearRegression-387"><span class="linenos">387</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-388"><a href="#UnivariateLinearRegression-388"><span class="linenos">388</span></a>
</span><span id="UnivariateLinearRegression-389"><a href="#UnivariateLinearRegression-389"><span class="linenos">389</span></a><span class="sd">        `X` : Union[np.ndarray, np.float64]</span>
</span><span id="UnivariateLinearRegression-390"><a href="#UnivariateLinearRegression-390"><span class="linenos">390</span></a><span class="sd">        - The input value or array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-391"><a href="#UnivariateLinearRegression-391"><span class="linenos">391</span></a>
</span><span id="UnivariateLinearRegression-392"><a href="#UnivariateLinearRegression-392"><span class="linenos">392</span></a>
</span><span id="UnivariateLinearRegression-393"><a href="#UnivariateLinearRegression-393"><span class="linenos">393</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-394"><a href="#UnivariateLinearRegression-394"><span class="linenos">394</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-395"><a href="#UnivariateLinearRegression-395"><span class="linenos">395</span></a>
</span><span id="UnivariateLinearRegression-396"><a href="#UnivariateLinearRegression-396"><span class="linenos">396</span></a><span class="sd">        `Union[np.ndarray, np.float64]`</span>
</span><span id="UnivariateLinearRegression-397"><a href="#UnivariateLinearRegression-397"><span class="linenos">397</span></a><span class="sd">        - The predicted value or array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-398"><a href="#UnivariateLinearRegression-398"><span class="linenos">398</span></a>
</span><span id="UnivariateLinearRegression-399"><a href="#UnivariateLinearRegression-399"><span class="linenos">399</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-400"><a href="#UnivariateLinearRegression-400"><span class="linenos">400</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-401"><a href="#UnivariateLinearRegression-401"><span class="linenos">401</span></a>        <span class="c1"># Check if the model is trained</span>
</span><span id="UnivariateLinearRegression-402"><a href="#UnivariateLinearRegression-402"><span class="linenos">402</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span><span id="UnivariateLinearRegression-403"><a href="#UnivariateLinearRegression-403"><span class="linenos">403</span></a>            <span class="s2">&quot;The model must be trained before making predictions. &quot;</span>
</span><span id="UnivariateLinearRegression-404"><a href="#UnivariateLinearRegression-404"><span class="linenos">404</span></a>            <span class="s2">&quot;Call the fit method first.&quot;</span>
</span><span id="UnivariateLinearRegression-405"><a href="#UnivariateLinearRegression-405"><span class="linenos">405</span></a>        <span class="p">)</span>
</span><span id="UnivariateLinearRegression-406"><a href="#UnivariateLinearRegression-406"><span class="linenos">406</span></a>
</span><span id="UnivariateLinearRegression-407"><a href="#UnivariateLinearRegression-407"><span class="linenos">407</span></a>        <span class="n">isXScalar</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-408"><a href="#UnivariateLinearRegression-408"><span class="linenos">408</span></a>
</span><span id="UnivariateLinearRegression-409"><a href="#UnivariateLinearRegression-409"><span class="linenos">409</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression-410"><a href="#UnivariateLinearRegression-410"><span class="linenos">410</span></a>            <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span>
</span><span id="UnivariateLinearRegression-411"><a href="#UnivariateLinearRegression-411"><span class="linenos">411</span></a>                <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="UnivariateLinearRegression-412"><a href="#UnivariateLinearRegression-412"><span class="linenos">412</span></a>            <span class="p">),</span> <span class="s2">&quot;X must be a 1D or 2D array with shape (n_samples,) or (n_samples, 1)&quot;</span>
</span><span id="UnivariateLinearRegression-413"><a href="#UnivariateLinearRegression-413"><span class="linenos">413</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-414"><a href="#UnivariateLinearRegression-414"><span class="linenos">414</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="p">])</span>
</span><span id="UnivariateLinearRegression-415"><a href="#UnivariateLinearRegression-415"><span class="linenos">415</span></a>
</span><span id="UnivariateLinearRegression-416"><a href="#UnivariateLinearRegression-416"><span class="linenos">416</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-417"><a href="#UnivariateLinearRegression-417"><span class="linenos">417</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-418"><a href="#UnivariateLinearRegression-418"><span class="linenos">418</span></a>
</span><span id="UnivariateLinearRegression-419"><a href="#UnivariateLinearRegression-419"><span class="linenos">419</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression-420"><a href="#UnivariateLinearRegression-420"><span class="linenos">420</span></a>
</span><span id="UnivariateLinearRegression-421"><a href="#UnivariateLinearRegression-421"><span class="linenos">421</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-422"><a href="#UnivariateLinearRegression-422"><span class="linenos">422</span></a>            <span class="n">predictions</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-423"><a href="#UnivariateLinearRegression-423"><span class="linenos">423</span></a>
</span><span id="UnivariateLinearRegression-424"><a href="#UnivariateLinearRegression-424"><span class="linenos">424</span></a>        <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">isXScalar</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-425"><a href="#UnivariateLinearRegression-425"><span class="linenos">425</span></a>
</span><span id="UnivariateLinearRegression-426"><a href="#UnivariateLinearRegression-426"><span class="linenos">426</span></a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression-427"><a href="#UnivariateLinearRegression-427"><span class="linenos">427</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="UnivariateLinearRegression-428"><a href="#UnivariateLinearRegression-428"><span class="linenos">428</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression-429"><a href="#UnivariateLinearRegression-429"><span class="linenos">429</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-430"><a href="#UnivariateLinearRegression-430"><span class="linenos">430</span></a><span class="sd">        ### Return the cost function given X, Y, w, and b.</span>
</span><span id="UnivariateLinearRegression-431"><a href="#UnivariateLinearRegression-431"><span class="linenos">431</span></a>
</span><span id="UnivariateLinearRegression-432"><a href="#UnivariateLinearRegression-432"><span class="linenos">432</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression-433"><a href="#UnivariateLinearRegression-433"><span class="linenos">433</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression-434"><a href="#UnivariateLinearRegression-434"><span class="linenos">434</span></a>
</span><span id="UnivariateLinearRegression-435"><a href="#UnivariateLinearRegression-435"><span class="linenos">435</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-436"><a href="#UnivariateLinearRegression-436"><span class="linenos">436</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-437"><a href="#UnivariateLinearRegression-437"><span class="linenos">437</span></a>
</span><span id="UnivariateLinearRegression-438"><a href="#UnivariateLinearRegression-438"><span class="linenos">438</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="UnivariateLinearRegression-439"><a href="#UnivariateLinearRegression-439"><span class="linenos">439</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression-440"><a href="#UnivariateLinearRegression-440"><span class="linenos">440</span></a>
</span><span id="UnivariateLinearRegression-441"><a href="#UnivariateLinearRegression-441"><span class="linenos">441</span></a><span class="sd">        `w` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression-442"><a href="#UnivariateLinearRegression-442"><span class="linenos">442</span></a><span class="sd">        - The weight, by default None</span>
</span><span id="UnivariateLinearRegression-443"><a href="#UnivariateLinearRegression-443"><span class="linenos">443</span></a>
</span><span id="UnivariateLinearRegression-444"><a href="#UnivariateLinearRegression-444"><span class="linenos">444</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression-445"><a href="#UnivariateLinearRegression-445"><span class="linenos">445</span></a><span class="sd">        - The intercept, by default None</span>
</span><span id="UnivariateLinearRegression-446"><a href="#UnivariateLinearRegression-446"><span class="linenos">446</span></a>
</span><span id="UnivariateLinearRegression-447"><a href="#UnivariateLinearRegression-447"><span class="linenos">447</span></a>
</span><span id="UnivariateLinearRegression-448"><a href="#UnivariateLinearRegression-448"><span class="linenos">448</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression-449"><a href="#UnivariateLinearRegression-449"><span class="linenos">449</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression-450"><a href="#UnivariateLinearRegression-450"><span class="linenos">450</span></a>
</span><span id="UnivariateLinearRegression-451"><a href="#UnivariateLinearRegression-451"><span class="linenos">451</span></a><span class="sd">        `np.float64`</span>
</span><span id="UnivariateLinearRegression-452"><a href="#UnivariateLinearRegression-452"><span class="linenos">452</span></a><span class="sd">        - The computed cost</span>
</span><span id="UnivariateLinearRegression-453"><a href="#UnivariateLinearRegression-453"><span class="linenos">453</span></a>
</span><span id="UnivariateLinearRegression-454"><a href="#UnivariateLinearRegression-454"><span class="linenos">454</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression-455"><a href="#UnivariateLinearRegression-455"><span class="linenos">455</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression-456"><a href="#UnivariateLinearRegression-456"><span class="linenos">456</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression-457"><a href="#UnivariateLinearRegression-457"><span class="linenos">457</span></a>
</span><span id="UnivariateLinearRegression-458"><a href="#UnivariateLinearRegression-458"><span class="linenos">458</span></a>        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w</span>
</span><span id="UnivariateLinearRegression-459"><a href="#UnivariateLinearRegression-459"><span class="linenos">459</span></a>        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b</span>
</span><span id="UnivariateLinearRegression-460"><a href="#UnivariateLinearRegression-460"><span class="linenos">460</span></a>
</span><span id="UnivariateLinearRegression-461"><a href="#UnivariateLinearRegression-461"><span class="linenos">461</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h1 id="univariate-linear-regression-model">Univariate Linear Regression model.</h1>

<p>Linear regression is a fundamental supervised machine learning algorithm that models the relationship between a dependent variable and a single independent variable. It approximates this relationship using a linear equation. Univariate Linear Regression is particularly useful when there is a clear linear correlation between the input and output variables.</p>

<hr />

<h2 id="mathematical-approach">Mathematical Approach</h2>

<p>Univariate Linear Regression aims to find the best-fitting line that predicts the output variable based on the input feature. The linear equation is represented as:</p>

<pre><code>y = mx + b
</code></pre>

<p>Where:</p>

<ul>
<li><code>y</code> is the predicted output (target variable).</li>
<li><code>x</code> is the input feature (independent variable).</li>
<li><code>m</code> is the slope of the line (weight).</li>
<li><code>b</code> is the y-intercept.</li>
</ul>

<p>The goal is to determine the optimal values of <code>m</code> and <code>b</code> that minimize the difference between predicted values and actual target values.</p>

<hr />

<h2 id="usage">Usage</h2>

<p>To utilize the Univariate Linear Regression model, follow these steps:</p>

<ol>
<li>Import the <code><a href="#UnivariateLinearRegression">UnivariateLinearRegression</a></code> class from the appropriate module.</li>
<li>Create an instance of the <code><a href="#UnivariateLinearRegression">UnivariateLinearRegression</a></code> class, specifying hyperparameters.</li>
<li>Fit the model to your training data using the <code><a href="#UnivariateLinearRegression.fit">fit</a></code> method.</li>
<li>Make predictions on new data using the <code><a href="#UnivariateLinearRegression.predict">predict</a></code> method.</li>
<li>Evaluate the model's performance using the <code><a href="#UnivariateLinearRegression.score">score</a></code> method.</li>
</ol>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">from</span> <span class="nn"><a href="">learnML.regression</a></span> <span class="kn">import</span> <span class="n">UnivariateLinearRegression</span>

<span class="c1"># Create an instance of UnivariateLinearRegression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">UnivariateLinearRegression</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Fit the model to training data</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Make predictions on new data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the model&#39;s score</span>
<span class="n">model_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
</code></pre>
</div>

<hr />

<h2 id="advantages">Advantages</h2>

<ul>
<li>Easy to implement</li>
<li>Easy to interpret the output</li>
<li>Computationally cheap</li>
</ul>

<h2 id="disadvantages">Disadvantages</h2>

<ul>
<li>Poor performance on non-linear data</li>
<li>Sensitive to outliers</li>
<li>Sensitive to overfitting</li>
</ul>

<hr />
</div>


                            <div id="UnivariateLinearRegression.__init__" class="classattr">
                                        <input id="UnivariateLinearRegression.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">UnivariateLinearRegression</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">learning_rate</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span>,</span><span class="param">	<span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>,</span><span class="param">	<span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="UnivariateLinearRegression.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#UnivariateLinearRegression.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="UnivariateLinearRegression.__init__-79"><a href="#UnivariateLinearRegression.__init__-79"><span class="linenos"> 79</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.__init__-80"><a href="#UnivariateLinearRegression.__init__-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-81"><a href="#UnivariateLinearRegression.__init__-81"><span class="linenos"> 81</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-82"><a href="#UnivariateLinearRegression.__init__-82"><span class="linenos"> 82</span></a>        <span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-83"><a href="#UnivariateLinearRegression.__init__-83"><span class="linenos"> 83</span></a>        <span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-84"><a href="#UnivariateLinearRegression.__init__-84"><span class="linenos"> 84</span></a>        <span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-85"><a href="#UnivariateLinearRegression.__init__-85"><span class="linenos"> 85</span></a>        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-86"><a href="#UnivariateLinearRegression.__init__-86"><span class="linenos"> 86</span></a>        <span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-87"><a href="#UnivariateLinearRegression.__init__-87"><span class="linenos"> 87</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.__init__-88"><a href="#UnivariateLinearRegression.__init__-88"><span class="linenos"> 88</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.__init__-89"><a href="#UnivariateLinearRegression.__init__-89"><span class="linenos"> 89</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression.__init__-90"><a href="#UnivariateLinearRegression.__init__-90"><span class="linenos"> 90</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression.__init__-91"><a href="#UnivariateLinearRegression.__init__-91"><span class="linenos"> 91</span></a>
</span><span id="UnivariateLinearRegression.__init__-92"><a href="#UnivariateLinearRegression.__init__-92"><span class="linenos"> 92</span></a><span class="sd">        `learning_rate` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression.__init__-93"><a href="#UnivariateLinearRegression.__init__-93"><span class="linenos"> 93</span></a><span class="sd">        - The learning rate, by default 0.001</span>
</span><span id="UnivariateLinearRegression.__init__-94"><a href="#UnivariateLinearRegression.__init__-94"><span class="linenos"> 94</span></a><span class="sd">        - The learning rate determines how much the weights are updated at each iteration</span>
</span><span id="UnivariateLinearRegression.__init__-95"><a href="#UnivariateLinearRegression.__init__-95"><span class="linenos"> 95</span></a><span class="sd">        - A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</span>
</span><span id="UnivariateLinearRegression.__init__-96"><a href="#UnivariateLinearRegression.__init__-96"><span class="linenos"> 96</span></a>
</span><span id="UnivariateLinearRegression.__init__-97"><a href="#UnivariateLinearRegression.__init__-97"><span class="linenos"> 97</span></a><span class="sd">        `n_iterations` : int, optional</span>
</span><span id="UnivariateLinearRegression.__init__-98"><a href="#UnivariateLinearRegression.__init__-98"><span class="linenos"> 98</span></a><span class="sd">        - The number of iterations, by default 1000</span>
</span><span id="UnivariateLinearRegression.__init__-99"><a href="#UnivariateLinearRegression.__init__-99"><span class="linenos"> 99</span></a><span class="sd">        - The number of iterations determines how many times the weights are updated</span>
</span><span id="UnivariateLinearRegression.__init__-100"><a href="#UnivariateLinearRegression.__init__-100"><span class="linenos">100</span></a><span class="sd">        - A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</span>
</span><span id="UnivariateLinearRegression.__init__-101"><a href="#UnivariateLinearRegression.__init__-101"><span class="linenos">101</span></a>
</span><span id="UnivariateLinearRegression.__init__-102"><a href="#UnivariateLinearRegression.__init__-102"><span class="linenos">102</span></a><span class="sd">        `x_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="UnivariateLinearRegression.__init__-103"><a href="#UnivariateLinearRegression.__init__-103"><span class="linenos">103</span></a><span class="sd">        - The feature engineering for the input data, by default None</span>
</span><span id="UnivariateLinearRegression.__init__-104"><a href="#UnivariateLinearRegression.__init__-104"><span class="linenos">104</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="UnivariateLinearRegression.__init__-105"><a href="#UnivariateLinearRegression.__init__-105"><span class="linenos">105</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all input data</span>
</span><span id="UnivariateLinearRegression.__init__-106"><a href="#UnivariateLinearRegression.__init__-106"><span class="linenos">106</span></a>
</span><span id="UnivariateLinearRegression.__init__-107"><a href="#UnivariateLinearRegression.__init__-107"><span class="linenos">107</span></a><span class="sd">        `y_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="UnivariateLinearRegression.__init__-108"><a href="#UnivariateLinearRegression.__init__-108"><span class="linenos">108</span></a><span class="sd">        - The feature engineering for the output data, by default None</span>
</span><span id="UnivariateLinearRegression.__init__-109"><a href="#UnivariateLinearRegression.__init__-109"><span class="linenos">109</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="UnivariateLinearRegression.__init__-110"><a href="#UnivariateLinearRegression.__init__-110"><span class="linenos">110</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all output data</span>
</span><span id="UnivariateLinearRegression.__init__-111"><a href="#UnivariateLinearRegression.__init__-111"><span class="linenos">111</span></a>
</span><span id="UnivariateLinearRegression.__init__-112"><a href="#UnivariateLinearRegression.__init__-112"><span class="linenos">112</span></a><span class="sd">        `debug` : bool, optional</span>
</span><span id="UnivariateLinearRegression.__init__-113"><a href="#UnivariateLinearRegression.__init__-113"><span class="linenos">113</span></a><span class="sd">        - Whether to print debug messages, by default True</span>
</span><span id="UnivariateLinearRegression.__init__-114"><a href="#UnivariateLinearRegression.__init__-114"><span class="linenos">114</span></a><span class="sd">        - Debug messages include the cost at each iteration</span>
</span><span id="UnivariateLinearRegression.__init__-115"><a href="#UnivariateLinearRegression.__init__-115"><span class="linenos">115</span></a>
</span><span id="UnivariateLinearRegression.__init__-116"><a href="#UnivariateLinearRegression.__init__-116"><span class="linenos">116</span></a><span class="sd">        `copy_x` : bool, optional</span>
</span><span id="UnivariateLinearRegression.__init__-117"><a href="#UnivariateLinearRegression.__init__-117"><span class="linenos">117</span></a><span class="sd">        - Whether to copy the input array, by default True</span>
</span><span id="UnivariateLinearRegression.__init__-118"><a href="#UnivariateLinearRegression.__init__-118"><span class="linenos">118</span></a><span class="sd">        - If False, the input array will be overwritten</span>
</span><span id="UnivariateLinearRegression.__init__-119"><a href="#UnivariateLinearRegression.__init__-119"><span class="linenos">119</span></a>
</span><span id="UnivariateLinearRegression.__init__-120"><a href="#UnivariateLinearRegression.__init__-120"><span class="linenos">120</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression.__init__-121"><a href="#UnivariateLinearRegression.__init__-121"><span class="linenos">121</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.__init__-122"><a href="#UnivariateLinearRegression.__init__-122"><span class="linenos">122</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.__init__-123"><a href="#UnivariateLinearRegression.__init__-123"><span class="linenos">123</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-124"><a href="#UnivariateLinearRegression.__init__-124"><span class="linenos">124</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-125"><a href="#UnivariateLinearRegression.__init__-125"><span class="linenos">125</span></a>            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-126"><a href="#UnivariateLinearRegression.__init__-126"><span class="linenos">126</span></a>            <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.__init__-127"><a href="#UnivariateLinearRegression.__init__-127"><span class="linenos">127</span></a>        <span class="p">)</span>
</span><span id="UnivariateLinearRegression.__init__-128"><a href="#UnivariateLinearRegression.__init__-128"><span class="linenos">128</span></a>
</span><span id="UnivariateLinearRegression.__init__-129"><a href="#UnivariateLinearRegression.__init__-129"><span class="linenos">129</span></a>        <span class="k">if</span> <span class="n">x_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.__init__-130"><a href="#UnivariateLinearRegression.__init__-130"><span class="linenos">130</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="UnivariateLinearRegression.__init__-131"><a href="#UnivariateLinearRegression.__init__-131"><span class="linenos">131</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression.__init__-132"><a href="#UnivariateLinearRegression.__init__-132"><span class="linenos">132</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_scalar</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression.__init__-133"><a href="#UnivariateLinearRegression.__init__-133"><span class="linenos">133</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span> <span class="o">=</span> <span class="n">x_scalar</span>
</span><span id="UnivariateLinearRegression.__init__-134"><a href="#UnivariateLinearRegression.__init__-134"><span class="linenos">134</span></a>
</span><span id="UnivariateLinearRegression.__init__-135"><a href="#UnivariateLinearRegression.__init__-135"><span class="linenos">135</span></a>        <span class="k">if</span> <span class="n">y_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.__init__-136"><a href="#UnivariateLinearRegression.__init__-136"><span class="linenos">136</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="UnivariateLinearRegression.__init__-137"><a href="#UnivariateLinearRegression.__init__-137"><span class="linenos">137</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression.__init__-138"><a href="#UnivariateLinearRegression.__init__-138"><span class="linenos">138</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_scalar</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression.__init__-139"><a href="#UnivariateLinearRegression.__init__-139"><span class="linenos">139</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span> <span class="o">=</span> <span class="n">y_scalar</span>
</span></pre></div>


            <div class="docstring"><h2 id="parameters">Parameters</h2>

<p><code>learning_rate</code> : np.float64, optional</p>

<ul>
<li>The learning rate, by default 0.001</li>
<li>The learning rate determines how much the weights are updated at each iteration</li>
<li>A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</li>
</ul>

<p><code>n_iterations</code> : int, optional</p>

<ul>
<li>The number of iterations, by default 1000</li>
<li>The number of iterations determines how many times the weights are updated</li>
<li>A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</li>
</ul>

<p><code>x_scalar</code> : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</p>

<ul>
<li>The feature engineering for the input data, by default None</li>
<li>If a list is provided, the feature engineering will be applied in the order provided</li>
<li>If a single feature engineering is provided, it will be applied to all input data</li>
</ul>

<p><code>y_scalar</code> : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</p>

<ul>
<li>The feature engineering for the output data, by default None</li>
<li>If a list is provided, the feature engineering will be applied in the order provided</li>
<li>If a single feature engineering is provided, it will be applied to all output data</li>
</ul>

<p><code>debug</code> : bool, optional</p>

<ul>
<li>Whether to print debug messages, by default True</li>
<li>Debug messages include the cost at each iteration</li>
</ul>

<p><code>copy_x</code> : bool, optional</p>

<ul>
<li>Whether to copy the input array, by default True</li>
<li>If False, the input array will be overwritten</li>
</ul>

<hr />
</div>


                            </div>
                            <div id="UnivariateLinearRegression.fit" class="classattr">
                                        <input id="UnivariateLinearRegression.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">Y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">w</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.0</span>,</span><span class="param">	<span class="n">b</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.0</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="UnivariateLinearRegression.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#UnivariateLinearRegression.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="UnivariateLinearRegression.fit-309"><a href="#UnivariateLinearRegression.fit-309"><span class="linenos">309</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.fit-310"><a href="#UnivariateLinearRegression.fit-310"><span class="linenos">310</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span id="UnivariateLinearRegression.fit-311"><a href="#UnivariateLinearRegression.fit-311"><span class="linenos">311</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.fit-312"><a href="#UnivariateLinearRegression.fit-312"><span class="linenos">312</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.fit-313"><a href="#UnivariateLinearRegression.fit-313"><span class="linenos">313</span></a><span class="sd">        ### Train the model given X and Y.</span>
</span><span id="UnivariateLinearRegression.fit-314"><a href="#UnivariateLinearRegression.fit-314"><span class="linenos">314</span></a>
</span><span id="UnivariateLinearRegression.fit-315"><a href="#UnivariateLinearRegression.fit-315"><span class="linenos">315</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression.fit-316"><a href="#UnivariateLinearRegression.fit-316"><span class="linenos">316</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression.fit-317"><a href="#UnivariateLinearRegression.fit-317"><span class="linenos">317</span></a>
</span><span id="UnivariateLinearRegression.fit-318"><a href="#UnivariateLinearRegression.fit-318"><span class="linenos">318</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression.fit-319"><a href="#UnivariateLinearRegression.fit-319"><span class="linenos">319</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression.fit-320"><a href="#UnivariateLinearRegression.fit-320"><span class="linenos">320</span></a>
</span><span id="UnivariateLinearRegression.fit-321"><a href="#UnivariateLinearRegression.fit-321"><span class="linenos">321</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="UnivariateLinearRegression.fit-322"><a href="#UnivariateLinearRegression.fit-322"><span class="linenos">322</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression.fit-323"><a href="#UnivariateLinearRegression.fit-323"><span class="linenos">323</span></a>
</span><span id="UnivariateLinearRegression.fit-324"><a href="#UnivariateLinearRegression.fit-324"><span class="linenos">324</span></a><span class="sd">        `w` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression.fit-325"><a href="#UnivariateLinearRegression.fit-325"><span class="linenos">325</span></a><span class="sd">        - The initial weight, by default 0.0</span>
</span><span id="UnivariateLinearRegression.fit-326"><a href="#UnivariateLinearRegression.fit-326"><span class="linenos">326</span></a>
</span><span id="UnivariateLinearRegression.fit-327"><a href="#UnivariateLinearRegression.fit-327"><span class="linenos">327</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression.fit-328"><a href="#UnivariateLinearRegression.fit-328"><span class="linenos">328</span></a><span class="sd">        - The initial intercept, by default 0.0</span>
</span><span id="UnivariateLinearRegression.fit-329"><a href="#UnivariateLinearRegression.fit-329"><span class="linenos">329</span></a>
</span><span id="UnivariateLinearRegression.fit-330"><a href="#UnivariateLinearRegression.fit-330"><span class="linenos">330</span></a>
</span><span id="UnivariateLinearRegression.fit-331"><a href="#UnivariateLinearRegression.fit-331"><span class="linenos">331</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression.fit-332"><a href="#UnivariateLinearRegression.fit-332"><span class="linenos">332</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression.fit-333"><a href="#UnivariateLinearRegression.fit-333"><span class="linenos">333</span></a>
</span><span id="UnivariateLinearRegression.fit-334"><a href="#UnivariateLinearRegression.fit-334"><span class="linenos">334</span></a><span class="sd">        None</span>
</span><span id="UnivariateLinearRegression.fit-335"><a href="#UnivariateLinearRegression.fit-335"><span class="linenos">335</span></a>
</span><span id="UnivariateLinearRegression.fit-336"><a href="#UnivariateLinearRegression.fit-336"><span class="linenos">336</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression.fit-337"><a href="#UnivariateLinearRegression.fit-337"><span class="linenos">337</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.fit-338"><a href="#UnivariateLinearRegression.fit-338"><span class="linenos">338</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-339"><a href="#UnivariateLinearRegression.fit-339"><span class="linenos">339</span></a>
</span><span id="UnivariateLinearRegression.fit-340"><a href="#UnivariateLinearRegression.fit-340"><span class="linenos">340</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">w</span>
</span><span id="UnivariateLinearRegression.fit-341"><a href="#UnivariateLinearRegression.fit-341"><span class="linenos">341</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">=</span> <span class="n">b</span>
</span><span id="UnivariateLinearRegression.fit-342"><a href="#UnivariateLinearRegression.fit-342"><span class="linenos">342</span></a>
</span><span id="UnivariateLinearRegression.fit-343"><a href="#UnivariateLinearRegression.fit-343"><span class="linenos">343</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.fit-344"><a href="#UnivariateLinearRegression.fit-344"><span class="linenos">344</span></a>            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)]</span>
</span><span id="UnivariateLinearRegression.fit-345"><a href="#UnivariateLinearRegression.fit-345"><span class="linenos">345</span></a>        <span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-346"><a href="#UnivariateLinearRegression.fit-346"><span class="linenos">346</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">])])</span>
</span><span id="UnivariateLinearRegression.fit-347"><a href="#UnivariateLinearRegression.fit-347"><span class="linenos">347</span></a>
</span><span id="UnivariateLinearRegression.fit-348"><a href="#UnivariateLinearRegression.fit-348"><span class="linenos">348</span></a>        <span class="c1"># Gradient descent</span>
</span><span id="UnivariateLinearRegression.fit-349"><a href="#UnivariateLinearRegression.fit-349"><span class="linenos">349</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression.fit-350"><a href="#UnivariateLinearRegression.fit-350"><span class="linenos">350</span></a>            <span class="c1"># Compute the gradient</span>
</span><span id="UnivariateLinearRegression.fit-351"><a href="#UnivariateLinearRegression.fit-351"><span class="linenos">351</span></a>            <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-352"><a href="#UnivariateLinearRegression.fit-352"><span class="linenos">352</span></a>
</span><span id="UnivariateLinearRegression.fit-353"><a href="#UnivariateLinearRegression.fit-353"><span class="linenos">353</span></a>            <span class="c1"># Update the weight and intercept</span>
</span><span id="UnivariateLinearRegression.fit-354"><a href="#UnivariateLinearRegression.fit-354"><span class="linenos">354</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
</span><span id="UnivariateLinearRegression.fit-355"><a href="#UnivariateLinearRegression.fit-355"><span class="linenos">355</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">db</span>
</span><span id="UnivariateLinearRegression.fit-356"><a href="#UnivariateLinearRegression.fit-356"><span class="linenos">356</span></a>
</span><span id="UnivariateLinearRegression.fit-357"><a href="#UnivariateLinearRegression.fit-357"><span class="linenos">357</span></a>            <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-358"><a href="#UnivariateLinearRegression.fit-358"><span class="linenos">358</span></a>
</span><span id="UnivariateLinearRegression.fit-359"><a href="#UnivariateLinearRegression.fit-359"><span class="linenos">359</span></a>            <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="ow">or</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.fit-360"><a href="#UnivariateLinearRegression.fit-360"><span class="linenos">360</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.fit-361"><a href="#UnivariateLinearRegression.fit-361"><span class="linenos">361</span></a>                    <span class="s2">&quot;Gradient descent failed. Try normalizing the input array or reducing the learning rate. &quot;</span>
</span><span id="UnivariateLinearRegression.fit-362"><a href="#UnivariateLinearRegression.fit-362"><span class="linenos">362</span></a>                    <span class="s2">&quot;If the problem persists, try reducing the number of iterations.&quot;</span>
</span><span id="UnivariateLinearRegression.fit-363"><a href="#UnivariateLinearRegression.fit-363"><span class="linenos">363</span></a>                <span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-364"><a href="#UnivariateLinearRegression.fit-364"><span class="linenos">364</span></a>
</span><span id="UnivariateLinearRegression.fit-365"><a href="#UnivariateLinearRegression.fit-365"><span class="linenos">365</span></a>            <span class="c1"># Save the cost and parameters</span>
</span><span id="UnivariateLinearRegression.fit-366"><a href="#UnivariateLinearRegression.fit-366"><span class="linenos">366</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-367"><a href="#UnivariateLinearRegression.fit-367"><span class="linenos">367</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.fit-368"><a href="#UnivariateLinearRegression.fit-368"><span class="linenos">368</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.fit-369"><a href="#UnivariateLinearRegression.fit-369"><span class="linenos">369</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">]]),</span>
</span><span id="UnivariateLinearRegression.fit-370"><a href="#UnivariateLinearRegression.fit-370"><span class="linenos">370</span></a>                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="UnivariateLinearRegression.fit-371"><a href="#UnivariateLinearRegression.fit-371"><span class="linenos">371</span></a>            <span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-372"><a href="#UnivariateLinearRegression.fit-372"><span class="linenos">372</span></a>
</span><span id="UnivariateLinearRegression.fit-373"><a href="#UnivariateLinearRegression.fit-373"><span class="linenos">373</span></a>            <span class="c1"># Print the cost and parameters</span>
</span><span id="UnivariateLinearRegression.fit-374"><a href="#UnivariateLinearRegression.fit-374"><span class="linenos">374</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.fit-375"><a href="#UnivariateLinearRegression.fit-375"><span class="linenos">375</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.fit-376"><a href="#UnivariateLinearRegression.fit-376"><span class="linenos">376</span></a>
</span><span id="UnivariateLinearRegression.fit-377"><a href="#UnivariateLinearRegression.fit-377"><span class="linenos">377</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.fit-378"><a href="#UnivariateLinearRegression.fit-378"><span class="linenos">378</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h3 id="train-the-model-given-x-and-y">Train the model given X and Y.</h3>

<h2 id="parameters">Parameters</h2>

<p><code>X</code> : np.ndarray</p>

<ul>
<li>The input array of shape (n_samples,)</li>
</ul>

<p><code>Y</code> : np.ndarray</p>

<ul>
<li>The output array of shape (n_samples,)</li>
</ul>

<p><code>w</code> : np.float64, optional</p>

<ul>
<li>The initial weight, by default 0.0</li>
</ul>

<p><code>b</code> : np.float64, optional</p>

<ul>
<li>The initial intercept, by default 0.0</li>
</ul>

<h2 id="returns">Returns</h2>

<p>None</p>

<hr />
</div>


                            </div>
                            <div id="UnivariateLinearRegression.predict" class="classattr">
                                        <input id="UnivariateLinearRegression.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span></span><span class="return-annotation">) -> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="UnivariateLinearRegression.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#UnivariateLinearRegression.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="UnivariateLinearRegression.predict-380"><a href="#UnivariateLinearRegression.predict-380"><span class="linenos">380</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.predict-381"><a href="#UnivariateLinearRegression.predict-381"><span class="linenos">381</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression.predict-382"><a href="#UnivariateLinearRegression.predict-382"><span class="linenos">382</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="UnivariateLinearRegression.predict-383"><a href="#UnivariateLinearRegression.predict-383"><span class="linenos">383</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.predict-384"><a href="#UnivariateLinearRegression.predict-384"><span class="linenos">384</span></a><span class="sd">        ### Return the predicted value of y given x.</span>
</span><span id="UnivariateLinearRegression.predict-385"><a href="#UnivariateLinearRegression.predict-385"><span class="linenos">385</span></a>
</span><span id="UnivariateLinearRegression.predict-386"><a href="#UnivariateLinearRegression.predict-386"><span class="linenos">386</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression.predict-387"><a href="#UnivariateLinearRegression.predict-387"><span class="linenos">387</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression.predict-388"><a href="#UnivariateLinearRegression.predict-388"><span class="linenos">388</span></a>
</span><span id="UnivariateLinearRegression.predict-389"><a href="#UnivariateLinearRegression.predict-389"><span class="linenos">389</span></a><span class="sd">        `X` : Union[np.ndarray, np.float64]</span>
</span><span id="UnivariateLinearRegression.predict-390"><a href="#UnivariateLinearRegression.predict-390"><span class="linenos">390</span></a><span class="sd">        - The input value or array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression.predict-391"><a href="#UnivariateLinearRegression.predict-391"><span class="linenos">391</span></a>
</span><span id="UnivariateLinearRegression.predict-392"><a href="#UnivariateLinearRegression.predict-392"><span class="linenos">392</span></a>
</span><span id="UnivariateLinearRegression.predict-393"><a href="#UnivariateLinearRegression.predict-393"><span class="linenos">393</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression.predict-394"><a href="#UnivariateLinearRegression.predict-394"><span class="linenos">394</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression.predict-395"><a href="#UnivariateLinearRegression.predict-395"><span class="linenos">395</span></a>
</span><span id="UnivariateLinearRegression.predict-396"><a href="#UnivariateLinearRegression.predict-396"><span class="linenos">396</span></a><span class="sd">        `Union[np.ndarray, np.float64]`</span>
</span><span id="UnivariateLinearRegression.predict-397"><a href="#UnivariateLinearRegression.predict-397"><span class="linenos">397</span></a><span class="sd">        - The predicted value or array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression.predict-398"><a href="#UnivariateLinearRegression.predict-398"><span class="linenos">398</span></a>
</span><span id="UnivariateLinearRegression.predict-399"><a href="#UnivariateLinearRegression.predict-399"><span class="linenos">399</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression.predict-400"><a href="#UnivariateLinearRegression.predict-400"><span class="linenos">400</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.predict-401"><a href="#UnivariateLinearRegression.predict-401"><span class="linenos">401</span></a>        <span class="c1"># Check if the model is trained</span>
</span><span id="UnivariateLinearRegression.predict-402"><a href="#UnivariateLinearRegression.predict-402"><span class="linenos">402</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span><span id="UnivariateLinearRegression.predict-403"><a href="#UnivariateLinearRegression.predict-403"><span class="linenos">403</span></a>            <span class="s2">&quot;The model must be trained before making predictions. &quot;</span>
</span><span id="UnivariateLinearRegression.predict-404"><a href="#UnivariateLinearRegression.predict-404"><span class="linenos">404</span></a>            <span class="s2">&quot;Call the fit method first.&quot;</span>
</span><span id="UnivariateLinearRegression.predict-405"><a href="#UnivariateLinearRegression.predict-405"><span class="linenos">405</span></a>        <span class="p">)</span>
</span><span id="UnivariateLinearRegression.predict-406"><a href="#UnivariateLinearRegression.predict-406"><span class="linenos">406</span></a>
</span><span id="UnivariateLinearRegression.predict-407"><a href="#UnivariateLinearRegression.predict-407"><span class="linenos">407</span></a>        <span class="n">isXScalar</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.predict-408"><a href="#UnivariateLinearRegression.predict-408"><span class="linenos">408</span></a>
</span><span id="UnivariateLinearRegression.predict-409"><a href="#UnivariateLinearRegression.predict-409"><span class="linenos">409</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="UnivariateLinearRegression.predict-410"><a href="#UnivariateLinearRegression.predict-410"><span class="linenos">410</span></a>            <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span>
</span><span id="UnivariateLinearRegression.predict-411"><a href="#UnivariateLinearRegression.predict-411"><span class="linenos">411</span></a>                <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
</span><span id="UnivariateLinearRegression.predict-412"><a href="#UnivariateLinearRegression.predict-412"><span class="linenos">412</span></a>            <span class="p">),</span> <span class="s2">&quot;X must be a 1D or 2D array with shape (n_samples,) or (n_samples, 1)&quot;</span>
</span><span id="UnivariateLinearRegression.predict-413"><a href="#UnivariateLinearRegression.predict-413"><span class="linenos">413</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.predict-414"><a href="#UnivariateLinearRegression.predict-414"><span class="linenos">414</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">X</span><span class="p">])</span>
</span><span id="UnivariateLinearRegression.predict-415"><a href="#UnivariateLinearRegression.predict-415"><span class="linenos">415</span></a>
</span><span id="UnivariateLinearRegression.predict-416"><a href="#UnivariateLinearRegression.predict-416"><span class="linenos">416</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.predict-417"><a href="#UnivariateLinearRegression.predict-417"><span class="linenos">417</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.predict-418"><a href="#UnivariateLinearRegression.predict-418"><span class="linenos">418</span></a>
</span><span id="UnivariateLinearRegression.predict-419"><a href="#UnivariateLinearRegression.predict-419"><span class="linenos">419</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span>
</span><span id="UnivariateLinearRegression.predict-420"><a href="#UnivariateLinearRegression.predict-420"><span class="linenos">420</span></a>
</span><span id="UnivariateLinearRegression.predict-421"><a href="#UnivariateLinearRegression.predict-421"><span class="linenos">421</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.predict-422"><a href="#UnivariateLinearRegression.predict-422"><span class="linenos">422</span></a>            <span class="n">predictions</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.predict-423"><a href="#UnivariateLinearRegression.predict-423"><span class="linenos">423</span></a>
</span><span id="UnivariateLinearRegression.predict-424"><a href="#UnivariateLinearRegression.predict-424"><span class="linenos">424</span></a>        <span class="k">return</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">isXScalar</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h3 id="return-the-predicted-value-of-y-given-x">Return the predicted value of y given x.</h3>

<h2 id="parameters">Parameters</h2>

<p><code>X</code> : Union[np.ndarray, np.float64]</p>

<ul>
<li>The input value or array of shape (n_samples,)</li>
</ul>

<h2 id="returns">Returns</h2>

<p><code>Union[np.ndarray, np.float64]</code></p>

<ul>
<li>The predicted value or array of shape (n_samples,)</li>
</ul>

<hr />
</div>


                            </div>
                            <div id="UnivariateLinearRegression.score" class="classattr">
                                        <input id="UnivariateLinearRegression.score-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">score</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">Y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">w</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">b</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span>:</span></span>

                <label class="view-source-button" for="UnivariateLinearRegression.score-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#UnivariateLinearRegression.score"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="UnivariateLinearRegression.score-426"><a href="#UnivariateLinearRegression.score-426"><span class="linenos">426</span></a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span>
</span><span id="UnivariateLinearRegression.score-427"><a href="#UnivariateLinearRegression.score-427"><span class="linenos">427</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="UnivariateLinearRegression.score-428"><a href="#UnivariateLinearRegression.score-428"><span class="linenos">428</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="UnivariateLinearRegression.score-429"><a href="#UnivariateLinearRegression.score-429"><span class="linenos">429</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.score-430"><a href="#UnivariateLinearRegression.score-430"><span class="linenos">430</span></a><span class="sd">        ### Return the cost function given X, Y, w, and b.</span>
</span><span id="UnivariateLinearRegression.score-431"><a href="#UnivariateLinearRegression.score-431"><span class="linenos">431</span></a>
</span><span id="UnivariateLinearRegression.score-432"><a href="#UnivariateLinearRegression.score-432"><span class="linenos">432</span></a><span class="sd">        Parameters</span>
</span><span id="UnivariateLinearRegression.score-433"><a href="#UnivariateLinearRegression.score-433"><span class="linenos">433</span></a><span class="sd">        ----------</span>
</span><span id="UnivariateLinearRegression.score-434"><a href="#UnivariateLinearRegression.score-434"><span class="linenos">434</span></a>
</span><span id="UnivariateLinearRegression.score-435"><a href="#UnivariateLinearRegression.score-435"><span class="linenos">435</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="UnivariateLinearRegression.score-436"><a href="#UnivariateLinearRegression.score-436"><span class="linenos">436</span></a><span class="sd">        - The input array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression.score-437"><a href="#UnivariateLinearRegression.score-437"><span class="linenos">437</span></a>
</span><span id="UnivariateLinearRegression.score-438"><a href="#UnivariateLinearRegression.score-438"><span class="linenos">438</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="UnivariateLinearRegression.score-439"><a href="#UnivariateLinearRegression.score-439"><span class="linenos">439</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="UnivariateLinearRegression.score-440"><a href="#UnivariateLinearRegression.score-440"><span class="linenos">440</span></a>
</span><span id="UnivariateLinearRegression.score-441"><a href="#UnivariateLinearRegression.score-441"><span class="linenos">441</span></a><span class="sd">        `w` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression.score-442"><a href="#UnivariateLinearRegression.score-442"><span class="linenos">442</span></a><span class="sd">        - The weight, by default None</span>
</span><span id="UnivariateLinearRegression.score-443"><a href="#UnivariateLinearRegression.score-443"><span class="linenos">443</span></a>
</span><span id="UnivariateLinearRegression.score-444"><a href="#UnivariateLinearRegression.score-444"><span class="linenos">444</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="UnivariateLinearRegression.score-445"><a href="#UnivariateLinearRegression.score-445"><span class="linenos">445</span></a><span class="sd">        - The intercept, by default None</span>
</span><span id="UnivariateLinearRegression.score-446"><a href="#UnivariateLinearRegression.score-446"><span class="linenos">446</span></a>
</span><span id="UnivariateLinearRegression.score-447"><a href="#UnivariateLinearRegression.score-447"><span class="linenos">447</span></a>
</span><span id="UnivariateLinearRegression.score-448"><a href="#UnivariateLinearRegression.score-448"><span class="linenos">448</span></a><span class="sd">        Returns</span>
</span><span id="UnivariateLinearRegression.score-449"><a href="#UnivariateLinearRegression.score-449"><span class="linenos">449</span></a><span class="sd">        -------</span>
</span><span id="UnivariateLinearRegression.score-450"><a href="#UnivariateLinearRegression.score-450"><span class="linenos">450</span></a>
</span><span id="UnivariateLinearRegression.score-451"><a href="#UnivariateLinearRegression.score-451"><span class="linenos">451</span></a><span class="sd">        `np.float64`</span>
</span><span id="UnivariateLinearRegression.score-452"><a href="#UnivariateLinearRegression.score-452"><span class="linenos">452</span></a><span class="sd">        - The computed cost</span>
</span><span id="UnivariateLinearRegression.score-453"><a href="#UnivariateLinearRegression.score-453"><span class="linenos">453</span></a>
</span><span id="UnivariateLinearRegression.score-454"><a href="#UnivariateLinearRegression.score-454"><span class="linenos">454</span></a><span class="sd">        ---</span>
</span><span id="UnivariateLinearRegression.score-455"><a href="#UnivariateLinearRegression.score-455"><span class="linenos">455</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="UnivariateLinearRegression.score-456"><a href="#UnivariateLinearRegression.score-456"><span class="linenos">456</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="UnivariateLinearRegression.score-457"><a href="#UnivariateLinearRegression.score-457"><span class="linenos">457</span></a>
</span><span id="UnivariateLinearRegression.score-458"><a href="#UnivariateLinearRegression.score-458"><span class="linenos">458</span></a>        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w</span>
</span><span id="UnivariateLinearRegression.score-459"><a href="#UnivariateLinearRegression.score-459"><span class="linenos">459</span></a>        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b</span>
</span><span id="UnivariateLinearRegression.score-460"><a href="#UnivariateLinearRegression.score-460"><span class="linenos">460</span></a>
</span><span id="UnivariateLinearRegression.score-461"><a href="#UnivariateLinearRegression.score-461"><span class="linenos">461</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h3 id="return-the-cost-function-given-x-y-w-and-b">Return the cost function given X, Y, w, and b.</h3>

<h2 id="parameters">Parameters</h2>

<p><code>X</code> : np.ndarray</p>

<ul>
<li>The input array of shape (n_samples,)</li>
</ul>

<p><code>Y</code> : np.ndarray</p>

<ul>
<li>The output array of shape (n_samples,)</li>
</ul>

<p><code>w</code> : np.float64, optional</p>

<ul>
<li>The weight, by default None</li>
</ul>

<p><code>b</code> : np.float64, optional</p>

<ul>
<li>The intercept, by default None</li>
</ul>

<h2 id="returns">Returns</h2>

<p><code>np.float64</code></p>

<ul>
<li>The computed cost</li>
</ul>

<hr />
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>learnML.interfaces.iregression.IRegression</dt>
                                <dd id="UnivariateLinearRegression.get_cost_history" class="function">get_cost_history</dd>
                <dd id="UnivariateLinearRegression.get_parameter_history" class="function">get_parameter_history</dd>
                <dd id="UnivariateLinearRegression.get_weights" class="function">get_weights</dd>
                <dd id="UnivariateLinearRegression.get_intercept" class="function">get_intercept</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="LinearRegression">
                            <input id="LinearRegression-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">LinearRegression</span><wbr>(<span class="base">learnML.interfaces.iregression.IRegression</span>):

                <label class="view-source-button" for="LinearRegression-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LinearRegression"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LinearRegression-9"><a href="#LinearRegression-9"><span class="linenos">  9</span></a><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">(</span><span class="n">IRegression</span><span class="p">):</span>
</span><span id="LinearRegression-10"><a href="#LinearRegression-10"><span class="linenos"> 10</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-11"><a href="#LinearRegression-11"><span class="linenos"> 11</span></a><span class="sd">    # Linear Regression Model</span>
</span><span id="LinearRegression-12"><a href="#LinearRegression-12"><span class="linenos"> 12</span></a>
</span><span id="LinearRegression-13"><a href="#LinearRegression-13"><span class="linenos"> 13</span></a><span class="sd">    Linear Regression is a fundamental supervised machine learning algorithm used to model the relationship between one or more independent variables and a continuous target variable. It serves as a cornerstone for predictive modeling and provides insights into how changes in input features affect the target variable. Linear Regression assumes that the target variable can be expressed as a linear combination of the input features, facilitating interpretation and prediction.</span>
</span><span id="LinearRegression-14"><a href="#LinearRegression-14"><span class="linenos"> 14</span></a>
</span><span id="LinearRegression-15"><a href="#LinearRegression-15"><span class="linenos"> 15</span></a><span class="sd">    ---</span>
</span><span id="LinearRegression-16"><a href="#LinearRegression-16"><span class="linenos"> 16</span></a>
</span><span id="LinearRegression-17"><a href="#LinearRegression-17"><span class="linenos"> 17</span></a><span class="sd">    ## Mathematical Approach</span>
</span><span id="LinearRegression-18"><a href="#LinearRegression-18"><span class="linenos"> 18</span></a>
</span><span id="LinearRegression-19"><a href="#LinearRegression-19"><span class="linenos"> 19</span></a><span class="sd">    Linear Regression aims to find the best-fitting linear equation that predicts the target variable. The equation takes the form:</span>
</span><span id="LinearRegression-20"><a href="#LinearRegression-20"><span class="linenos"> 20</span></a>
</span><span id="LinearRegression-21"><a href="#LinearRegression-21"><span class="linenos"> 21</span></a><span class="sd">    ```</span>
</span><span id="LinearRegression-22"><a href="#LinearRegression-22"><span class="linenos"> 22</span></a><span class="sd">    y = b + w1 * x1 + w2 * x2 + ... + wn * xn</span>
</span><span id="LinearRegression-23"><a href="#LinearRegression-23"><span class="linenos"> 23</span></a><span class="sd">    ```</span>
</span><span id="LinearRegression-24"><a href="#LinearRegression-24"><span class="linenos"> 24</span></a>
</span><span id="LinearRegression-25"><a href="#LinearRegression-25"><span class="linenos"> 25</span></a><span class="sd">    Where:</span>
</span><span id="LinearRegression-26"><a href="#LinearRegression-26"><span class="linenos"> 26</span></a>
</span><span id="LinearRegression-27"><a href="#LinearRegression-27"><span class="linenos"> 27</span></a><span class="sd">    - `y` is the predicted target variable.</span>
</span><span id="LinearRegression-28"><a href="#LinearRegression-28"><span class="linenos"> 28</span></a><span class="sd">    - `b` is the intercept (bias term).</span>
</span><span id="LinearRegression-29"><a href="#LinearRegression-29"><span class="linenos"> 29</span></a><span class="sd">    - `w1, w2, ..., wn` are the weights assigned to each input feature `x1, x2, ..., xn`.</span>
</span><span id="LinearRegression-30"><a href="#LinearRegression-30"><span class="linenos"> 30</span></a>
</span><span id="LinearRegression-31"><a href="#LinearRegression-31"><span class="linenos"> 31</span></a><span class="sd">    The goal of Linear Regression is to find the optimal values for `b` and the weights that minimize the difference between predicted and actual target values.</span>
</span><span id="LinearRegression-32"><a href="#LinearRegression-32"><span class="linenos"> 32</span></a>
</span><span id="LinearRegression-33"><a href="#LinearRegression-33"><span class="linenos"> 33</span></a><span class="sd">    ---</span>
</span><span id="LinearRegression-34"><a href="#LinearRegression-34"><span class="linenos"> 34</span></a>
</span><span id="LinearRegression-35"><a href="#LinearRegression-35"><span class="linenos"> 35</span></a><span class="sd">    ## Usage</span>
</span><span id="LinearRegression-36"><a href="#LinearRegression-36"><span class="linenos"> 36</span></a>
</span><span id="LinearRegression-37"><a href="#LinearRegression-37"><span class="linenos"> 37</span></a><span class="sd">    To use the Linear Regression model, follow these steps:</span>
</span><span id="LinearRegression-38"><a href="#LinearRegression-38"><span class="linenos"> 38</span></a>
</span><span id="LinearRegression-39"><a href="#LinearRegression-39"><span class="linenos"> 39</span></a><span class="sd">    1. Import the `LinearRegression` class from the appropriate module.</span>
</span><span id="LinearRegression-40"><a href="#LinearRegression-40"><span class="linenos"> 40</span></a><span class="sd">    2. Create an instance of the `LinearRegression` class, specifying hyperparameters.</span>
</span><span id="LinearRegression-41"><a href="#LinearRegression-41"><span class="linenos"> 41</span></a><span class="sd">    3. Fit the model to your training data using the `fit` method.</span>
</span><span id="LinearRegression-42"><a href="#LinearRegression-42"><span class="linenos"> 42</span></a><span class="sd">    4. Make predictions on new data using the `predict` method.</span>
</span><span id="LinearRegression-43"><a href="#LinearRegression-43"><span class="linenos"> 43</span></a><span class="sd">    5. Evaluate the model&#39;s performance using the `score` method.</span>
</span><span id="LinearRegression-44"><a href="#LinearRegression-44"><span class="linenos"> 44</span></a>
</span><span id="LinearRegression-45"><a href="#LinearRegression-45"><span class="linenos"> 45</span></a><span class="sd">    ```python</span>
</span><span id="LinearRegression-46"><a href="#LinearRegression-46"><span class="linenos"> 46</span></a><span class="sd">    from learnML.regression import LinearRegression</span>
</span><span id="LinearRegression-47"><a href="#LinearRegression-47"><span class="linenos"> 47</span></a>
</span><span id="LinearRegression-48"><a href="#LinearRegression-48"><span class="linenos"> 48</span></a><span class="sd">    # Create an instance of LinearRegression</span>
</span><span id="LinearRegression-49"><a href="#LinearRegression-49"><span class="linenos"> 49</span></a><span class="sd">    model = LinearRegression(learning_rate=0.01, n_iterations=1000)</span>
</span><span id="LinearRegression-50"><a href="#LinearRegression-50"><span class="linenos"> 50</span></a>
</span><span id="LinearRegression-51"><a href="#LinearRegression-51"><span class="linenos"> 51</span></a><span class="sd">    # Fit the model to training data</span>
</span><span id="LinearRegression-52"><a href="#LinearRegression-52"><span class="linenos"> 52</span></a><span class="sd">    model.fit(X_train, Y_train)</span>
</span><span id="LinearRegression-53"><a href="#LinearRegression-53"><span class="linenos"> 53</span></a>
</span><span id="LinearRegression-54"><a href="#LinearRegression-54"><span class="linenos"> 54</span></a><span class="sd">    # Make predictions on new data</span>
</span><span id="LinearRegression-55"><a href="#LinearRegression-55"><span class="linenos"> 55</span></a><span class="sd">    predictions = model.predict(X_test)</span>
</span><span id="LinearRegression-56"><a href="#LinearRegression-56"><span class="linenos"> 56</span></a>
</span><span id="LinearRegression-57"><a href="#LinearRegression-57"><span class="linenos"> 57</span></a><span class="sd">    # Calculate the model&#39;s score</span>
</span><span id="LinearRegression-58"><a href="#LinearRegression-58"><span class="linenos"> 58</span></a><span class="sd">    model_score = model.score(X_test, Y_test)</span>
</span><span id="LinearRegression-59"><a href="#LinearRegression-59"><span class="linenos"> 59</span></a><span class="sd">    ```</span>
</span><span id="LinearRegression-60"><a href="#LinearRegression-60"><span class="linenos"> 60</span></a>
</span><span id="LinearRegression-61"><a href="#LinearRegression-61"><span class="linenos"> 61</span></a><span class="sd">    ---</span>
</span><span id="LinearRegression-62"><a href="#LinearRegression-62"><span class="linenos"> 62</span></a>
</span><span id="LinearRegression-63"><a href="#LinearRegression-63"><span class="linenos"> 63</span></a><span class="sd">    ## Advantages</span>
</span><span id="LinearRegression-64"><a href="#LinearRegression-64"><span class="linenos"> 64</span></a>
</span><span id="LinearRegression-65"><a href="#LinearRegression-65"><span class="linenos"> 65</span></a><span class="sd">    - Easy to implement</span>
</span><span id="LinearRegression-66"><a href="#LinearRegression-66"><span class="linenos"> 66</span></a><span class="sd">    - Easy to interpret the output</span>
</span><span id="LinearRegression-67"><a href="#LinearRegression-67"><span class="linenos"> 67</span></a><span class="sd">    - Computationally cheap</span>
</span><span id="LinearRegression-68"><a href="#LinearRegression-68"><span class="linenos"> 68</span></a>
</span><span id="LinearRegression-69"><a href="#LinearRegression-69"><span class="linenos"> 69</span></a><span class="sd">    ## Disadvantages</span>
</span><span id="LinearRegression-70"><a href="#LinearRegression-70"><span class="linenos"> 70</span></a>
</span><span id="LinearRegression-71"><a href="#LinearRegression-71"><span class="linenos"> 71</span></a><span class="sd">    - Poor performance on non-linear data</span>
</span><span id="LinearRegression-72"><a href="#LinearRegression-72"><span class="linenos"> 72</span></a><span class="sd">    - Sensitive to outliers</span>
</span><span id="LinearRegression-73"><a href="#LinearRegression-73"><span class="linenos"> 73</span></a><span class="sd">    - Sensitive to overfitting</span>
</span><span id="LinearRegression-74"><a href="#LinearRegression-74"><span class="linenos"> 74</span></a>
</span><span id="LinearRegression-75"><a href="#LinearRegression-75"><span class="linenos"> 75</span></a><span class="sd">    ---</span>
</span><span id="LinearRegression-76"><a href="#LinearRegression-76"><span class="linenos"> 76</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="LinearRegression-77"><a href="#LinearRegression-77"><span class="linenos"> 77</span></a>
</span><span id="LinearRegression-78"><a href="#LinearRegression-78"><span class="linenos"> 78</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="LinearRegression-79"><a href="#LinearRegression-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LinearRegression-80"><a href="#LinearRegression-80"><span class="linenos"> 80</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="LinearRegression-81"><a href="#LinearRegression-81"><span class="linenos"> 81</span></a>        <span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="LinearRegression-82"><a href="#LinearRegression-82"><span class="linenos"> 82</span></a>        <span class="n">lambda_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="LinearRegression-83"><a href="#LinearRegression-83"><span class="linenos"> 83</span></a>        <span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LinearRegression-84"><a href="#LinearRegression-84"><span class="linenos"> 84</span></a>        <span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LinearRegression-85"><a href="#LinearRegression-85"><span class="linenos"> 85</span></a>        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="LinearRegression-86"><a href="#LinearRegression-86"><span class="linenos"> 86</span></a>        <span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="LinearRegression-87"><a href="#LinearRegression-87"><span class="linenos"> 87</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-88"><a href="#LinearRegression-88"><span class="linenos"> 88</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-89"><a href="#LinearRegression-89"><span class="linenos"> 89</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-90"><a href="#LinearRegression-90"><span class="linenos"> 90</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-91"><a href="#LinearRegression-91"><span class="linenos"> 91</span></a>
</span><span id="LinearRegression-92"><a href="#LinearRegression-92"><span class="linenos"> 92</span></a><span class="sd">        `learning_rate` : np.float64, optional</span>
</span><span id="LinearRegression-93"><a href="#LinearRegression-93"><span class="linenos"> 93</span></a><span class="sd">        - The learning rate, by default 0.001</span>
</span><span id="LinearRegression-94"><a href="#LinearRegression-94"><span class="linenos"> 94</span></a><span class="sd">        - The learning rate determines how much the weights are updated at each iteration</span>
</span><span id="LinearRegression-95"><a href="#LinearRegression-95"><span class="linenos"> 95</span></a><span class="sd">        - A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</span>
</span><span id="LinearRegression-96"><a href="#LinearRegression-96"><span class="linenos"> 96</span></a>
</span><span id="LinearRegression-97"><a href="#LinearRegression-97"><span class="linenos"> 97</span></a><span class="sd">        `n_iterations` : int, optional</span>
</span><span id="LinearRegression-98"><a href="#LinearRegression-98"><span class="linenos"> 98</span></a><span class="sd">        - The number of iterations, by default 1000</span>
</span><span id="LinearRegression-99"><a href="#LinearRegression-99"><span class="linenos"> 99</span></a><span class="sd">        - The number of iterations determines how many times the weights are updated</span>
</span><span id="LinearRegression-100"><a href="#LinearRegression-100"><span class="linenos">100</span></a><span class="sd">        - A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</span>
</span><span id="LinearRegression-101"><a href="#LinearRegression-101"><span class="linenos">101</span></a>
</span><span id="LinearRegression-102"><a href="#LinearRegression-102"><span class="linenos">102</span></a><span class="sd">        `lambda_` : np.float64, optional</span>
</span><span id="LinearRegression-103"><a href="#LinearRegression-103"><span class="linenos">103</span></a><span class="sd">        - The regularization parameter, by default 0</span>
</span><span id="LinearRegression-104"><a href="#LinearRegression-104"><span class="linenos">104</span></a><span class="sd">        - The regularization parameter helps prevent overfitting by penalizing large weights</span>
</span><span id="LinearRegression-105"><a href="#LinearRegression-105"><span class="linenos">105</span></a><span class="sd">        - A higher regularization parameter will penalize large weights more, but a lower regularization parameter may not be enough to prevent overfitting</span>
</span><span id="LinearRegression-106"><a href="#LinearRegression-106"><span class="linenos">106</span></a>
</span><span id="LinearRegression-107"><a href="#LinearRegression-107"><span class="linenos">107</span></a><span class="sd">        `x_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="LinearRegression-108"><a href="#LinearRegression-108"><span class="linenos">108</span></a><span class="sd">        - The feature engineering for the input data, by default None</span>
</span><span id="LinearRegression-109"><a href="#LinearRegression-109"><span class="linenos">109</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="LinearRegression-110"><a href="#LinearRegression-110"><span class="linenos">110</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all input data</span>
</span><span id="LinearRegression-111"><a href="#LinearRegression-111"><span class="linenos">111</span></a>
</span><span id="LinearRegression-112"><a href="#LinearRegression-112"><span class="linenos">112</span></a><span class="sd">        `y_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="LinearRegression-113"><a href="#LinearRegression-113"><span class="linenos">113</span></a><span class="sd">        - The feature engineering for the output data, by default None</span>
</span><span id="LinearRegression-114"><a href="#LinearRegression-114"><span class="linenos">114</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="LinearRegression-115"><a href="#LinearRegression-115"><span class="linenos">115</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all output data</span>
</span><span id="LinearRegression-116"><a href="#LinearRegression-116"><span class="linenos">116</span></a>
</span><span id="LinearRegression-117"><a href="#LinearRegression-117"><span class="linenos">117</span></a><span class="sd">        `debug` : bool, optional</span>
</span><span id="LinearRegression-118"><a href="#LinearRegression-118"><span class="linenos">118</span></a><span class="sd">        - Whether to print debug messages, by default True</span>
</span><span id="LinearRegression-119"><a href="#LinearRegression-119"><span class="linenos">119</span></a><span class="sd">        - Debug messages include the cost at each iteration</span>
</span><span id="LinearRegression-120"><a href="#LinearRegression-120"><span class="linenos">120</span></a>
</span><span id="LinearRegression-121"><a href="#LinearRegression-121"><span class="linenos">121</span></a><span class="sd">        `copy_x` : bool, optional</span>
</span><span id="LinearRegression-122"><a href="#LinearRegression-122"><span class="linenos">122</span></a><span class="sd">        - Whether to copy the input array, by default True</span>
</span><span id="LinearRegression-123"><a href="#LinearRegression-123"><span class="linenos">123</span></a><span class="sd">        - If False, the input array will be overwritten</span>
</span><span id="LinearRegression-124"><a href="#LinearRegression-124"><span class="linenos">124</span></a>
</span><span id="LinearRegression-125"><a href="#LinearRegression-125"><span class="linenos">125</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-126"><a href="#LinearRegression-126"><span class="linenos">126</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-127"><a href="#LinearRegression-127"><span class="linenos">127</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="LinearRegression-128"><a href="#LinearRegression-128"><span class="linenos">128</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LinearRegression-129"><a href="#LinearRegression-129"><span class="linenos">129</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="LinearRegression-130"><a href="#LinearRegression-130"><span class="linenos">130</span></a>            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
</span><span id="LinearRegression-131"><a href="#LinearRegression-131"><span class="linenos">131</span></a>            <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
</span><span id="LinearRegression-132"><a href="#LinearRegression-132"><span class="linenos">132</span></a>        <span class="p">)</span>
</span><span id="LinearRegression-133"><a href="#LinearRegression-133"><span class="linenos">133</span></a>
</span><span id="LinearRegression-134"><a href="#LinearRegression-134"><span class="linenos">134</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_lambda</span> <span class="o">=</span> <span class="n">lambda_</span>
</span><span id="LinearRegression-135"><a href="#LinearRegression-135"><span class="linenos">135</span></a>
</span><span id="LinearRegression-136"><a href="#LinearRegression-136"><span class="linenos">136</span></a>        <span class="k">if</span> <span class="n">x_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-137"><a href="#LinearRegression-137"><span class="linenos">137</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="LinearRegression-138"><a href="#LinearRegression-138"><span class="linenos">138</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="LinearRegression-139"><a href="#LinearRegression-139"><span class="linenos">139</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_scalar</span><span class="p">]</span>
</span><span id="LinearRegression-140"><a href="#LinearRegression-140"><span class="linenos">140</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span> <span class="o">=</span> <span class="n">x_scalar</span>
</span><span id="LinearRegression-141"><a href="#LinearRegression-141"><span class="linenos">141</span></a>
</span><span id="LinearRegression-142"><a href="#LinearRegression-142"><span class="linenos">142</span></a>        <span class="k">if</span> <span class="n">y_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-143"><a href="#LinearRegression-143"><span class="linenos">143</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="LinearRegression-144"><a href="#LinearRegression-144"><span class="linenos">144</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="LinearRegression-145"><a href="#LinearRegression-145"><span class="linenos">145</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_scalar</span><span class="p">]</span>
</span><span id="LinearRegression-146"><a href="#LinearRegression-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span> <span class="o">=</span> <span class="n">y_scalar</span>
</span><span id="LinearRegression-147"><a href="#LinearRegression-147"><span class="linenos">147</span></a>
</span><span id="LinearRegression-148"><a href="#LinearRegression-148"><span class="linenos">148</span></a>    <span class="k">def</span> <span class="nf">_y_hat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="LinearRegression-149"><a href="#LinearRegression-149"><span class="linenos">149</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-150"><a href="#LinearRegression-150"><span class="linenos">150</span></a><span class="sd">        ### Return the predicted value of y given x, w, and b.</span>
</span><span id="LinearRegression-151"><a href="#LinearRegression-151"><span class="linenos">151</span></a>
</span><span id="LinearRegression-152"><a href="#LinearRegression-152"><span class="linenos">152</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-153"><a href="#LinearRegression-153"><span class="linenos">153</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-154"><a href="#LinearRegression-154"><span class="linenos">154</span></a>
</span><span id="LinearRegression-155"><a href="#LinearRegression-155"><span class="linenos">155</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-156"><a href="#LinearRegression-156"><span class="linenos">156</span></a><span class="sd">        - The input array of shape (n_features,)</span>
</span><span id="LinearRegression-157"><a href="#LinearRegression-157"><span class="linenos">157</span></a>
</span><span id="LinearRegression-158"><a href="#LinearRegression-158"><span class="linenos">158</span></a><span class="sd">        `W` : np.ndarray</span>
</span><span id="LinearRegression-159"><a href="#LinearRegression-159"><span class="linenos">159</span></a><span class="sd">        - The weight array of shape (n_features,)</span>
</span><span id="LinearRegression-160"><a href="#LinearRegression-160"><span class="linenos">160</span></a>
</span><span id="LinearRegression-161"><a href="#LinearRegression-161"><span class="linenos">161</span></a><span class="sd">        `b` : np.float64</span>
</span><span id="LinearRegression-162"><a href="#LinearRegression-162"><span class="linenos">162</span></a><span class="sd">        - The intercept</span>
</span><span id="LinearRegression-163"><a href="#LinearRegression-163"><span class="linenos">163</span></a>
</span><span id="LinearRegression-164"><a href="#LinearRegression-164"><span class="linenos">164</span></a>
</span><span id="LinearRegression-165"><a href="#LinearRegression-165"><span class="linenos">165</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-166"><a href="#LinearRegression-166"><span class="linenos">166</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-167"><a href="#LinearRegression-167"><span class="linenos">167</span></a>
</span><span id="LinearRegression-168"><a href="#LinearRegression-168"><span class="linenos">168</span></a><span class="sd">        `np.float64`</span>
</span><span id="LinearRegression-169"><a href="#LinearRegression-169"><span class="linenos">169</span></a><span class="sd">        - The predicted value of y</span>
</span><span id="LinearRegression-170"><a href="#LinearRegression-170"><span class="linenos">170</span></a>
</span><span id="LinearRegression-171"><a href="#LinearRegression-171"><span class="linenos">171</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-172"><a href="#LinearRegression-172"><span class="linenos">172</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-173"><a href="#LinearRegression-173"><span class="linenos">173</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</span><span id="LinearRegression-174"><a href="#LinearRegression-174"><span class="linenos">174</span></a>
</span><span id="LinearRegression-175"><a href="#LinearRegression-175"><span class="linenos">175</span></a>    <span class="k">def</span> <span class="nf">_cost</span><span class="p">(</span>
</span><span id="LinearRegression-176"><a href="#LinearRegression-176"><span class="linenos">176</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span>
</span><span id="LinearRegression-177"><a href="#LinearRegression-177"><span class="linenos">177</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="LinearRegression-178"><a href="#LinearRegression-178"><span class="linenos">178</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-179"><a href="#LinearRegression-179"><span class="linenos">179</span></a><span class="sd">        ### Return the cost function given X, Y, w, and b.</span>
</span><span id="LinearRegression-180"><a href="#LinearRegression-180"><span class="linenos">180</span></a>
</span><span id="LinearRegression-181"><a href="#LinearRegression-181"><span class="linenos">181</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-182"><a href="#LinearRegression-182"><span class="linenos">182</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-183"><a href="#LinearRegression-183"><span class="linenos">183</span></a>
</span><span id="LinearRegression-184"><a href="#LinearRegression-184"><span class="linenos">184</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-185"><a href="#LinearRegression-185"><span class="linenos">185</span></a><span class="sd">        - The input array of shape (n_samples, n_features)</span>
</span><span id="LinearRegression-186"><a href="#LinearRegression-186"><span class="linenos">186</span></a>
</span><span id="LinearRegression-187"><a href="#LinearRegression-187"><span class="linenos">187</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="LinearRegression-188"><a href="#LinearRegression-188"><span class="linenos">188</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="LinearRegression-189"><a href="#LinearRegression-189"><span class="linenos">189</span></a>
</span><span id="LinearRegression-190"><a href="#LinearRegression-190"><span class="linenos">190</span></a><span class="sd">        `W` : np.ndarray</span>
</span><span id="LinearRegression-191"><a href="#LinearRegression-191"><span class="linenos">191</span></a><span class="sd">        - The weight array of shape (n_features,)</span>
</span><span id="LinearRegression-192"><a href="#LinearRegression-192"><span class="linenos">192</span></a>
</span><span id="LinearRegression-193"><a href="#LinearRegression-193"><span class="linenos">193</span></a><span class="sd">        `b` : np.float64</span>
</span><span id="LinearRegression-194"><a href="#LinearRegression-194"><span class="linenos">194</span></a><span class="sd">        - The intercept</span>
</span><span id="LinearRegression-195"><a href="#LinearRegression-195"><span class="linenos">195</span></a>
</span><span id="LinearRegression-196"><a href="#LinearRegression-196"><span class="linenos">196</span></a>
</span><span id="LinearRegression-197"><a href="#LinearRegression-197"><span class="linenos">197</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-198"><a href="#LinearRegression-198"><span class="linenos">198</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-199"><a href="#LinearRegression-199"><span class="linenos">199</span></a>
</span><span id="LinearRegression-200"><a href="#LinearRegression-200"><span class="linenos">200</span></a><span class="sd">        `np.float64`</span>
</span><span id="LinearRegression-201"><a href="#LinearRegression-201"><span class="linenos">201</span></a><span class="sd">        - The computed cost</span>
</span><span id="LinearRegression-202"><a href="#LinearRegression-202"><span class="linenos">202</span></a>
</span><span id="LinearRegression-203"><a href="#LinearRegression-203"><span class="linenos">203</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-204"><a href="#LinearRegression-204"><span class="linenos">204</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-205"><a href="#LinearRegression-205"><span class="linenos">205</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-206"><a href="#LinearRegression-206"><span class="linenos">206</span></a><span class="sd">        ALTERNATIVE IMPLEMENTATION</span>
</span><span id="LinearRegression-207"><a href="#LinearRegression-207"><span class="linenos">207</span></a><span class="sd">        --------------------------</span>
</span><span id="LinearRegression-208"><a href="#LinearRegression-208"><span class="linenos">208</span></a><span class="sd">        m = X.shape[0]</span>
</span><span id="LinearRegression-209"><a href="#LinearRegression-209"><span class="linenos">209</span></a><span class="sd">        cost = 0.0</span>
</span><span id="LinearRegression-210"><a href="#LinearRegression-210"><span class="linenos">210</span></a>
</span><span id="LinearRegression-211"><a href="#LinearRegression-211"><span class="linenos">211</span></a><span class="sd">        for i in range(m):</span>
</span><span id="LinearRegression-212"><a href="#LinearRegression-212"><span class="linenos">212</span></a><span class="sd">            cost += (self._y_hat(X[i], W, b) - Y[i]) ** 2</span>
</span><span id="LinearRegression-213"><a href="#LinearRegression-213"><span class="linenos">213</span></a>
</span><span id="LinearRegression-214"><a href="#LinearRegression-214"><span class="linenos">214</span></a><span class="sd">        return cost / (2 * m)</span>
</span><span id="LinearRegression-215"><a href="#LinearRegression-215"><span class="linenos">215</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-216"><a href="#LinearRegression-216"><span class="linenos">216</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LinearRegression-217"><a href="#LinearRegression-217"><span class="linenos">217</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span>
</span><span id="LinearRegression-218"><a href="#LinearRegression-218"><span class="linenos">218</span></a>
</span><span id="LinearRegression-219"><a href="#LinearRegression-219"><span class="linenos">219</span></a>    <span class="k">def</span> <span class="nf">_gradient</span><span class="p">(</span>
</span><span id="LinearRegression-220"><a href="#LinearRegression-220"><span class="linenos">220</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span>
</span><span id="LinearRegression-221"><a href="#LinearRegression-221"><span class="linenos">221</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
</span><span id="LinearRegression-222"><a href="#LinearRegression-222"><span class="linenos">222</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-223"><a href="#LinearRegression-223"><span class="linenos">223</span></a><span class="sd">        ### Return the gradient of the cost function given X, Y, w, and b.</span>
</span><span id="LinearRegression-224"><a href="#LinearRegression-224"><span class="linenos">224</span></a>
</span><span id="LinearRegression-225"><a href="#LinearRegression-225"><span class="linenos">225</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-226"><a href="#LinearRegression-226"><span class="linenos">226</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-227"><a href="#LinearRegression-227"><span class="linenos">227</span></a>
</span><span id="LinearRegression-228"><a href="#LinearRegression-228"><span class="linenos">228</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-229"><a href="#LinearRegression-229"><span class="linenos">229</span></a><span class="sd">        - The input array of shape (n_samples, n_features)</span>
</span><span id="LinearRegression-230"><a href="#LinearRegression-230"><span class="linenos">230</span></a>
</span><span id="LinearRegression-231"><a href="#LinearRegression-231"><span class="linenos">231</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="LinearRegression-232"><a href="#LinearRegression-232"><span class="linenos">232</span></a><span class="sd">        - The output array of shape (n_samples,)</span>
</span><span id="LinearRegression-233"><a href="#LinearRegression-233"><span class="linenos">233</span></a>
</span><span id="LinearRegression-234"><a href="#LinearRegression-234"><span class="linenos">234</span></a><span class="sd">        `W` : np.ndarray</span>
</span><span id="LinearRegression-235"><a href="#LinearRegression-235"><span class="linenos">235</span></a><span class="sd">        - The weight array of shape (n_features,)</span>
</span><span id="LinearRegression-236"><a href="#LinearRegression-236"><span class="linenos">236</span></a>
</span><span id="LinearRegression-237"><a href="#LinearRegression-237"><span class="linenos">237</span></a><span class="sd">        `b` : np.float64</span>
</span><span id="LinearRegression-238"><a href="#LinearRegression-238"><span class="linenos">238</span></a><span class="sd">        - The intercept</span>
</span><span id="LinearRegression-239"><a href="#LinearRegression-239"><span class="linenos">239</span></a>
</span><span id="LinearRegression-240"><a href="#LinearRegression-240"><span class="linenos">240</span></a>
</span><span id="LinearRegression-241"><a href="#LinearRegression-241"><span class="linenos">241</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-242"><a href="#LinearRegression-242"><span class="linenos">242</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-243"><a href="#LinearRegression-243"><span class="linenos">243</span></a>
</span><span id="LinearRegression-244"><a href="#LinearRegression-244"><span class="linenos">244</span></a><span class="sd">        `Tuple[np.ndarray, np.float64]`</span>
</span><span id="LinearRegression-245"><a href="#LinearRegression-245"><span class="linenos">245</span></a><span class="sd">        - The computed gradient</span>
</span><span id="LinearRegression-246"><a href="#LinearRegression-246"><span class="linenos">246</span></a>
</span><span id="LinearRegression-247"><a href="#LinearRegression-247"><span class="linenos">247</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-248"><a href="#LinearRegression-248"><span class="linenos">248</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-249"><a href="#LinearRegression-249"><span class="linenos">249</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-250"><a href="#LinearRegression-250"><span class="linenos">250</span></a><span class="sd">        ALTERNATIVE IMPLEMENTATION</span>
</span><span id="LinearRegression-251"><a href="#LinearRegression-251"><span class="linenos">251</span></a><span class="sd">        --------------------------</span>
</span><span id="LinearRegression-252"><a href="#LinearRegression-252"><span class="linenos">252</span></a><span class="sd">        m, n = X.shape</span>
</span><span id="LinearRegression-253"><a href="#LinearRegression-253"><span class="linenos">253</span></a>
</span><span id="LinearRegression-254"><a href="#LinearRegression-254"><span class="linenos">254</span></a><span class="sd">        dw = np.zeros((n,))</span>
</span><span id="LinearRegression-255"><a href="#LinearRegression-255"><span class="linenos">255</span></a><span class="sd">        db = 0.0</span>
</span><span id="LinearRegression-256"><a href="#LinearRegression-256"><span class="linenos">256</span></a>
</span><span id="LinearRegression-257"><a href="#LinearRegression-257"><span class="linenos">257</span></a><span class="sd">        for i in range(m):</span>
</span><span id="LinearRegression-258"><a href="#LinearRegression-258"><span class="linenos">258</span></a><span class="sd">            dw += (self._y_hat(X[i], W, b) - Y[i]) * X[i]</span>
</span><span id="LinearRegression-259"><a href="#LinearRegression-259"><span class="linenos">259</span></a><span class="sd">            db += self._y_hat(X[i], W, b) - Y[i]</span>
</span><span id="LinearRegression-260"><a href="#LinearRegression-260"><span class="linenos">260</span></a>
</span><span id="LinearRegression-261"><a href="#LinearRegression-261"><span class="linenos">261</span></a><span class="sd">        return dw / m, db / m</span>
</span><span id="LinearRegression-262"><a href="#LinearRegression-262"><span class="linenos">262</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-263"><a href="#LinearRegression-263"><span class="linenos">263</span></a>        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LinearRegression-264"><a href="#LinearRegression-264"><span class="linenos">264</span></a>        <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
</span><span id="LinearRegression-265"><a href="#LinearRegression-265"><span class="linenos">265</span></a>        <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
</span><span id="LinearRegression-266"><a href="#LinearRegression-266"><span class="linenos">266</span></a>        <span class="k">return</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span>
</span><span id="LinearRegression-267"><a href="#LinearRegression-267"><span class="linenos">267</span></a>
</span><span id="LinearRegression-268"><a href="#LinearRegression-268"><span class="linenos">268</span></a>    <span class="k">def</span> <span class="nf">_validate_data</span><span class="p">(</span>
</span><span id="LinearRegression-269"><a href="#LinearRegression-269"><span class="linenos">269</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LinearRegression-270"><a href="#LinearRegression-270"><span class="linenos">270</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="LinearRegression-271"><a href="#LinearRegression-271"><span class="linenos">271</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-272"><a href="#LinearRegression-272"><span class="linenos">272</span></a><span class="sd">        ### Return the input and output arrays.</span>
</span><span id="LinearRegression-273"><a href="#LinearRegression-273"><span class="linenos">273</span></a>
</span><span id="LinearRegression-274"><a href="#LinearRegression-274"><span class="linenos">274</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-275"><a href="#LinearRegression-275"><span class="linenos">275</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-276"><a href="#LinearRegression-276"><span class="linenos">276</span></a>
</span><span id="LinearRegression-277"><a href="#LinearRegression-277"><span class="linenos">277</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-278"><a href="#LinearRegression-278"><span class="linenos">278</span></a><span class="sd">        - The input array of shape (n_samples, n_features)</span>
</span><span id="LinearRegression-279"><a href="#LinearRegression-279"><span class="linenos">279</span></a>
</span><span id="LinearRegression-280"><a href="#LinearRegression-280"><span class="linenos">280</span></a><span class="sd">        `Y` : np.ndarray, optional</span>
</span><span id="LinearRegression-281"><a href="#LinearRegression-281"><span class="linenos">281</span></a><span class="sd">        - The output array of shape (n_samples,) or (n_samples, 1)</span>
</span><span id="LinearRegression-282"><a href="#LinearRegression-282"><span class="linenos">282</span></a>
</span><span id="LinearRegression-283"><a href="#LinearRegression-283"><span class="linenos">283</span></a>
</span><span id="LinearRegression-284"><a href="#LinearRegression-284"><span class="linenos">284</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-285"><a href="#LinearRegression-285"><span class="linenos">285</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-286"><a href="#LinearRegression-286"><span class="linenos">286</span></a>
</span><span id="LinearRegression-287"><a href="#LinearRegression-287"><span class="linenos">287</span></a><span class="sd">        `Tuple[np.ndarray, np.ndarray]`</span>
</span><span id="LinearRegression-288"><a href="#LinearRegression-288"><span class="linenos">288</span></a><span class="sd">        - The input and output arrays</span>
</span><span id="LinearRegression-289"><a href="#LinearRegression-289"><span class="linenos">289</span></a>
</span><span id="LinearRegression-290"><a href="#LinearRegression-290"><span class="linenos">290</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-291"><a href="#LinearRegression-291"><span class="linenos">291</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-292"><a href="#LinearRegression-292"><span class="linenos">292</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_copy_x</span><span class="p">:</span>
</span><span id="LinearRegression-293"><a href="#LinearRegression-293"><span class="linenos">293</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LinearRegression-294"><a href="#LinearRegression-294"><span class="linenos">294</span></a>
</span><span id="LinearRegression-295"><a href="#LinearRegression-295"><span class="linenos">295</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_numpy_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LinearRegression-296"><a href="#LinearRegression-296"><span class="linenos">296</span></a>        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_numpy_array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="LinearRegression-297"><a href="#LinearRegression-297"><span class="linenos">297</span></a>
</span><span id="LinearRegression-298"><a href="#LinearRegression-298"><span class="linenos">298</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-299"><a href="#LinearRegression-299"><span class="linenos">299</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="LinearRegression-300"><a href="#LinearRegression-300"><span class="linenos">300</span></a>                <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="LinearRegression-301"><a href="#LinearRegression-301"><span class="linenos">301</span></a>            <span class="p">),</span> <span class="s2">&quot;X and Y must have the same number of samples&quot;</span>
</span><span id="LinearRegression-302"><a href="#LinearRegression-302"><span class="linenos">302</span></a>
</span><span id="LinearRegression-303"><a href="#LinearRegression-303"><span class="linenos">303</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LinearRegression-304"><a href="#LinearRegression-304"><span class="linenos">304</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="LinearRegression-305"><a href="#LinearRegression-305"><span class="linenos">305</span></a>
</span><span id="LinearRegression-306"><a href="#LinearRegression-306"><span class="linenos">306</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span><span class="p">:</span>
</span><span id="LinearRegression-307"><a href="#LinearRegression-307"><span class="linenos">307</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LinearRegression-308"><a href="#LinearRegression-308"><span class="linenos">308</span></a>
</span><span id="LinearRegression-309"><a href="#LinearRegression-309"><span class="linenos">309</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-310"><a href="#LinearRegression-310"><span class="linenos">310</span></a>            <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="LinearRegression-311"><a href="#LinearRegression-311"><span class="linenos">311</span></a>                <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="LinearRegression-312"><a href="#LinearRegression-312"><span class="linenos">312</span></a>
</span><span id="LinearRegression-313"><a href="#LinearRegression-313"><span class="linenos">313</span></a>            <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="LinearRegression-314"><a href="#LinearRegression-314"><span class="linenos">314</span></a>                <span class="n">Y</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</span><span id="LinearRegression-315"><a href="#LinearRegression-315"><span class="linenos">315</span></a>
</span><span id="LinearRegression-316"><a href="#LinearRegression-316"><span class="linenos">316</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-317"><a href="#LinearRegression-317"><span class="linenos">317</span></a>            <span class="k">return</span> <span class="n">X</span>
</span><span id="LinearRegression-318"><a href="#LinearRegression-318"><span class="linenos">318</span></a>        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</span><span id="LinearRegression-319"><a href="#LinearRegression-319"><span class="linenos">319</span></a>
</span><span id="LinearRegression-320"><a href="#LinearRegression-320"><span class="linenos">320</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
</span><span id="LinearRegression-321"><a href="#LinearRegression-321"><span class="linenos">321</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="LinearRegression-322"><a href="#LinearRegression-322"><span class="linenos">322</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression-323"><a href="#LinearRegression-323"><span class="linenos">323</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-324"><a href="#LinearRegression-324"><span class="linenos">324</span></a><span class="sd">        ### Train the model given X and Y.</span>
</span><span id="LinearRegression-325"><a href="#LinearRegression-325"><span class="linenos">325</span></a>
</span><span id="LinearRegression-326"><a href="#LinearRegression-326"><span class="linenos">326</span></a>
</span><span id="LinearRegression-327"><a href="#LinearRegression-327"><span class="linenos">327</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-328"><a href="#LinearRegression-328"><span class="linenos">328</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-329"><a href="#LinearRegression-329"><span class="linenos">329</span></a>
</span><span id="LinearRegression-330"><a href="#LinearRegression-330"><span class="linenos">330</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-331"><a href="#LinearRegression-331"><span class="linenos">331</span></a><span class="sd">        - The input array of shape (n_samples, n_features) or (n_samples,)</span>
</span><span id="LinearRegression-332"><a href="#LinearRegression-332"><span class="linenos">332</span></a><span class="sd">        - If the shape is (n_samples,), then the model will be trained as a</span>
</span><span id="LinearRegression-333"><a href="#LinearRegression-333"><span class="linenos">333</span></a><span class="sd">            univariate linear regression model</span>
</span><span id="LinearRegression-334"><a href="#LinearRegression-334"><span class="linenos">334</span></a><span class="sd">        - If the shape is (n_samples, n_features), then the model will be</span>
</span><span id="LinearRegression-335"><a href="#LinearRegression-335"><span class="linenos">335</span></a><span class="sd">            trained as a multivariate linear regression model</span>
</span><span id="LinearRegression-336"><a href="#LinearRegression-336"><span class="linenos">336</span></a>
</span><span id="LinearRegression-337"><a href="#LinearRegression-337"><span class="linenos">337</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="LinearRegression-338"><a href="#LinearRegression-338"><span class="linenos">338</span></a><span class="sd">        - The output array of shape (n_samples,) or (n_samples, 1)</span>
</span><span id="LinearRegression-339"><a href="#LinearRegression-339"><span class="linenos">339</span></a>
</span><span id="LinearRegression-340"><a href="#LinearRegression-340"><span class="linenos">340</span></a><span class="sd">        `w` : np.ndarray, optional</span>
</span><span id="LinearRegression-341"><a href="#LinearRegression-341"><span class="linenos">341</span></a><span class="sd">        - The weight array, by default None</span>
</span><span id="LinearRegression-342"><a href="#LinearRegression-342"><span class="linenos">342</span></a><span class="sd">        - If None, then the weight array will be initialized to an array of</span>
</span><span id="LinearRegression-343"><a href="#LinearRegression-343"><span class="linenos">343</span></a><span class="sd">            zeros of shape (n_features,)</span>
</span><span id="LinearRegression-344"><a href="#LinearRegression-344"><span class="linenos">344</span></a><span class="sd">        - If not None, then the weight array will be initialized to the given</span>
</span><span id="LinearRegression-345"><a href="#LinearRegression-345"><span class="linenos">345</span></a><span class="sd">            array</span>
</span><span id="LinearRegression-346"><a href="#LinearRegression-346"><span class="linenos">346</span></a>
</span><span id="LinearRegression-347"><a href="#LinearRegression-347"><span class="linenos">347</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="LinearRegression-348"><a href="#LinearRegression-348"><span class="linenos">348</span></a><span class="sd">        - The intercept, by default 0</span>
</span><span id="LinearRegression-349"><a href="#LinearRegression-349"><span class="linenos">349</span></a><span class="sd">        - If None, then the intercept will be initialized to 0</span>
</span><span id="LinearRegression-350"><a href="#LinearRegression-350"><span class="linenos">350</span></a><span class="sd">        - If not None, then the intercept will be initialized to the given</span>
</span><span id="LinearRegression-351"><a href="#LinearRegression-351"><span class="linenos">351</span></a><span class="sd">            value</span>
</span><span id="LinearRegression-352"><a href="#LinearRegression-352"><span class="linenos">352</span></a>
</span><span id="LinearRegression-353"><a href="#LinearRegression-353"><span class="linenos">353</span></a>
</span><span id="LinearRegression-354"><a href="#LinearRegression-354"><span class="linenos">354</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-355"><a href="#LinearRegression-355"><span class="linenos">355</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-356"><a href="#LinearRegression-356"><span class="linenos">356</span></a>
</span><span id="LinearRegression-357"><a href="#LinearRegression-357"><span class="linenos">357</span></a><span class="sd">        None</span>
</span><span id="LinearRegression-358"><a href="#LinearRegression-358"><span class="linenos">358</span></a>
</span><span id="LinearRegression-359"><a href="#LinearRegression-359"><span class="linenos">359</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-360"><a href="#LinearRegression-360"><span class="linenos">360</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-361"><a href="#LinearRegression-361"><span class="linenos">361</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="LinearRegression-362"><a href="#LinearRegression-362"><span class="linenos">362</span></a>
</span><span id="LinearRegression-363"><a href="#LinearRegression-363"><span class="linenos">363</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">W</span>
</span><span id="LinearRegression-364"><a href="#LinearRegression-364"><span class="linenos">364</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">=</span> <span class="n">b</span>
</span><span id="LinearRegression-365"><a href="#LinearRegression-365"><span class="linenos">365</span></a>
</span><span id="LinearRegression-366"><a href="#LinearRegression-366"><span class="linenos">366</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="LinearRegression-367"><a href="#LinearRegression-367"><span class="linenos">367</span></a>            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)]</span>
</span><span id="LinearRegression-368"><a href="#LinearRegression-368"><span class="linenos">368</span></a>        <span class="p">)</span>
</span><span id="LinearRegression-369"><a href="#LinearRegression-369"><span class="linenos">369</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="LinearRegression-370"><a href="#LinearRegression-370"><span class="linenos">370</span></a>            <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span>
</span><span id="LinearRegression-371"><a href="#LinearRegression-371"><span class="linenos">371</span></a>        <span class="p">)</span>
</span><span id="LinearRegression-372"><a href="#LinearRegression-372"><span class="linenos">372</span></a>
</span><span id="LinearRegression-373"><a href="#LinearRegression-373"><span class="linenos">373</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">):</span>
</span><span id="LinearRegression-374"><a href="#LinearRegression-374"><span class="linenos">374</span></a>            <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="LinearRegression-375"><a href="#LinearRegression-375"><span class="linenos">375</span></a>
</span><span id="LinearRegression-376"><a href="#LinearRegression-376"><span class="linenos">376</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
</span><span id="LinearRegression-377"><a href="#LinearRegression-377"><span class="linenos">377</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
</span><span id="LinearRegression-378"><a href="#LinearRegression-378"><span class="linenos">378</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">db</span>
</span><span id="LinearRegression-379"><a href="#LinearRegression-379"><span class="linenos">379</span></a>
</span><span id="LinearRegression-380"><a href="#LinearRegression-380"><span class="linenos">380</span></a>            <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="LinearRegression-381"><a href="#LinearRegression-381"><span class="linenos">381</span></a>
</span><span id="LinearRegression-382"><a href="#LinearRegression-382"><span class="linenos">382</span></a>            <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="ow">or</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
</span><span id="LinearRegression-383"><a href="#LinearRegression-383"><span class="linenos">383</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="LinearRegression-384"><a href="#LinearRegression-384"><span class="linenos">384</span></a>                    <span class="s2">&quot;Gradient descent failed. Try normalizing the input array or reducing the learning rate. &quot;</span>
</span><span id="LinearRegression-385"><a href="#LinearRegression-385"><span class="linenos">385</span></a>                    <span class="s2">&quot;If the problem persists, try reducing the number of iterations.&quot;</span>
</span><span id="LinearRegression-386"><a href="#LinearRegression-386"><span class="linenos">386</span></a>                <span class="p">)</span>
</span><span id="LinearRegression-387"><a href="#LinearRegression-387"><span class="linenos">387</span></a>
</span><span id="LinearRegression-388"><a href="#LinearRegression-388"><span class="linenos">388</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="LinearRegression-389"><a href="#LinearRegression-389"><span class="linenos">389</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="LinearRegression-390"><a href="#LinearRegression-390"><span class="linenos">390</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span><span class="p">,</span>
</span><span id="LinearRegression-391"><a href="#LinearRegression-391"><span class="linenos">391</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">),</span>
</span><span id="LinearRegression-392"><a href="#LinearRegression-392"><span class="linenos">392</span></a>                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LinearRegression-393"><a href="#LinearRegression-393"><span class="linenos">393</span></a>            <span class="p">)</span>
</span><span id="LinearRegression-394"><a href="#LinearRegression-394"><span class="linenos">394</span></a>
</span><span id="LinearRegression-395"><a href="#LinearRegression-395"><span class="linenos">395</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LinearRegression-396"><a href="#LinearRegression-396"><span class="linenos">396</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="LinearRegression-397"><a href="#LinearRegression-397"><span class="linenos">397</span></a>
</span><span id="LinearRegression-398"><a href="#LinearRegression-398"><span class="linenos">398</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span><span class="p">:</span>
</span><span id="LinearRegression-399"><a href="#LinearRegression-399"><span class="linenos">399</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="LinearRegression-400"><a href="#LinearRegression-400"><span class="linenos">400</span></a>
</span><span id="LinearRegression-401"><a href="#LinearRegression-401"><span class="linenos">401</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="LinearRegression-402"><a href="#LinearRegression-402"><span class="linenos">402</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-403"><a href="#LinearRegression-403"><span class="linenos">403</span></a><span class="sd">        ### Return the predicted values given X.</span>
</span><span id="LinearRegression-404"><a href="#LinearRegression-404"><span class="linenos">404</span></a>
</span><span id="LinearRegression-405"><a href="#LinearRegression-405"><span class="linenos">405</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-406"><a href="#LinearRegression-406"><span class="linenos">406</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-407"><a href="#LinearRegression-407"><span class="linenos">407</span></a>
</span><span id="LinearRegression-408"><a href="#LinearRegression-408"><span class="linenos">408</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-409"><a href="#LinearRegression-409"><span class="linenos">409</span></a><span class="sd">        - The input array of shape (n_samples, n_features) or (n_samples,)</span>
</span><span id="LinearRegression-410"><a href="#LinearRegression-410"><span class="linenos">410</span></a>
</span><span id="LinearRegression-411"><a href="#LinearRegression-411"><span class="linenos">411</span></a>
</span><span id="LinearRegression-412"><a href="#LinearRegression-412"><span class="linenos">412</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-413"><a href="#LinearRegression-413"><span class="linenos">413</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-414"><a href="#LinearRegression-414"><span class="linenos">414</span></a>
</span><span id="LinearRegression-415"><a href="#LinearRegression-415"><span class="linenos">415</span></a><span class="sd">        `np.ndarray`</span>
</span><span id="LinearRegression-416"><a href="#LinearRegression-416"><span class="linenos">416</span></a><span class="sd">        - The predicted values of shape (n_samples, 1) or (n_samples,)</span>
</span><span id="LinearRegression-417"><a href="#LinearRegression-417"><span class="linenos">417</span></a><span class="sd">        - If the model was trained as a univariate linear regression model,</span>
</span><span id="LinearRegression-418"><a href="#LinearRegression-418"><span class="linenos">418</span></a><span class="sd">            then the shape will be (n_samples,)</span>
</span><span id="LinearRegression-419"><a href="#LinearRegression-419"><span class="linenos">419</span></a><span class="sd">        - If the model was trained as a multivariate linear regression model,</span>
</span><span id="LinearRegression-420"><a href="#LinearRegression-420"><span class="linenos">420</span></a><span class="sd">            then the shape will be (n_samples, 1)</span>
</span><span id="LinearRegression-421"><a href="#LinearRegression-421"><span class="linenos">421</span></a>
</span><span id="LinearRegression-422"><a href="#LinearRegression-422"><span class="linenos">422</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-423"><a href="#LinearRegression-423"><span class="linenos">423</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-424"><a href="#LinearRegression-424"><span class="linenos">424</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span><span id="LinearRegression-425"><a href="#LinearRegression-425"><span class="linenos">425</span></a>            <span class="s2">&quot;The model must be trained before making predictions. &quot;</span>
</span><span id="LinearRegression-426"><a href="#LinearRegression-426"><span class="linenos">426</span></a>            <span class="s2">&quot;Call the fit method first.&quot;</span>
</span><span id="LinearRegression-427"><a href="#LinearRegression-427"><span class="linenos">427</span></a>        <span class="p">)</span>
</span><span id="LinearRegression-428"><a href="#LinearRegression-428"><span class="linenos">428</span></a>
</span><span id="LinearRegression-429"><a href="#LinearRegression-429"><span class="linenos">429</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LinearRegression-430"><a href="#LinearRegression-430"><span class="linenos">430</span></a>
</span><span id="LinearRegression-431"><a href="#LinearRegression-431"><span class="linenos">431</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="LinearRegression-432"><a href="#LinearRegression-432"><span class="linenos">432</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="LinearRegression-433"><a href="#LinearRegression-433"><span class="linenos">433</span></a>        <span class="p">]</span>
</span><span id="LinearRegression-434"><a href="#LinearRegression-434"><span class="linenos">434</span></a>
</span><span id="LinearRegression-435"><a href="#LinearRegression-435"><span class="linenos">435</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="LinearRegression-436"><a href="#LinearRegression-436"><span class="linenos">436</span></a>            <span class="n">predictions</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="LinearRegression-437"><a href="#LinearRegression-437"><span class="linenos">437</span></a>
</span><span id="LinearRegression-438"><a href="#LinearRegression-438"><span class="linenos">438</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="LinearRegression-439"><a href="#LinearRegression-439"><span class="linenos">439</span></a>
</span><span id="LinearRegression-440"><a href="#LinearRegression-440"><span class="linenos">440</span></a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span>
</span><span id="LinearRegression-441"><a href="#LinearRegression-441"><span class="linenos">441</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LinearRegression-442"><a href="#LinearRegression-442"><span class="linenos">442</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="LinearRegression-443"><a href="#LinearRegression-443"><span class="linenos">443</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression-444"><a href="#LinearRegression-444"><span class="linenos">444</span></a><span class="sd">        ### Return the cost for given X and Y.</span>
</span><span id="LinearRegression-445"><a href="#LinearRegression-445"><span class="linenos">445</span></a>
</span><span id="LinearRegression-446"><a href="#LinearRegression-446"><span class="linenos">446</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression-447"><a href="#LinearRegression-447"><span class="linenos">447</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression-448"><a href="#LinearRegression-448"><span class="linenos">448</span></a>
</span><span id="LinearRegression-449"><a href="#LinearRegression-449"><span class="linenos">449</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression-450"><a href="#LinearRegression-450"><span class="linenos">450</span></a><span class="sd">        - The input array of shape (n_samples, n_features) or (n_samples,)</span>
</span><span id="LinearRegression-451"><a href="#LinearRegression-451"><span class="linenos">451</span></a>
</span><span id="LinearRegression-452"><a href="#LinearRegression-452"><span class="linenos">452</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="LinearRegression-453"><a href="#LinearRegression-453"><span class="linenos">453</span></a><span class="sd">        - The output array of shape (n_samples,) or (n_samples, 1)</span>
</span><span id="LinearRegression-454"><a href="#LinearRegression-454"><span class="linenos">454</span></a>
</span><span id="LinearRegression-455"><a href="#LinearRegression-455"><span class="linenos">455</span></a><span class="sd">        `w` : np.ndarray, optional</span>
</span><span id="LinearRegression-456"><a href="#LinearRegression-456"><span class="linenos">456</span></a><span class="sd">        - The weight array, by default None</span>
</span><span id="LinearRegression-457"><a href="#LinearRegression-457"><span class="linenos">457</span></a><span class="sd">        - If None, then the weight array will be cosidered as the trained</span>
</span><span id="LinearRegression-458"><a href="#LinearRegression-458"><span class="linenos">458</span></a><span class="sd">            weight array</span>
</span><span id="LinearRegression-459"><a href="#LinearRegression-459"><span class="linenos">459</span></a>
</span><span id="LinearRegression-460"><a href="#LinearRegression-460"><span class="linenos">460</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="LinearRegression-461"><a href="#LinearRegression-461"><span class="linenos">461</span></a><span class="sd">        - The intercept, by default None</span>
</span><span id="LinearRegression-462"><a href="#LinearRegression-462"><span class="linenos">462</span></a><span class="sd">        - If None, then the intercept will be cosidered as the trained</span>
</span><span id="LinearRegression-463"><a href="#LinearRegression-463"><span class="linenos">463</span></a><span class="sd">            intercept</span>
</span><span id="LinearRegression-464"><a href="#LinearRegression-464"><span class="linenos">464</span></a>
</span><span id="LinearRegression-465"><a href="#LinearRegression-465"><span class="linenos">465</span></a>
</span><span id="LinearRegression-466"><a href="#LinearRegression-466"><span class="linenos">466</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression-467"><a href="#LinearRegression-467"><span class="linenos">467</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression-468"><a href="#LinearRegression-468"><span class="linenos">468</span></a>
</span><span id="LinearRegression-469"><a href="#LinearRegression-469"><span class="linenos">469</span></a><span class="sd">        `np.float64`</span>
</span><span id="LinearRegression-470"><a href="#LinearRegression-470"><span class="linenos">470</span></a><span class="sd">        - The computed cost</span>
</span><span id="LinearRegression-471"><a href="#LinearRegression-471"><span class="linenos">471</span></a>
</span><span id="LinearRegression-472"><a href="#LinearRegression-472"><span class="linenos">472</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression-473"><a href="#LinearRegression-473"><span class="linenos">473</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression-474"><a href="#LinearRegression-474"><span class="linenos">474</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="LinearRegression-475"><a href="#LinearRegression-475"><span class="linenos">475</span></a>
</span><span id="LinearRegression-476"><a href="#LinearRegression-476"><span class="linenos">476</span></a>        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w</span>
</span><span id="LinearRegression-477"><a href="#LinearRegression-477"><span class="linenos">477</span></a>        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b</span>
</span><span id="LinearRegression-478"><a href="#LinearRegression-478"><span class="linenos">478</span></a>
</span><span id="LinearRegression-479"><a href="#LinearRegression-479"><span class="linenos">479</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h1 id="linear-regression-model">Linear Regression Model</h1>

<p>Linear Regression is a fundamental supervised machine learning algorithm used to model the relationship between one or more independent variables and a continuous target variable. It serves as a cornerstone for predictive modeling and provides insights into how changes in input features affect the target variable. Linear Regression assumes that the target variable can be expressed as a linear combination of the input features, facilitating interpretation and prediction.</p>

<hr />

<h2 id="mathematical-approach">Mathematical Approach</h2>

<p>Linear Regression aims to find the best-fitting linear equation that predicts the target variable. The equation takes the form:</p>

<pre><code>y = b + w1 * x1 + w2 * x2 + ... + wn * xn
</code></pre>

<p>Where:</p>

<ul>
<li><code>y</code> is the predicted target variable.</li>
<li><code>b</code> is the intercept (bias term).</li>
<li><code>w1, w2, ..., wn</code> are the weights assigned to each input feature <code>x1, x2, ..., xn</code>.</li>
</ul>

<p>The goal of Linear Regression is to find the optimal values for <code>b</code> and the weights that minimize the difference between predicted and actual target values.</p>

<hr />

<h2 id="usage">Usage</h2>

<p>To use the Linear Regression model, follow these steps:</p>

<ol>
<li>Import the <code><a href="#LinearRegression">LinearRegression</a></code> class from the appropriate module.</li>
<li>Create an instance of the <code><a href="#LinearRegression">LinearRegression</a></code> class, specifying hyperparameters.</li>
<li>Fit the model to your training data using the <code><a href="#LinearRegression.fit">fit</a></code> method.</li>
<li>Make predictions on new data using the <code><a href="#LinearRegression.predict">predict</a></code> method.</li>
<li>Evaluate the model's performance using the <code><a href="#LinearRegression.score">score</a></code> method.</li>
</ol>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">from</span> <span class="nn"><a href="">learnML.regression</a></span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Create an instance of LinearRegression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Fit the model to training data</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Make predictions on new data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the model&#39;s score</span>
<span class="n">model_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
</code></pre>
</div>

<hr />

<h2 id="advantages">Advantages</h2>

<ul>
<li>Easy to implement</li>
<li>Easy to interpret the output</li>
<li>Computationally cheap</li>
</ul>

<h2 id="disadvantages">Disadvantages</h2>

<ul>
<li>Poor performance on non-linear data</li>
<li>Sensitive to outliers</li>
<li>Sensitive to overfitting</li>
</ul>

<hr />
</div>


                            <div id="LinearRegression.__init__" class="classattr">
                                        <input id="LinearRegression.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">LinearRegression</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">learning_rate</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span>,</span><span class="param">	<span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>,</span><span class="param">	<span class="n">lambda_</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">	<span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="LinearRegression.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LinearRegression.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LinearRegression.__init__-78"><a href="#LinearRegression.__init__-78"><span class="linenos"> 78</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="LinearRegression.__init__-79"><a href="#LinearRegression.__init__-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-80"><a href="#LinearRegression.__init__-80"><span class="linenos"> 80</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-81"><a href="#LinearRegression.__init__-81"><span class="linenos"> 81</span></a>        <span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-82"><a href="#LinearRegression.__init__-82"><span class="linenos"> 82</span></a>        <span class="n">lambda_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-83"><a href="#LinearRegression.__init__-83"><span class="linenos"> 83</span></a>        <span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-84"><a href="#LinearRegression.__init__-84"><span class="linenos"> 84</span></a>        <span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-85"><a href="#LinearRegression.__init__-85"><span class="linenos"> 85</span></a>        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-86"><a href="#LinearRegression.__init__-86"><span class="linenos"> 86</span></a>        <span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-87"><a href="#LinearRegression.__init__-87"><span class="linenos"> 87</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression.__init__-88"><a href="#LinearRegression.__init__-88"><span class="linenos"> 88</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression.__init__-89"><a href="#LinearRegression.__init__-89"><span class="linenos"> 89</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression.__init__-90"><a href="#LinearRegression.__init__-90"><span class="linenos"> 90</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression.__init__-91"><a href="#LinearRegression.__init__-91"><span class="linenos"> 91</span></a>
</span><span id="LinearRegression.__init__-92"><a href="#LinearRegression.__init__-92"><span class="linenos"> 92</span></a><span class="sd">        `learning_rate` : np.float64, optional</span>
</span><span id="LinearRegression.__init__-93"><a href="#LinearRegression.__init__-93"><span class="linenos"> 93</span></a><span class="sd">        - The learning rate, by default 0.001</span>
</span><span id="LinearRegression.__init__-94"><a href="#LinearRegression.__init__-94"><span class="linenos"> 94</span></a><span class="sd">        - The learning rate determines how much the weights are updated at each iteration</span>
</span><span id="LinearRegression.__init__-95"><a href="#LinearRegression.__init__-95"><span class="linenos"> 95</span></a><span class="sd">        - A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</span>
</span><span id="LinearRegression.__init__-96"><a href="#LinearRegression.__init__-96"><span class="linenos"> 96</span></a>
</span><span id="LinearRegression.__init__-97"><a href="#LinearRegression.__init__-97"><span class="linenos"> 97</span></a><span class="sd">        `n_iterations` : int, optional</span>
</span><span id="LinearRegression.__init__-98"><a href="#LinearRegression.__init__-98"><span class="linenos"> 98</span></a><span class="sd">        - The number of iterations, by default 1000</span>
</span><span id="LinearRegression.__init__-99"><a href="#LinearRegression.__init__-99"><span class="linenos"> 99</span></a><span class="sd">        - The number of iterations determines how many times the weights are updated</span>
</span><span id="LinearRegression.__init__-100"><a href="#LinearRegression.__init__-100"><span class="linenos">100</span></a><span class="sd">        - A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</span>
</span><span id="LinearRegression.__init__-101"><a href="#LinearRegression.__init__-101"><span class="linenos">101</span></a>
</span><span id="LinearRegression.__init__-102"><a href="#LinearRegression.__init__-102"><span class="linenos">102</span></a><span class="sd">        `lambda_` : np.float64, optional</span>
</span><span id="LinearRegression.__init__-103"><a href="#LinearRegression.__init__-103"><span class="linenos">103</span></a><span class="sd">        - The regularization parameter, by default 0</span>
</span><span id="LinearRegression.__init__-104"><a href="#LinearRegression.__init__-104"><span class="linenos">104</span></a><span class="sd">        - The regularization parameter helps prevent overfitting by penalizing large weights</span>
</span><span id="LinearRegression.__init__-105"><a href="#LinearRegression.__init__-105"><span class="linenos">105</span></a><span class="sd">        - A higher regularization parameter will penalize large weights more, but a lower regularization parameter may not be enough to prevent overfitting</span>
</span><span id="LinearRegression.__init__-106"><a href="#LinearRegression.__init__-106"><span class="linenos">106</span></a>
</span><span id="LinearRegression.__init__-107"><a href="#LinearRegression.__init__-107"><span class="linenos">107</span></a><span class="sd">        `x_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="LinearRegression.__init__-108"><a href="#LinearRegression.__init__-108"><span class="linenos">108</span></a><span class="sd">        - The feature engineering for the input data, by default None</span>
</span><span id="LinearRegression.__init__-109"><a href="#LinearRegression.__init__-109"><span class="linenos">109</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="LinearRegression.__init__-110"><a href="#LinearRegression.__init__-110"><span class="linenos">110</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all input data</span>
</span><span id="LinearRegression.__init__-111"><a href="#LinearRegression.__init__-111"><span class="linenos">111</span></a>
</span><span id="LinearRegression.__init__-112"><a href="#LinearRegression.__init__-112"><span class="linenos">112</span></a><span class="sd">        `y_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="LinearRegression.__init__-113"><a href="#LinearRegression.__init__-113"><span class="linenos">113</span></a><span class="sd">        - The feature engineering for the output data, by default None</span>
</span><span id="LinearRegression.__init__-114"><a href="#LinearRegression.__init__-114"><span class="linenos">114</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="LinearRegression.__init__-115"><a href="#LinearRegression.__init__-115"><span class="linenos">115</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all output data</span>
</span><span id="LinearRegression.__init__-116"><a href="#LinearRegression.__init__-116"><span class="linenos">116</span></a>
</span><span id="LinearRegression.__init__-117"><a href="#LinearRegression.__init__-117"><span class="linenos">117</span></a><span class="sd">        `debug` : bool, optional</span>
</span><span id="LinearRegression.__init__-118"><a href="#LinearRegression.__init__-118"><span class="linenos">118</span></a><span class="sd">        - Whether to print debug messages, by default True</span>
</span><span id="LinearRegression.__init__-119"><a href="#LinearRegression.__init__-119"><span class="linenos">119</span></a><span class="sd">        - Debug messages include the cost at each iteration</span>
</span><span id="LinearRegression.__init__-120"><a href="#LinearRegression.__init__-120"><span class="linenos">120</span></a>
</span><span id="LinearRegression.__init__-121"><a href="#LinearRegression.__init__-121"><span class="linenos">121</span></a><span class="sd">        `copy_x` : bool, optional</span>
</span><span id="LinearRegression.__init__-122"><a href="#LinearRegression.__init__-122"><span class="linenos">122</span></a><span class="sd">        - Whether to copy the input array, by default True</span>
</span><span id="LinearRegression.__init__-123"><a href="#LinearRegression.__init__-123"><span class="linenos">123</span></a><span class="sd">        - If False, the input array will be overwritten</span>
</span><span id="LinearRegression.__init__-124"><a href="#LinearRegression.__init__-124"><span class="linenos">124</span></a>
</span><span id="LinearRegression.__init__-125"><a href="#LinearRegression.__init__-125"><span class="linenos">125</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression.__init__-126"><a href="#LinearRegression.__init__-126"><span class="linenos">126</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression.__init__-127"><a href="#LinearRegression.__init__-127"><span class="linenos">127</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="LinearRegression.__init__-128"><a href="#LinearRegression.__init__-128"><span class="linenos">128</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-129"><a href="#LinearRegression.__init__-129"><span class="linenos">129</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-130"><a href="#LinearRegression.__init__-130"><span class="linenos">130</span></a>            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-131"><a href="#LinearRegression.__init__-131"><span class="linenos">131</span></a>            <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
</span><span id="LinearRegression.__init__-132"><a href="#LinearRegression.__init__-132"><span class="linenos">132</span></a>        <span class="p">)</span>
</span><span id="LinearRegression.__init__-133"><a href="#LinearRegression.__init__-133"><span class="linenos">133</span></a>
</span><span id="LinearRegression.__init__-134"><a href="#LinearRegression.__init__-134"><span class="linenos">134</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_lambda</span> <span class="o">=</span> <span class="n">lambda_</span>
</span><span id="LinearRegression.__init__-135"><a href="#LinearRegression.__init__-135"><span class="linenos">135</span></a>
</span><span id="LinearRegression.__init__-136"><a href="#LinearRegression.__init__-136"><span class="linenos">136</span></a>        <span class="k">if</span> <span class="n">x_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression.__init__-137"><a href="#LinearRegression.__init__-137"><span class="linenos">137</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="LinearRegression.__init__-138"><a href="#LinearRegression.__init__-138"><span class="linenos">138</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="LinearRegression.__init__-139"><a href="#LinearRegression.__init__-139"><span class="linenos">139</span></a>            <span class="n">x_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_scalar</span><span class="p">]</span>
</span><span id="LinearRegression.__init__-140"><a href="#LinearRegression.__init__-140"><span class="linenos">140</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span> <span class="o">=</span> <span class="n">x_scalar</span>
</span><span id="LinearRegression.__init__-141"><a href="#LinearRegression.__init__-141"><span class="linenos">141</span></a>
</span><span id="LinearRegression.__init__-142"><a href="#LinearRegression.__init__-142"><span class="linenos">142</span></a>        <span class="k">if</span> <span class="n">y_scalar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression.__init__-143"><a href="#LinearRegression.__init__-143"><span class="linenos">143</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="LinearRegression.__init__-144"><a href="#LinearRegression.__init__-144"><span class="linenos">144</span></a>        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_scalar</span><span class="p">,</span> <span class="n">IFeatureEngineering</span><span class="p">):</span>
</span><span id="LinearRegression.__init__-145"><a href="#LinearRegression.__init__-145"><span class="linenos">145</span></a>            <span class="n">y_scalar</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_scalar</span><span class="p">]</span>
</span><span id="LinearRegression.__init__-146"><a href="#LinearRegression.__init__-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span> <span class="o">=</span> <span class="n">y_scalar</span>
</span></pre></div>


            <div class="docstring"><h2 id="parameters">Parameters</h2>

<p><code>learning_rate</code> : np.float64, optional</p>

<ul>
<li>The learning rate, by default 0.001</li>
<li>The learning rate determines how much the weights are updated at each iteration</li>
<li>A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</li>
</ul>

<p><code>n_iterations</code> : int, optional</p>

<ul>
<li>The number of iterations, by default 1000</li>
<li>The number of iterations determines how many times the weights are updated</li>
<li>A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</li>
</ul>

<p><code>lambda_</code> : np.float64, optional</p>

<ul>
<li>The regularization parameter, by default 0</li>
<li>The regularization parameter helps prevent overfitting by penalizing large weights</li>
<li>A higher regularization parameter will penalize large weights more, but a lower regularization parameter may not be enough to prevent overfitting</li>
</ul>

<p><code>x_scalar</code> : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</p>

<ul>
<li>The feature engineering for the input data, by default None</li>
<li>If a list is provided, the feature engineering will be applied in the order provided</li>
<li>If a single feature engineering is provided, it will be applied to all input data</li>
</ul>

<p><code>y_scalar</code> : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</p>

<ul>
<li>The feature engineering for the output data, by default None</li>
<li>If a list is provided, the feature engineering will be applied in the order provided</li>
<li>If a single feature engineering is provided, it will be applied to all output data</li>
</ul>

<p><code>debug</code> : bool, optional</p>

<ul>
<li>Whether to print debug messages, by default True</li>
<li>Debug messages include the cost at each iteration</li>
</ul>

<p><code>copy_x</code> : bool, optional</p>

<ul>
<li>Whether to copy the input array, by default True</li>
<li>If False, the input array will be overwritten</li>
</ul>

<hr />
</div>


                            </div>
                            <div id="LinearRegression.fit" class="classattr">
                                        <input id="LinearRegression.fit-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">fit</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">Y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">W</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">b</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span></span><span class="return-annotation">) -> <span class="kc">None</span>:</span></span>

                <label class="view-source-button" for="LinearRegression.fit-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LinearRegression.fit"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LinearRegression.fit-320"><a href="#LinearRegression.fit-320"><span class="linenos">320</span></a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
</span><span id="LinearRegression.fit-321"><a href="#LinearRegression.fit-321"><span class="linenos">321</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="LinearRegression.fit-322"><a href="#LinearRegression.fit-322"><span class="linenos">322</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LinearRegression.fit-323"><a href="#LinearRegression.fit-323"><span class="linenos">323</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression.fit-324"><a href="#LinearRegression.fit-324"><span class="linenos">324</span></a><span class="sd">        ### Train the model given X and Y.</span>
</span><span id="LinearRegression.fit-325"><a href="#LinearRegression.fit-325"><span class="linenos">325</span></a>
</span><span id="LinearRegression.fit-326"><a href="#LinearRegression.fit-326"><span class="linenos">326</span></a>
</span><span id="LinearRegression.fit-327"><a href="#LinearRegression.fit-327"><span class="linenos">327</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression.fit-328"><a href="#LinearRegression.fit-328"><span class="linenos">328</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression.fit-329"><a href="#LinearRegression.fit-329"><span class="linenos">329</span></a>
</span><span id="LinearRegression.fit-330"><a href="#LinearRegression.fit-330"><span class="linenos">330</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression.fit-331"><a href="#LinearRegression.fit-331"><span class="linenos">331</span></a><span class="sd">        - The input array of shape (n_samples, n_features) or (n_samples,)</span>
</span><span id="LinearRegression.fit-332"><a href="#LinearRegression.fit-332"><span class="linenos">332</span></a><span class="sd">        - If the shape is (n_samples,), then the model will be trained as a</span>
</span><span id="LinearRegression.fit-333"><a href="#LinearRegression.fit-333"><span class="linenos">333</span></a><span class="sd">            univariate linear regression model</span>
</span><span id="LinearRegression.fit-334"><a href="#LinearRegression.fit-334"><span class="linenos">334</span></a><span class="sd">        - If the shape is (n_samples, n_features), then the model will be</span>
</span><span id="LinearRegression.fit-335"><a href="#LinearRegression.fit-335"><span class="linenos">335</span></a><span class="sd">            trained as a multivariate linear regression model</span>
</span><span id="LinearRegression.fit-336"><a href="#LinearRegression.fit-336"><span class="linenos">336</span></a>
</span><span id="LinearRegression.fit-337"><a href="#LinearRegression.fit-337"><span class="linenos">337</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="LinearRegression.fit-338"><a href="#LinearRegression.fit-338"><span class="linenos">338</span></a><span class="sd">        - The output array of shape (n_samples,) or (n_samples, 1)</span>
</span><span id="LinearRegression.fit-339"><a href="#LinearRegression.fit-339"><span class="linenos">339</span></a>
</span><span id="LinearRegression.fit-340"><a href="#LinearRegression.fit-340"><span class="linenos">340</span></a><span class="sd">        `w` : np.ndarray, optional</span>
</span><span id="LinearRegression.fit-341"><a href="#LinearRegression.fit-341"><span class="linenos">341</span></a><span class="sd">        - The weight array, by default None</span>
</span><span id="LinearRegression.fit-342"><a href="#LinearRegression.fit-342"><span class="linenos">342</span></a><span class="sd">        - If None, then the weight array will be initialized to an array of</span>
</span><span id="LinearRegression.fit-343"><a href="#LinearRegression.fit-343"><span class="linenos">343</span></a><span class="sd">            zeros of shape (n_features,)</span>
</span><span id="LinearRegression.fit-344"><a href="#LinearRegression.fit-344"><span class="linenos">344</span></a><span class="sd">        - If not None, then the weight array will be initialized to the given</span>
</span><span id="LinearRegression.fit-345"><a href="#LinearRegression.fit-345"><span class="linenos">345</span></a><span class="sd">            array</span>
</span><span id="LinearRegression.fit-346"><a href="#LinearRegression.fit-346"><span class="linenos">346</span></a>
</span><span id="LinearRegression.fit-347"><a href="#LinearRegression.fit-347"><span class="linenos">347</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="LinearRegression.fit-348"><a href="#LinearRegression.fit-348"><span class="linenos">348</span></a><span class="sd">        - The intercept, by default 0</span>
</span><span id="LinearRegression.fit-349"><a href="#LinearRegression.fit-349"><span class="linenos">349</span></a><span class="sd">        - If None, then the intercept will be initialized to 0</span>
</span><span id="LinearRegression.fit-350"><a href="#LinearRegression.fit-350"><span class="linenos">350</span></a><span class="sd">        - If not None, then the intercept will be initialized to the given</span>
</span><span id="LinearRegression.fit-351"><a href="#LinearRegression.fit-351"><span class="linenos">351</span></a><span class="sd">            value</span>
</span><span id="LinearRegression.fit-352"><a href="#LinearRegression.fit-352"><span class="linenos">352</span></a>
</span><span id="LinearRegression.fit-353"><a href="#LinearRegression.fit-353"><span class="linenos">353</span></a>
</span><span id="LinearRegression.fit-354"><a href="#LinearRegression.fit-354"><span class="linenos">354</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression.fit-355"><a href="#LinearRegression.fit-355"><span class="linenos">355</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression.fit-356"><a href="#LinearRegression.fit-356"><span class="linenos">356</span></a>
</span><span id="LinearRegression.fit-357"><a href="#LinearRegression.fit-357"><span class="linenos">357</span></a><span class="sd">        None</span>
</span><span id="LinearRegression.fit-358"><a href="#LinearRegression.fit-358"><span class="linenos">358</span></a>
</span><span id="LinearRegression.fit-359"><a href="#LinearRegression.fit-359"><span class="linenos">359</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression.fit-360"><a href="#LinearRegression.fit-360"><span class="linenos">360</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression.fit-361"><a href="#LinearRegression.fit-361"><span class="linenos">361</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="LinearRegression.fit-362"><a href="#LinearRegression.fit-362"><span class="linenos">362</span></a>
</span><span id="LinearRegression.fit-363"><a href="#LinearRegression.fit-363"><span class="linenos">363</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="n">W</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">W</span>
</span><span id="LinearRegression.fit-364"><a href="#LinearRegression.fit-364"><span class="linenos">364</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">=</span> <span class="n">b</span>
</span><span id="LinearRegression.fit-365"><a href="#LinearRegression.fit-365"><span class="linenos">365</span></a>
</span><span id="LinearRegression.fit-366"><a href="#LinearRegression.fit-366"><span class="linenos">366</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="LinearRegression.fit-367"><a href="#LinearRegression.fit-367"><span class="linenos">367</span></a>            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)]</span>
</span><span id="LinearRegression.fit-368"><a href="#LinearRegression.fit-368"><span class="linenos">368</span></a>        <span class="p">)</span>
</span><span id="LinearRegression.fit-369"><a href="#LinearRegression.fit-369"><span class="linenos">369</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
</span><span id="LinearRegression.fit-370"><a href="#LinearRegression.fit-370"><span class="linenos">370</span></a>            <span class="p">[[</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span>
</span><span id="LinearRegression.fit-371"><a href="#LinearRegression.fit-371"><span class="linenos">371</span></a>        <span class="p">)</span>
</span><span id="LinearRegression.fit-372"><a href="#LinearRegression.fit-372"><span class="linenos">372</span></a>
</span><span id="LinearRegression.fit-373"><a href="#LinearRegression.fit-373"><span class="linenos">373</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">):</span>
</span><span id="LinearRegression.fit-374"><a href="#LinearRegression.fit-374"><span class="linenos">374</span></a>            <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="LinearRegression.fit-375"><a href="#LinearRegression.fit-375"><span class="linenos">375</span></a>
</span><span id="LinearRegression.fit-376"><a href="#LinearRegression.fit-376"><span class="linenos">376</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">)</span>
</span><span id="LinearRegression.fit-377"><a href="#LinearRegression.fit-377"><span class="linenos">377</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">dw</span>
</span><span id="LinearRegression.fit-378"><a href="#LinearRegression.fit-378"><span class="linenos">378</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_learning_rate</span> <span class="o">*</span> <span class="n">db</span>
</span><span id="LinearRegression.fit-379"><a href="#LinearRegression.fit-379"><span class="linenos">379</span></a>
</span><span id="LinearRegression.fit-380"><a href="#LinearRegression.fit-380"><span class="linenos">380</span></a>            <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span>
</span><span id="LinearRegression.fit-381"><a href="#LinearRegression.fit-381"><span class="linenos">381</span></a>
</span><span id="LinearRegression.fit-382"><a href="#LinearRegression.fit-382"><span class="linenos">382</span></a>            <span class="k">if</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span> <span class="ow">or</span> <span class="n">cost</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
</span><span id="LinearRegression.fit-383"><a href="#LinearRegression.fit-383"><span class="linenos">383</span></a>                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="LinearRegression.fit-384"><a href="#LinearRegression.fit-384"><span class="linenos">384</span></a>                    <span class="s2">&quot;Gradient descent failed. Try normalizing the input array or reducing the learning rate. &quot;</span>
</span><span id="LinearRegression.fit-385"><a href="#LinearRegression.fit-385"><span class="linenos">385</span></a>                    <span class="s2">&quot;If the problem persists, try reducing the number of iterations.&quot;</span>
</span><span id="LinearRegression.fit-386"><a href="#LinearRegression.fit-386"><span class="linenos">386</span></a>                <span class="p">)</span>
</span><span id="LinearRegression.fit-387"><a href="#LinearRegression.fit-387"><span class="linenos">387</span></a>
</span><span id="LinearRegression.fit-388"><a href="#LinearRegression.fit-388"><span class="linenos">388</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_cost_history</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="LinearRegression.fit-389"><a href="#LinearRegression.fit-389"><span class="linenos">389</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="LinearRegression.fit-390"><a href="#LinearRegression.fit-390"><span class="linenos">390</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_params_history</span><span class="p">,</span>
</span><span id="LinearRegression.fit-391"><a href="#LinearRegression.fit-391"><span class="linenos">391</span></a>                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">),</span>
</span><span id="LinearRegression.fit-392"><a href="#LinearRegression.fit-392"><span class="linenos">392</span></a>                <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span id="LinearRegression.fit-393"><a href="#LinearRegression.fit-393"><span class="linenos">393</span></a>            <span class="p">)</span>
</span><span id="LinearRegression.fit-394"><a href="#LinearRegression.fit-394"><span class="linenos">394</span></a>
</span><span id="LinearRegression.fit-395"><a href="#LinearRegression.fit-395"><span class="linenos">395</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LinearRegression.fit-396"><a href="#LinearRegression.fit-396"><span class="linenos">396</span></a>                <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span><span id="LinearRegression.fit-397"><a href="#LinearRegression.fit-397"><span class="linenos">397</span></a>
</span><span id="LinearRegression.fit-398"><a href="#LinearRegression.fit-398"><span class="linenos">398</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_debug</span><span class="p">:</span>
</span><span id="LinearRegression.fit-399"><a href="#LinearRegression.fit-399"><span class="linenos">399</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_debug_print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_iterations</span><span class="p">,</span> <span class="n">cost</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h3 id="train-the-model-given-x-and-y">Train the model given X and Y.</h3>

<h2 id="parameters">Parameters</h2>

<p><code>X</code> : np.ndarray</p>

<ul>
<li>The input array of shape (n_samples, n_features) or (n_samples,)</li>
<li>If the shape is (n_samples,), then the model will be trained as a
univariate linear regression model</li>
<li>If the shape is (n_samples, n_features), then the model will be
trained as a multivariate linear regression model</li>
</ul>

<p><code>Y</code> : np.ndarray</p>

<ul>
<li>The output array of shape (n_samples,) or (n_samples, 1)</li>
</ul>

<p><code>w</code> : np.ndarray, optional</p>

<ul>
<li>The weight array, by default None</li>
<li>If None, then the weight array will be initialized to an array of
zeros of shape (n_features,)</li>
<li>If not None, then the weight array will be initialized to the given
array</li>
</ul>

<p><code>b</code> : np.float64, optional</p>

<ul>
<li>The intercept, by default 0</li>
<li>If None, then the intercept will be initialized to 0</li>
<li>If not None, then the intercept will be initialized to the given
value</li>
</ul>

<h2 id="returns">Returns</h2>

<p>None</p>

<hr />
</div>


                            </div>
                            <div id="LinearRegression.predict" class="classattr">
                                        <input id="LinearRegression.predict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">predict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>:</span></span>

                <label class="view-source-button" for="LinearRegression.predict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LinearRegression.predict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LinearRegression.predict-401"><a href="#LinearRegression.predict-401"><span class="linenos">401</span></a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="LinearRegression.predict-402"><a href="#LinearRegression.predict-402"><span class="linenos">402</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression.predict-403"><a href="#LinearRegression.predict-403"><span class="linenos">403</span></a><span class="sd">        ### Return the predicted values given X.</span>
</span><span id="LinearRegression.predict-404"><a href="#LinearRegression.predict-404"><span class="linenos">404</span></a>
</span><span id="LinearRegression.predict-405"><a href="#LinearRegression.predict-405"><span class="linenos">405</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression.predict-406"><a href="#LinearRegression.predict-406"><span class="linenos">406</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression.predict-407"><a href="#LinearRegression.predict-407"><span class="linenos">407</span></a>
</span><span id="LinearRegression.predict-408"><a href="#LinearRegression.predict-408"><span class="linenos">408</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression.predict-409"><a href="#LinearRegression.predict-409"><span class="linenos">409</span></a><span class="sd">        - The input array of shape (n_samples, n_features) or (n_samples,)</span>
</span><span id="LinearRegression.predict-410"><a href="#LinearRegression.predict-410"><span class="linenos">410</span></a>
</span><span id="LinearRegression.predict-411"><a href="#LinearRegression.predict-411"><span class="linenos">411</span></a>
</span><span id="LinearRegression.predict-412"><a href="#LinearRegression.predict-412"><span class="linenos">412</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression.predict-413"><a href="#LinearRegression.predict-413"><span class="linenos">413</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression.predict-414"><a href="#LinearRegression.predict-414"><span class="linenos">414</span></a>
</span><span id="LinearRegression.predict-415"><a href="#LinearRegression.predict-415"><span class="linenos">415</span></a><span class="sd">        `np.ndarray`</span>
</span><span id="LinearRegression.predict-416"><a href="#LinearRegression.predict-416"><span class="linenos">416</span></a><span class="sd">        - The predicted values of shape (n_samples, 1) or (n_samples,)</span>
</span><span id="LinearRegression.predict-417"><a href="#LinearRegression.predict-417"><span class="linenos">417</span></a><span class="sd">        - If the model was trained as a univariate linear regression model,</span>
</span><span id="LinearRegression.predict-418"><a href="#LinearRegression.predict-418"><span class="linenos">418</span></a><span class="sd">            then the shape will be (n_samples,)</span>
</span><span id="LinearRegression.predict-419"><a href="#LinearRegression.predict-419"><span class="linenos">419</span></a><span class="sd">        - If the model was trained as a multivariate linear regression model,</span>
</span><span id="LinearRegression.predict-420"><a href="#LinearRegression.predict-420"><span class="linenos">420</span></a><span class="sd">            then the shape will be (n_samples, 1)</span>
</span><span id="LinearRegression.predict-421"><a href="#LinearRegression.predict-421"><span class="linenos">421</span></a>
</span><span id="LinearRegression.predict-422"><a href="#LinearRegression.predict-422"><span class="linenos">422</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression.predict-423"><a href="#LinearRegression.predict-423"><span class="linenos">423</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression.predict-424"><a href="#LinearRegression.predict-424"><span class="linenos">424</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
</span><span id="LinearRegression.predict-425"><a href="#LinearRegression.predict-425"><span class="linenos">425</span></a>            <span class="s2">&quot;The model must be trained before making predictions. &quot;</span>
</span><span id="LinearRegression.predict-426"><a href="#LinearRegression.predict-426"><span class="linenos">426</span></a>            <span class="s2">&quot;Call the fit method first.&quot;</span>
</span><span id="LinearRegression.predict-427"><a href="#LinearRegression.predict-427"><span class="linenos">427</span></a>        <span class="p">)</span>
</span><span id="LinearRegression.predict-428"><a href="#LinearRegression.predict-428"><span class="linenos">428</span></a>
</span><span id="LinearRegression.predict-429"><a href="#LinearRegression.predict-429"><span class="linenos">429</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="LinearRegression.predict-430"><a href="#LinearRegression.predict-430"><span class="linenos">430</span></a>
</span><span id="LinearRegression.predict-431"><a href="#LinearRegression.predict-431"><span class="linenos">431</span></a>        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="LinearRegression.predict-432"><a href="#LinearRegression.predict-432"><span class="linenos">432</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_y_hat</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="LinearRegression.predict-433"><a href="#LinearRegression.predict-433"><span class="linenos">433</span></a>        <span class="p">]</span>
</span><span id="LinearRegression.predict-434"><a href="#LinearRegression.predict-434"><span class="linenos">434</span></a>
</span><span id="LinearRegression.predict-435"><a href="#LinearRegression.predict-435"><span class="linenos">435</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="LinearRegression.predict-436"><a href="#LinearRegression.predict-436"><span class="linenos">436</span></a>            <span class="n">predictions</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span><span id="LinearRegression.predict-437"><a href="#LinearRegression.predict-437"><span class="linenos">437</span></a>
</span><span id="LinearRegression.predict-438"><a href="#LinearRegression.predict-438"><span class="linenos">438</span></a>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h3 id="return-the-predicted-values-given-x">Return the predicted values given X.</h3>

<h2 id="parameters">Parameters</h2>

<p><code>X</code> : np.ndarray</p>

<ul>
<li>The input array of shape (n_samples, n_features) or (n_samples,)</li>
</ul>

<h2 id="returns">Returns</h2>

<p><code>np.ndarray</code></p>

<ul>
<li>The predicted values of shape (n_samples, 1) or (n_samples,)</li>
<li>If the model was trained as a univariate linear regression model,
then the shape will be (n_samples,)</li>
<li>If the model was trained as a multivariate linear regression model,
then the shape will be (n_samples, 1)</li>
</ul>

<hr />
</div>


                            </div>
                            <div id="LinearRegression.score" class="classattr">
                                        <input id="LinearRegression.score-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">score</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">X</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">Y</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>,</span><span class="param">	<span class="n">w</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">b</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span>:</span></span>

                <label class="view-source-button" for="LinearRegression.score-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LinearRegression.score"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LinearRegression.score-440"><a href="#LinearRegression.score-440"><span class="linenos">440</span></a>    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span>
</span><span id="LinearRegression.score-441"><a href="#LinearRegression.score-441"><span class="linenos">441</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LinearRegression.score-442"><a href="#LinearRegression.score-442"><span class="linenos">442</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
</span><span id="LinearRegression.score-443"><a href="#LinearRegression.score-443"><span class="linenos">443</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="LinearRegression.score-444"><a href="#LinearRegression.score-444"><span class="linenos">444</span></a><span class="sd">        ### Return the cost for given X and Y.</span>
</span><span id="LinearRegression.score-445"><a href="#LinearRegression.score-445"><span class="linenos">445</span></a>
</span><span id="LinearRegression.score-446"><a href="#LinearRegression.score-446"><span class="linenos">446</span></a><span class="sd">        Parameters</span>
</span><span id="LinearRegression.score-447"><a href="#LinearRegression.score-447"><span class="linenos">447</span></a><span class="sd">        ----------</span>
</span><span id="LinearRegression.score-448"><a href="#LinearRegression.score-448"><span class="linenos">448</span></a>
</span><span id="LinearRegression.score-449"><a href="#LinearRegression.score-449"><span class="linenos">449</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="LinearRegression.score-450"><a href="#LinearRegression.score-450"><span class="linenos">450</span></a><span class="sd">        - The input array of shape (n_samples, n_features) or (n_samples,)</span>
</span><span id="LinearRegression.score-451"><a href="#LinearRegression.score-451"><span class="linenos">451</span></a>
</span><span id="LinearRegression.score-452"><a href="#LinearRegression.score-452"><span class="linenos">452</span></a><span class="sd">        `Y` : np.ndarray</span>
</span><span id="LinearRegression.score-453"><a href="#LinearRegression.score-453"><span class="linenos">453</span></a><span class="sd">        - The output array of shape (n_samples,) or (n_samples, 1)</span>
</span><span id="LinearRegression.score-454"><a href="#LinearRegression.score-454"><span class="linenos">454</span></a>
</span><span id="LinearRegression.score-455"><a href="#LinearRegression.score-455"><span class="linenos">455</span></a><span class="sd">        `w` : np.ndarray, optional</span>
</span><span id="LinearRegression.score-456"><a href="#LinearRegression.score-456"><span class="linenos">456</span></a><span class="sd">        - The weight array, by default None</span>
</span><span id="LinearRegression.score-457"><a href="#LinearRegression.score-457"><span class="linenos">457</span></a><span class="sd">        - If None, then the weight array will be cosidered as the trained</span>
</span><span id="LinearRegression.score-458"><a href="#LinearRegression.score-458"><span class="linenos">458</span></a><span class="sd">            weight array</span>
</span><span id="LinearRegression.score-459"><a href="#LinearRegression.score-459"><span class="linenos">459</span></a>
</span><span id="LinearRegression.score-460"><a href="#LinearRegression.score-460"><span class="linenos">460</span></a><span class="sd">        `b` : np.float64, optional</span>
</span><span id="LinearRegression.score-461"><a href="#LinearRegression.score-461"><span class="linenos">461</span></a><span class="sd">        - The intercept, by default None</span>
</span><span id="LinearRegression.score-462"><a href="#LinearRegression.score-462"><span class="linenos">462</span></a><span class="sd">        - If None, then the intercept will be cosidered as the trained</span>
</span><span id="LinearRegression.score-463"><a href="#LinearRegression.score-463"><span class="linenos">463</span></a><span class="sd">            intercept</span>
</span><span id="LinearRegression.score-464"><a href="#LinearRegression.score-464"><span class="linenos">464</span></a>
</span><span id="LinearRegression.score-465"><a href="#LinearRegression.score-465"><span class="linenos">465</span></a>
</span><span id="LinearRegression.score-466"><a href="#LinearRegression.score-466"><span class="linenos">466</span></a><span class="sd">        Returns</span>
</span><span id="LinearRegression.score-467"><a href="#LinearRegression.score-467"><span class="linenos">467</span></a><span class="sd">        -------</span>
</span><span id="LinearRegression.score-468"><a href="#LinearRegression.score-468"><span class="linenos">468</span></a>
</span><span id="LinearRegression.score-469"><a href="#LinearRegression.score-469"><span class="linenos">469</span></a><span class="sd">        `np.float64`</span>
</span><span id="LinearRegression.score-470"><a href="#LinearRegression.score-470"><span class="linenos">470</span></a><span class="sd">        - The computed cost</span>
</span><span id="LinearRegression.score-471"><a href="#LinearRegression.score-471"><span class="linenos">471</span></a>
</span><span id="LinearRegression.score-472"><a href="#LinearRegression.score-472"><span class="linenos">472</span></a><span class="sd">        ---</span>
</span><span id="LinearRegression.score-473"><a href="#LinearRegression.score-473"><span class="linenos">473</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LinearRegression.score-474"><a href="#LinearRegression.score-474"><span class="linenos">474</span></a>        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span><span id="LinearRegression.score-475"><a href="#LinearRegression.score-475"><span class="linenos">475</span></a>
</span><span id="LinearRegression.score-476"><a href="#LinearRegression.score-476"><span class="linenos">476</span></a>        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w</span>
</span><span id="LinearRegression.score-477"><a href="#LinearRegression.score-477"><span class="linenos">477</span></a>        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_intercept</span> <span class="k">if</span> <span class="n">b</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b</span>
</span><span id="LinearRegression.score-478"><a href="#LinearRegression.score-478"><span class="linenos">478</span></a>
</span><span id="LinearRegression.score-479"><a href="#LinearRegression.score-479"><span class="linenos">479</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cost</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><h3 id="return-the-cost-for-given-x-and-y">Return the cost for given X and Y.</h3>

<h2 id="parameters">Parameters</h2>

<p><code>X</code> : np.ndarray</p>

<ul>
<li>The input array of shape (n_samples, n_features) or (n_samples,)</li>
</ul>

<p><code>Y</code> : np.ndarray</p>

<ul>
<li>The output array of shape (n_samples,) or (n_samples, 1)</li>
</ul>

<p><code>w</code> : np.ndarray, optional</p>

<ul>
<li>The weight array, by default None</li>
<li>If None, then the weight array will be cosidered as the trained
weight array</li>
</ul>

<p><code>b</code> : np.float64, optional</p>

<ul>
<li>The intercept, by default None</li>
<li>If None, then the intercept will be cosidered as the trained
intercept</li>
</ul>

<h2 id="returns">Returns</h2>

<p><code>np.float64</code></p>

<ul>
<li>The computed cost</li>
</ul>

<hr />
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>learnML.interfaces.iregression.IRegression</dt>
                                <dd id="LinearRegression.get_cost_history" class="function">get_cost_history</dd>
                <dd id="LinearRegression.get_parameter_history" class="function">get_parameter_history</dd>
                <dd id="LinearRegression.get_weights" class="function">get_weights</dd>
                <dd id="LinearRegression.get_intercept" class="function">get_intercept</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="PolynomialRegression">
                            <input id="PolynomialRegression-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">PolynomialRegression</span><wbr>(<span class="base"><a href="#LinearRegression">learnML.regression.LinearRegression</a></span>):

                <label class="view-source-button" for="PolynomialRegression-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PolynomialRegression"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PolynomialRegression-11"><a href="#PolynomialRegression-11"><span class="linenos"> 11</span></a><span class="k">class</span> <span class="nc">PolynomialRegression</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">):</span>
</span><span id="PolynomialRegression-12"><a href="#PolynomialRegression-12"><span class="linenos"> 12</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-13"><a href="#PolynomialRegression-13"><span class="linenos"> 13</span></a><span class="sd">    # Polynomial Linear Regression Model</span>
</span><span id="PolynomialRegression-14"><a href="#PolynomialRegression-14"><span class="linenos"> 14</span></a>
</span><span id="PolynomialRegression-15"><a href="#PolynomialRegression-15"><span class="linenos"> 15</span></a><span class="sd">    Polynomial Regression is an extension of Linear Regression that allows for the modeling of nonlinear relationships between the input features and the target variable. It achieves this by introducing polynomial features, which are derived from raising the original input features to various powers. This approach can capture more complex patterns in the data and provide a higher degree of flexibility in modeling.</span>
</span><span id="PolynomialRegression-16"><a href="#PolynomialRegression-16"><span class="linenos"> 16</span></a>
</span><span id="PolynomialRegression-17"><a href="#PolynomialRegression-17"><span class="linenos"> 17</span></a><span class="sd">    ---</span>
</span><span id="PolynomialRegression-18"><a href="#PolynomialRegression-18"><span class="linenos"> 18</span></a>
</span><span id="PolynomialRegression-19"><a href="#PolynomialRegression-19"><span class="linenos"> 19</span></a><span class="sd">    ## Mathematical Approach</span>
</span><span id="PolynomialRegression-20"><a href="#PolynomialRegression-20"><span class="linenos"> 20</span></a>
</span><span id="PolynomialRegression-21"><a href="#PolynomialRegression-21"><span class="linenos"> 21</span></a><span class="sd">    Polynomial Regression aims to approximate the relationship between the input feature `x` and the target variable `y` using a polynomial equation of the form:</span>
</span><span id="PolynomialRegression-22"><a href="#PolynomialRegression-22"><span class="linenos"> 22</span></a>
</span><span id="PolynomialRegression-23"><a href="#PolynomialRegression-23"><span class="linenos"> 23</span></a><span class="sd">    ```</span>
</span><span id="PolynomialRegression-24"><a href="#PolynomialRegression-24"><span class="linenos"> 24</span></a><span class="sd">    y = b0 + b1*x + b2*x^2 + ... + bn*x^n</span>
</span><span id="PolynomialRegression-25"><a href="#PolynomialRegression-25"><span class="linenos"> 25</span></a><span class="sd">    ```</span>
</span><span id="PolynomialRegression-26"><a href="#PolynomialRegression-26"><span class="linenos"> 26</span></a>
</span><span id="PolynomialRegression-27"><a href="#PolynomialRegression-27"><span class="linenos"> 27</span></a><span class="sd">    Where:</span>
</span><span id="PolynomialRegression-28"><a href="#PolynomialRegression-28"><span class="linenos"> 28</span></a>
</span><span id="PolynomialRegression-29"><a href="#PolynomialRegression-29"><span class="linenos"> 29</span></a><span class="sd">    - `y` is the predicted output (target variable).</span>
</span><span id="PolynomialRegression-30"><a href="#PolynomialRegression-30"><span class="linenos"> 30</span></a><span class="sd">    - `x` is the input feature.</span>
</span><span id="PolynomialRegression-31"><a href="#PolynomialRegression-31"><span class="linenos"> 31</span></a><span class="sd">    - `b0, b1, ..., bn` are the coefficients of the polynomial terms.</span>
</span><span id="PolynomialRegression-32"><a href="#PolynomialRegression-32"><span class="linenos"> 32</span></a><span class="sd">    - `n` is the degree of the polynomial.</span>
</span><span id="PolynomialRegression-33"><a href="#PolynomialRegression-33"><span class="linenos"> 33</span></a>
</span><span id="PolynomialRegression-34"><a href="#PolynomialRegression-34"><span class="linenos"> 34</span></a><span class="sd">    The degree `n` determines the complexity of the polynomial curve. By increasing the degree, the model can fit the training data more closely, but it might also lead to overfitting.</span>
</span><span id="PolynomialRegression-35"><a href="#PolynomialRegression-35"><span class="linenos"> 35</span></a>
</span><span id="PolynomialRegression-36"><a href="#PolynomialRegression-36"><span class="linenos"> 36</span></a><span class="sd">    Polynomial Regression is implemented using a linear regression model by treating the polynomial terms as separate input features. The model learns the optimal coefficients `b0, b1, ..., bn` that minimize the difference between predicted values and actual target values.</span>
</span><span id="PolynomialRegression-37"><a href="#PolynomialRegression-37"><span class="linenos"> 37</span></a>
</span><span id="PolynomialRegression-38"><a href="#PolynomialRegression-38"><span class="linenos"> 38</span></a><span class="sd">    ---</span>
</span><span id="PolynomialRegression-39"><a href="#PolynomialRegression-39"><span class="linenos"> 39</span></a>
</span><span id="PolynomialRegression-40"><a href="#PolynomialRegression-40"><span class="linenos"> 40</span></a><span class="sd">    ## Usage</span>
</span><span id="PolynomialRegression-41"><a href="#PolynomialRegression-41"><span class="linenos"> 41</span></a>
</span><span id="PolynomialRegression-42"><a href="#PolynomialRegression-42"><span class="linenos"> 42</span></a><span class="sd">    To utilize the Polynomial Regression model, follow these steps:</span>
</span><span id="PolynomialRegression-43"><a href="#PolynomialRegression-43"><span class="linenos"> 43</span></a>
</span><span id="PolynomialRegression-44"><a href="#PolynomialRegression-44"><span class="linenos"> 44</span></a><span class="sd">    1. Import the `PolynomialRegression` class from the appropriate module.</span>
</span><span id="PolynomialRegression-45"><a href="#PolynomialRegression-45"><span class="linenos"> 45</span></a><span class="sd">    2. Create an instance of the `PolynomialRegression` class, specifying hyperparameters such as learning rate, degree, etc.</span>
</span><span id="PolynomialRegression-46"><a href="#PolynomialRegression-46"><span class="linenos"> 46</span></a><span class="sd">    3. Fit the model to your training data using the `fit` method.</span>
</span><span id="PolynomialRegression-47"><a href="#PolynomialRegression-47"><span class="linenos"> 47</span></a><span class="sd">    4. Make predictions on new data using the `predict` method.</span>
</span><span id="PolynomialRegression-48"><a href="#PolynomialRegression-48"><span class="linenos"> 48</span></a><span class="sd">    5. Evaluate the model&#39;s performance using the `score` method.</span>
</span><span id="PolynomialRegression-49"><a href="#PolynomialRegression-49"><span class="linenos"> 49</span></a>
</span><span id="PolynomialRegression-50"><a href="#PolynomialRegression-50"><span class="linenos"> 50</span></a><span class="sd">    ```python</span>
</span><span id="PolynomialRegression-51"><a href="#PolynomialRegression-51"><span class="linenos"> 51</span></a><span class="sd">    from learnML.regression import PolynomialRegression</span>
</span><span id="PolynomialRegression-52"><a href="#PolynomialRegression-52"><span class="linenos"> 52</span></a>
</span><span id="PolynomialRegression-53"><a href="#PolynomialRegression-53"><span class="linenos"> 53</span></a><span class="sd">    # Create an instance of PolynomialRegression</span>
</span><span id="PolynomialRegression-54"><a href="#PolynomialRegression-54"><span class="linenos"> 54</span></a><span class="sd">    model = PolynomialRegression(learning_rate=0.01, degree=2, n_iterations=1000)</span>
</span><span id="PolynomialRegression-55"><a href="#PolynomialRegression-55"><span class="linenos"> 55</span></a>
</span><span id="PolynomialRegression-56"><a href="#PolynomialRegression-56"><span class="linenos"> 56</span></a><span class="sd">    # Fit the model to training data</span>
</span><span id="PolynomialRegression-57"><a href="#PolynomialRegression-57"><span class="linenos"> 57</span></a><span class="sd">    model.fit(X_train, Y_train)</span>
</span><span id="PolynomialRegression-58"><a href="#PolynomialRegression-58"><span class="linenos"> 58</span></a>
</span><span id="PolynomialRegression-59"><a href="#PolynomialRegression-59"><span class="linenos"> 59</span></a><span class="sd">    # Make predictions on new data</span>
</span><span id="PolynomialRegression-60"><a href="#PolynomialRegression-60"><span class="linenos"> 60</span></a><span class="sd">    predictions = model.predict(X_test)</span>
</span><span id="PolynomialRegression-61"><a href="#PolynomialRegression-61"><span class="linenos"> 61</span></a>
</span><span id="PolynomialRegression-62"><a href="#PolynomialRegression-62"><span class="linenos"> 62</span></a><span class="sd">    # Calculate the model&#39;s score</span>
</span><span id="PolynomialRegression-63"><a href="#PolynomialRegression-63"><span class="linenos"> 63</span></a><span class="sd">    model_score = model.score(X_test, Y_test)</span>
</span><span id="PolynomialRegression-64"><a href="#PolynomialRegression-64"><span class="linenos"> 64</span></a><span class="sd">    ```</span>
</span><span id="PolynomialRegression-65"><a href="#PolynomialRegression-65"><span class="linenos"> 65</span></a>
</span><span id="PolynomialRegression-66"><a href="#PolynomialRegression-66"><span class="linenos"> 66</span></a><span class="sd">    ---</span>
</span><span id="PolynomialRegression-67"><a href="#PolynomialRegression-67"><span class="linenos"> 67</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-68"><a href="#PolynomialRegression-68"><span class="linenos"> 68</span></a>
</span><span id="PolynomialRegression-69"><a href="#PolynomialRegression-69"><span class="linenos"> 69</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="PolynomialRegression-70"><a href="#PolynomialRegression-70"><span class="linenos"> 70</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="PolynomialRegression-71"><a href="#PolynomialRegression-71"><span class="linenos"> 71</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="PolynomialRegression-72"><a href="#PolynomialRegression-72"><span class="linenos"> 72</span></a>        <span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="PolynomialRegression-73"><a href="#PolynomialRegression-73"><span class="linenos"> 73</span></a>        <span class="n">degree</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
</span><span id="PolynomialRegression-74"><a href="#PolynomialRegression-74"><span class="linenos"> 74</span></a>        <span class="n">lambda_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="PolynomialRegression-75"><a href="#PolynomialRegression-75"><span class="linenos"> 75</span></a>        <span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="PolynomialRegression-76"><a href="#PolynomialRegression-76"><span class="linenos"> 76</span></a>        <span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="PolynomialRegression-77"><a href="#PolynomialRegression-77"><span class="linenos"> 77</span></a>        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="PolynomialRegression-78"><a href="#PolynomialRegression-78"><span class="linenos"> 78</span></a>        <span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="PolynomialRegression-79"><a href="#PolynomialRegression-79"><span class="linenos"> 79</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PolynomialRegression-80"><a href="#PolynomialRegression-80"><span class="linenos"> 80</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-81"><a href="#PolynomialRegression-81"><span class="linenos"> 81</span></a><span class="sd">        Parameters</span>
</span><span id="PolynomialRegression-82"><a href="#PolynomialRegression-82"><span class="linenos"> 82</span></a><span class="sd">        ----------</span>
</span><span id="PolynomialRegression-83"><a href="#PolynomialRegression-83"><span class="linenos"> 83</span></a>
</span><span id="PolynomialRegression-84"><a href="#PolynomialRegression-84"><span class="linenos"> 84</span></a><span class="sd">        `learning_rate` : np.float64, optional</span>
</span><span id="PolynomialRegression-85"><a href="#PolynomialRegression-85"><span class="linenos"> 85</span></a><span class="sd">        - The learning rate, by default 0.001</span>
</span><span id="PolynomialRegression-86"><a href="#PolynomialRegression-86"><span class="linenos"> 86</span></a><span class="sd">        - The learning rate determines how much the weights are updated at each iteration</span>
</span><span id="PolynomialRegression-87"><a href="#PolynomialRegression-87"><span class="linenos"> 87</span></a><span class="sd">        - A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</span>
</span><span id="PolynomialRegression-88"><a href="#PolynomialRegression-88"><span class="linenos"> 88</span></a>
</span><span id="PolynomialRegression-89"><a href="#PolynomialRegression-89"><span class="linenos"> 89</span></a><span class="sd">        `n_iterations` : int, optional</span>
</span><span id="PolynomialRegression-90"><a href="#PolynomialRegression-90"><span class="linenos"> 90</span></a><span class="sd">        - The number of iterations, by default 1000</span>
</span><span id="PolynomialRegression-91"><a href="#PolynomialRegression-91"><span class="linenos"> 91</span></a><span class="sd">        - The number of iterations determines how many times the weights are updated</span>
</span><span id="PolynomialRegression-92"><a href="#PolynomialRegression-92"><span class="linenos"> 92</span></a><span class="sd">        - A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</span>
</span><span id="PolynomialRegression-93"><a href="#PolynomialRegression-93"><span class="linenos"> 93</span></a>
</span><span id="PolynomialRegression-94"><a href="#PolynomialRegression-94"><span class="linenos"> 94</span></a><span class="sd">        `degree` : Union[int, List[int], Dict[int, Union[int, List[int]]]], optional</span>
</span><span id="PolynomialRegression-95"><a href="#PolynomialRegression-95"><span class="linenos"> 95</span></a><span class="sd">        - The degree of the polynomial, by default 2</span>
</span><span id="PolynomialRegression-96"><a href="#PolynomialRegression-96"><span class="linenos"> 96</span></a><span class="sd">        - It can be a single integer, a list of integers or a dictionary of integers and lists of integers</span>
</span><span id="PolynomialRegression-97"><a href="#PolynomialRegression-97"><span class="linenos"> 97</span></a><span class="sd">        - If it is a single integer, then the polynomial features of all the features of the input array will be generated with the given degree from 1 to the given degree</span>
</span><span id="PolynomialRegression-98"><a href="#PolynomialRegression-98"><span class="linenos"> 98</span></a><span class="sd">        - If it is a list of integers, then the polynomial features of all the features of the input array will be generated with the given degrees</span>
</span><span id="PolynomialRegression-99"><a href="#PolynomialRegression-99"><span class="linenos"> 99</span></a><span class="sd">        - If it is a dictionary of integers and lists of integers, then for each key-value pair in the dictionary, the polynomial features of the features at the key index of the input array will be generated with the given degrees in the list</span>
</span><span id="PolynomialRegression-100"><a href="#PolynomialRegression-100"><span class="linenos">100</span></a>
</span><span id="PolynomialRegression-101"><a href="#PolynomialRegression-101"><span class="linenos">101</span></a><span class="sd">        `lambda_` : np.float64, optional</span>
</span><span id="PolynomialRegression-102"><a href="#PolynomialRegression-102"><span class="linenos">102</span></a><span class="sd">        - The regularization parameter, by default 0</span>
</span><span id="PolynomialRegression-103"><a href="#PolynomialRegression-103"><span class="linenos">103</span></a><span class="sd">        - The regularization parameter helps prevent overfitting by penalizing large weights</span>
</span><span id="PolynomialRegression-104"><a href="#PolynomialRegression-104"><span class="linenos">104</span></a><span class="sd">        - A higher regularization parameter will penalize large weights more, but a lower regularization parameter may not be enough to prevent overfitting</span>
</span><span id="PolynomialRegression-105"><a href="#PolynomialRegression-105"><span class="linenos">105</span></a>
</span><span id="PolynomialRegression-106"><a href="#PolynomialRegression-106"><span class="linenos">106</span></a><span class="sd">        `x_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="PolynomialRegression-107"><a href="#PolynomialRegression-107"><span class="linenos">107</span></a><span class="sd">        - The feature engineering for the input data, by default None</span>
</span><span id="PolynomialRegression-108"><a href="#PolynomialRegression-108"><span class="linenos">108</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="PolynomialRegression-109"><a href="#PolynomialRegression-109"><span class="linenos">109</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all input data</span>
</span><span id="PolynomialRegression-110"><a href="#PolynomialRegression-110"><span class="linenos">110</span></a>
</span><span id="PolynomialRegression-111"><a href="#PolynomialRegression-111"><span class="linenos">111</span></a><span class="sd">        `y_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="PolynomialRegression-112"><a href="#PolynomialRegression-112"><span class="linenos">112</span></a><span class="sd">        - The feature engineering for the output data, by default None</span>
</span><span id="PolynomialRegression-113"><a href="#PolynomialRegression-113"><span class="linenos">113</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="PolynomialRegression-114"><a href="#PolynomialRegression-114"><span class="linenos">114</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all output data</span>
</span><span id="PolynomialRegression-115"><a href="#PolynomialRegression-115"><span class="linenos">115</span></a>
</span><span id="PolynomialRegression-116"><a href="#PolynomialRegression-116"><span class="linenos">116</span></a><span class="sd">        `debug` : bool, optional</span>
</span><span id="PolynomialRegression-117"><a href="#PolynomialRegression-117"><span class="linenos">117</span></a><span class="sd">        - Whether to print debug messages, by default True</span>
</span><span id="PolynomialRegression-118"><a href="#PolynomialRegression-118"><span class="linenos">118</span></a><span class="sd">        - Debug messages include the cost at each iteration</span>
</span><span id="PolynomialRegression-119"><a href="#PolynomialRegression-119"><span class="linenos">119</span></a>
</span><span id="PolynomialRegression-120"><a href="#PolynomialRegression-120"><span class="linenos">120</span></a><span class="sd">        `copy_x` : bool, optional</span>
</span><span id="PolynomialRegression-121"><a href="#PolynomialRegression-121"><span class="linenos">121</span></a><span class="sd">        - Whether to copy the input array, by default True</span>
</span><span id="PolynomialRegression-122"><a href="#PolynomialRegression-122"><span class="linenos">122</span></a><span class="sd">        - If False, the input array will be overwritten</span>
</span><span id="PolynomialRegression-123"><a href="#PolynomialRegression-123"><span class="linenos">123</span></a>
</span><span id="PolynomialRegression-124"><a href="#PolynomialRegression-124"><span class="linenos">124</span></a>
</span><span id="PolynomialRegression-125"><a href="#PolynomialRegression-125"><span class="linenos">125</span></a><span class="sd">        Degree</span>
</span><span id="PolynomialRegression-126"><a href="#PolynomialRegression-126"><span class="linenos">126</span></a><span class="sd">        ------</span>
</span><span id="PolynomialRegression-127"><a href="#PolynomialRegression-127"><span class="linenos">127</span></a>
</span><span id="PolynomialRegression-128"><a href="#PolynomialRegression-128"><span class="linenos">128</span></a><span class="sd">        Examples:</span>
</span><span id="PolynomialRegression-129"><a href="#PolynomialRegression-129"><span class="linenos">129</span></a>
</span><span id="PolynomialRegression-130"><a href="#PolynomialRegression-130"><span class="linenos">130</span></a><span class="sd">        ```python</span>
</span><span id="PolynomialRegression-131"><a href="#PolynomialRegression-131"><span class="linenos">131</span></a><span class="sd">        degree = 2</span>
</span><span id="PolynomialRegression-132"><a href="#PolynomialRegression-132"><span class="linenos">132</span></a><span class="sd">        # Generate polynomial features of degree 1 and 2 for all the features</span>
</span><span id="PolynomialRegression-133"><a href="#PolynomialRegression-133"><span class="linenos">133</span></a>
</span><span id="PolynomialRegression-134"><a href="#PolynomialRegression-134"><span class="linenos">134</span></a><span class="sd">        degree = [2, 3, 6]</span>
</span><span id="PolynomialRegression-135"><a href="#PolynomialRegression-135"><span class="linenos">135</span></a><span class="sd">        # Generate polynomial features of degree 2, 3 and 6 for all the features</span>
</span><span id="PolynomialRegression-136"><a href="#PolynomialRegression-136"><span class="linenos">136</span></a>
</span><span id="PolynomialRegression-137"><a href="#PolynomialRegression-137"><span class="linenos">137</span></a><span class="sd">        degree = {0: [2, 3, 6], 1: 2}</span>
</span><span id="PolynomialRegression-138"><a href="#PolynomialRegression-138"><span class="linenos">138</span></a><span class="sd">        # Generate polynomial features of degree 2, 3 and 6 for the first feature</span>
</span><span id="PolynomialRegression-139"><a href="#PolynomialRegression-139"><span class="linenos">139</span></a><span class="sd">        # Generate polynomial features of degree 1 and 2 for the second feature</span>
</span><span id="PolynomialRegression-140"><a href="#PolynomialRegression-140"><span class="linenos">140</span></a><span class="sd">        ```</span>
</span><span id="PolynomialRegression-141"><a href="#PolynomialRegression-141"><span class="linenos">141</span></a>
</span><span id="PolynomialRegression-142"><a href="#PolynomialRegression-142"><span class="linenos">142</span></a><span class="sd">        ---</span>
</span><span id="PolynomialRegression-143"><a href="#PolynomialRegression-143"><span class="linenos">143</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-144"><a href="#PolynomialRegression-144"><span class="linenos">144</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="PolynomialRegression-145"><a href="#PolynomialRegression-145"><span class="linenos">145</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="PolynomialRegression-146"><a href="#PolynomialRegression-146"><span class="linenos">146</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="PolynomialRegression-147"><a href="#PolynomialRegression-147"><span class="linenos">147</span></a>            <span class="n">lambda_</span><span class="o">=</span><span class="n">lambda_</span><span class="p">,</span>
</span><span id="PolynomialRegression-148"><a href="#PolynomialRegression-148"><span class="linenos">148</span></a>            <span class="n">x_scalar</span><span class="o">=</span><span class="n">x_scalar</span><span class="p">,</span>
</span><span id="PolynomialRegression-149"><a href="#PolynomialRegression-149"><span class="linenos">149</span></a>            <span class="n">y_scalar</span><span class="o">=</span><span class="n">y_scalar</span><span class="p">,</span>
</span><span id="PolynomialRegression-150"><a href="#PolynomialRegression-150"><span class="linenos">150</span></a>            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
</span><span id="PolynomialRegression-151"><a href="#PolynomialRegression-151"><span class="linenos">151</span></a>            <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
</span><span id="PolynomialRegression-152"><a href="#PolynomialRegression-152"><span class="linenos">152</span></a>        <span class="p">)</span>
</span><span id="PolynomialRegression-153"><a href="#PolynomialRegression-153"><span class="linenos">153</span></a>
</span><span id="PolynomialRegression-154"><a href="#PolynomialRegression-154"><span class="linenos">154</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">=</span> <span class="n">degree</span>
</span><span id="PolynomialRegression-155"><a href="#PolynomialRegression-155"><span class="linenos">155</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_polynomial_features</span><span class="p">:</span> <span class="n">PolynomialFeatures</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PolynomialRegression-156"><a href="#PolynomialRegression-156"><span class="linenos">156</span></a>
</span><span id="PolynomialRegression-157"><a href="#PolynomialRegression-157"><span class="linenos">157</span></a>    <span class="k">def</span> <span class="nf">_get_polynomial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="PolynomialRegression-158"><a href="#PolynomialRegression-158"><span class="linenos">158</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-159"><a href="#PolynomialRegression-159"><span class="linenos">159</span></a><span class="sd">        ### Return the polynomial of the given degree</span>
</span><span id="PolynomialRegression-160"><a href="#PolynomialRegression-160"><span class="linenos">160</span></a>
</span><span id="PolynomialRegression-161"><a href="#PolynomialRegression-161"><span class="linenos">161</span></a><span class="sd">        Parameters</span>
</span><span id="PolynomialRegression-162"><a href="#PolynomialRegression-162"><span class="linenos">162</span></a><span class="sd">        ----------</span>
</span><span id="PolynomialRegression-163"><a href="#PolynomialRegression-163"><span class="linenos">163</span></a>
</span><span id="PolynomialRegression-164"><a href="#PolynomialRegression-164"><span class="linenos">164</span></a><span class="sd">        `data` : np.ndarray</span>
</span><span id="PolynomialRegression-165"><a href="#PolynomialRegression-165"><span class="linenos">165</span></a><span class="sd">        - The input array of shape (n_samples, n_features)</span>
</span><span id="PolynomialRegression-166"><a href="#PolynomialRegression-166"><span class="linenos">166</span></a>
</span><span id="PolynomialRegression-167"><a href="#PolynomialRegression-167"><span class="linenos">167</span></a>
</span><span id="PolynomialRegression-168"><a href="#PolynomialRegression-168"><span class="linenos">168</span></a><span class="sd">        Returns</span>
</span><span id="PolynomialRegression-169"><a href="#PolynomialRegression-169"><span class="linenos">169</span></a><span class="sd">        -------</span>
</span><span id="PolynomialRegression-170"><a href="#PolynomialRegression-170"><span class="linenos">170</span></a>
</span><span id="PolynomialRegression-171"><a href="#PolynomialRegression-171"><span class="linenos">171</span></a><span class="sd">        `np.ndarray`</span>
</span><span id="PolynomialRegression-172"><a href="#PolynomialRegression-172"><span class="linenos">172</span></a><span class="sd">        - The polynomial of the given degree of shape (n_samples, n_features * degree)</span>
</span><span id="PolynomialRegression-173"><a href="#PolynomialRegression-173"><span class="linenos">173</span></a>
</span><span id="PolynomialRegression-174"><a href="#PolynomialRegression-174"><span class="linenos">174</span></a><span class="sd">        ---</span>
</span><span id="PolynomialRegression-175"><a href="#PolynomialRegression-175"><span class="linenos">175</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-176"><a href="#PolynomialRegression-176"><span class="linenos">176</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_polynomial_features</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PolynomialRegression-177"><a href="#PolynomialRegression-177"><span class="linenos">177</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">_polynomial_features</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span>
</span><span id="PolynomialRegression-178"><a href="#PolynomialRegression-178"><span class="linenos">178</span></a>                <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_degree</span>
</span><span id="PolynomialRegression-179"><a href="#PolynomialRegression-179"><span class="linenos">179</span></a>            <span class="p">)</span>
</span><span id="PolynomialRegression-180"><a href="#PolynomialRegression-180"><span class="linenos">180</span></a>
</span><span id="PolynomialRegression-181"><a href="#PolynomialRegression-181"><span class="linenos">181</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_polynomial_features</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span><span id="PolynomialRegression-182"><a href="#PolynomialRegression-182"><span class="linenos">182</span></a>
</span><span id="PolynomialRegression-183"><a href="#PolynomialRegression-183"><span class="linenos">183</span></a>    <span class="k">def</span> <span class="nf">_validate_data</span><span class="p">(</span>
</span><span id="PolynomialRegression-184"><a href="#PolynomialRegression-184"><span class="linenos">184</span></a>        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="PolynomialRegression-185"><a href="#PolynomialRegression-185"><span class="linenos">185</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
</span><span id="PolynomialRegression-186"><a href="#PolynomialRegression-186"><span class="linenos">186</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-187"><a href="#PolynomialRegression-187"><span class="linenos">187</span></a><span class="sd">        ### Return the input and output arrays.</span>
</span><span id="PolynomialRegression-188"><a href="#PolynomialRegression-188"><span class="linenos">188</span></a>
</span><span id="PolynomialRegression-189"><a href="#PolynomialRegression-189"><span class="linenos">189</span></a><span class="sd">        Parameters</span>
</span><span id="PolynomialRegression-190"><a href="#PolynomialRegression-190"><span class="linenos">190</span></a><span class="sd">        ----------</span>
</span><span id="PolynomialRegression-191"><a href="#PolynomialRegression-191"><span class="linenos">191</span></a>
</span><span id="PolynomialRegression-192"><a href="#PolynomialRegression-192"><span class="linenos">192</span></a><span class="sd">        `X` : np.ndarray</span>
</span><span id="PolynomialRegression-193"><a href="#PolynomialRegression-193"><span class="linenos">193</span></a><span class="sd">        - The input array of shape (n_samples, n_features)</span>
</span><span id="PolynomialRegression-194"><a href="#PolynomialRegression-194"><span class="linenos">194</span></a>
</span><span id="PolynomialRegression-195"><a href="#PolynomialRegression-195"><span class="linenos">195</span></a><span class="sd">        `Y` : np.ndarray, optional</span>
</span><span id="PolynomialRegression-196"><a href="#PolynomialRegression-196"><span class="linenos">196</span></a><span class="sd">        - The output array of shape (n_samples,) or (n_samples, 1)</span>
</span><span id="PolynomialRegression-197"><a href="#PolynomialRegression-197"><span class="linenos">197</span></a>
</span><span id="PolynomialRegression-198"><a href="#PolynomialRegression-198"><span class="linenos">198</span></a>
</span><span id="PolynomialRegression-199"><a href="#PolynomialRegression-199"><span class="linenos">199</span></a><span class="sd">        Returns</span>
</span><span id="PolynomialRegression-200"><a href="#PolynomialRegression-200"><span class="linenos">200</span></a><span class="sd">        -------</span>
</span><span id="PolynomialRegression-201"><a href="#PolynomialRegression-201"><span class="linenos">201</span></a>
</span><span id="PolynomialRegression-202"><a href="#PolynomialRegression-202"><span class="linenos">202</span></a><span class="sd">        `Tuple[np.ndarray, np.ndarray]`</span>
</span><span id="PolynomialRegression-203"><a href="#PolynomialRegression-203"><span class="linenos">203</span></a><span class="sd">        - The input and output arrays</span>
</span><span id="PolynomialRegression-204"><a href="#PolynomialRegression-204"><span class="linenos">204</span></a>
</span><span id="PolynomialRegression-205"><a href="#PolynomialRegression-205"><span class="linenos">205</span></a><span class="sd">        ---</span>
</span><span id="PolynomialRegression-206"><a href="#PolynomialRegression-206"><span class="linenos">206</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PolynomialRegression-207"><a href="#PolynomialRegression-207"><span class="linenos">207</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_copy_x</span><span class="p">:</span>
</span><span id="PolynomialRegression-208"><a href="#PolynomialRegression-208"><span class="linenos">208</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="PolynomialRegression-209"><a href="#PolynomialRegression-209"><span class="linenos">209</span></a>
</span><span id="PolynomialRegression-210"><a href="#PolynomialRegression-210"><span class="linenos">210</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_numpy_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="PolynomialRegression-211"><a href="#PolynomialRegression-211"><span class="linenos">211</span></a>        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_numpy_array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
</span><span id="PolynomialRegression-212"><a href="#PolynomialRegression-212"><span class="linenos">212</span></a>
</span><span id="PolynomialRegression-213"><a href="#PolynomialRegression-213"><span class="linenos">213</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PolynomialRegression-214"><a href="#PolynomialRegression-214"><span class="linenos">214</span></a>            <span class="k">assert</span> <span class="p">(</span>
</span><span id="PolynomialRegression-215"><a href="#PolynomialRegression-215"><span class="linenos">215</span></a>                <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="PolynomialRegression-216"><a href="#PolynomialRegression-216"><span class="linenos">216</span></a>            <span class="p">),</span> <span class="s2">&quot;X and Y must have the same number of samples&quot;</span>
</span><span id="PolynomialRegression-217"><a href="#PolynomialRegression-217"><span class="linenos">217</span></a>
</span><span id="PolynomialRegression-218"><a href="#PolynomialRegression-218"><span class="linenos">218</span></a>        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="PolynomialRegression-219"><a href="#PolynomialRegression-219"><span class="linenos">219</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="PolynomialRegression-220"><a href="#PolynomialRegression-220"><span class="linenos">220</span></a>
</span><span id="PolynomialRegression-221"><a href="#PolynomialRegression-221"><span class="linenos">221</span></a>        <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x_scalar</span><span class="p">:</span>
</span><span id="PolynomialRegression-222"><a href="#PolynomialRegression-222"><span class="linenos">222</span></a>            <span class="n">X</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="PolynomialRegression-223"><a href="#PolynomialRegression-223"><span class="linenos">223</span></a>
</span><span id="PolynomialRegression-224"><a href="#PolynomialRegression-224"><span class="linenos">224</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PolynomialRegression-225"><a href="#PolynomialRegression-225"><span class="linenos">225</span></a>            <span class="k">if</span> <span class="n">Y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span><span id="PolynomialRegression-226"><a href="#PolynomialRegression-226"><span class="linenos">226</span></a>                <span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="PolynomialRegression-227"><a href="#PolynomialRegression-227"><span class="linenos">227</span></a>
</span><span id="PolynomialRegression-228"><a href="#PolynomialRegression-228"><span class="linenos">228</span></a>            <span class="k">for</span> <span class="n">scalar</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_y_scalar</span><span class="p">:</span>
</span><span id="PolynomialRegression-229"><a href="#PolynomialRegression-229"><span class="linenos">229</span></a>                <span class="n">Y</span> <span class="o">=</span> <span class="n">scalar</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</span><span id="PolynomialRegression-230"><a href="#PolynomialRegression-230"><span class="linenos">230</span></a>
</span><span id="PolynomialRegression-231"><a href="#PolynomialRegression-231"><span class="linenos">231</span></a>        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_polynomial</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
</span><span id="PolynomialRegression-232"><a href="#PolynomialRegression-232"><span class="linenos">232</span></a>
</span><span id="PolynomialRegression-233"><a href="#PolynomialRegression-233"><span class="linenos">233</span></a>        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PolynomialRegression-234"><a href="#PolynomialRegression-234"><span class="linenos">234</span></a>            <span class="k">return</span> <span class="n">X</span>
</span><span id="PolynomialRegression-235"><a href="#PolynomialRegression-235"><span class="linenos">235</span></a>        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</span></pre></div>


            <div class="docstring"><h1 id="polynomial-linear-regression-model">Polynomial Linear Regression Model</h1>

<p>Polynomial Regression is an extension of Linear Regression that allows for the modeling of nonlinear relationships between the input features and the target variable. It achieves this by introducing polynomial features, which are derived from raising the original input features to various powers. This approach can capture more complex patterns in the data and provide a higher degree of flexibility in modeling.</p>

<hr />

<h2 id="mathematical-approach">Mathematical Approach</h2>

<p>Polynomial Regression aims to approximate the relationship between the input feature <code>x</code> and the target variable <code>y</code> using a polynomial equation of the form:</p>

<pre><code>y = b0 + b1*x + b2*x^2 + ... + bn*x^n
</code></pre>

<p>Where:</p>

<ul>
<li><code>y</code> is the predicted output (target variable).</li>
<li><code>x</code> is the input feature.</li>
<li><code>b0, b1, ..., bn</code> are the coefficients of the polynomial terms.</li>
<li><code>n</code> is the degree of the polynomial.</li>
</ul>

<p>The degree <code>n</code> determines the complexity of the polynomial curve. By increasing the degree, the model can fit the training data more closely, but it might also lead to overfitting.</p>

<p>Polynomial Regression is implemented using a linear regression model by treating the polynomial terms as separate input features. The model learns the optimal coefficients <code>b0, b1, ..., bn</code> that minimize the difference between predicted values and actual target values.</p>

<hr />

<h2 id="usage">Usage</h2>

<p>To utilize the Polynomial Regression model, follow these steps:</p>

<ol>
<li>Import the <code><a href="#PolynomialRegression">PolynomialRegression</a></code> class from the appropriate module.</li>
<li>Create an instance of the <code><a href="#PolynomialRegression">PolynomialRegression</a></code> class, specifying hyperparameters such as learning rate, degree, etc.</li>
<li>Fit the model to your training data using the <code><a href="#PolynomialRegression.fit">fit</a></code> method.</li>
<li>Make predictions on new data using the <code><a href="#PolynomialRegression.predict">predict</a></code> method.</li>
<li>Evaluate the model's performance using the <code><a href="#PolynomialRegression.score">score</a></code> method.</li>
</ol>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">from</span> <span class="nn"><a href="">learnML.regression</a></span> <span class="kn">import</span> <span class="n">PolynomialRegression</span>

<span class="c1"># Create an instance of PolynomialRegression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PolynomialRegression</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Fit the model to training data</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Make predictions on new data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate the model&#39;s score</span>
<span class="n">model_score</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
</code></pre>
</div>

<hr />
</div>


                            <div id="PolynomialRegression.__init__" class="classattr">
                                        <input id="PolynomialRegression.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">PolynomialRegression</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">learning_rate</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span>,</span><span class="param">	<span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span>,</span><span class="param">	<span class="n">degree</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]</span> <span class="o">=</span> <span class="mi">2</span>,</span><span class="param">	<span class="n">lambda_</span><span class="p">:</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span>,</span><span class="param">	<span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">learnML</span><span class="o">.</span><span class="n">interfaces</span><span class="o">.</span><span class="n">ifeature_engineering</span><span class="o">.</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>,</span><span class="param">	<span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span></span>)</span>

                <label class="view-source-button" for="PolynomialRegression.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#PolynomialRegression.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="PolynomialRegression.__init__-69"><a href="#PolynomialRegression.__init__-69"><span class="linenos"> 69</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="PolynomialRegression.__init__-70"><a href="#PolynomialRegression.__init__-70"><span class="linenos"> 70</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-71"><a href="#PolynomialRegression.__init__-71"><span class="linenos"> 71</span></a>        <span class="n">learning_rate</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-72"><a href="#PolynomialRegression.__init__-72"><span class="linenos"> 72</span></a>        <span class="n">n_iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-73"><a href="#PolynomialRegression.__init__-73"><span class="linenos"> 73</span></a>        <span class="n">degree</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-74"><a href="#PolynomialRegression.__init__-74"><span class="linenos"> 74</span></a>        <span class="n">lambda_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-75"><a href="#PolynomialRegression.__init__-75"><span class="linenos"> 75</span></a>        <span class="n">x_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-76"><a href="#PolynomialRegression.__init__-76"><span class="linenos"> 76</span></a>        <span class="n">y_scalar</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">IFeatureEngineering</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-77"><a href="#PolynomialRegression.__init__-77"><span class="linenos"> 77</span></a>        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-78"><a href="#PolynomialRegression.__init__-78"><span class="linenos"> 78</span></a>        <span class="n">copy_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-79"><a href="#PolynomialRegression.__init__-79"><span class="linenos"> 79</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="PolynomialRegression.__init__-80"><a href="#PolynomialRegression.__init__-80"><span class="linenos"> 80</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="PolynomialRegression.__init__-81"><a href="#PolynomialRegression.__init__-81"><span class="linenos"> 81</span></a><span class="sd">        Parameters</span>
</span><span id="PolynomialRegression.__init__-82"><a href="#PolynomialRegression.__init__-82"><span class="linenos"> 82</span></a><span class="sd">        ----------</span>
</span><span id="PolynomialRegression.__init__-83"><a href="#PolynomialRegression.__init__-83"><span class="linenos"> 83</span></a>
</span><span id="PolynomialRegression.__init__-84"><a href="#PolynomialRegression.__init__-84"><span class="linenos"> 84</span></a><span class="sd">        `learning_rate` : np.float64, optional</span>
</span><span id="PolynomialRegression.__init__-85"><a href="#PolynomialRegression.__init__-85"><span class="linenos"> 85</span></a><span class="sd">        - The learning rate, by default 0.001</span>
</span><span id="PolynomialRegression.__init__-86"><a href="#PolynomialRegression.__init__-86"><span class="linenos"> 86</span></a><span class="sd">        - The learning rate determines how much the weights are updated at each iteration</span>
</span><span id="PolynomialRegression.__init__-87"><a href="#PolynomialRegression.__init__-87"><span class="linenos"> 87</span></a><span class="sd">        - A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</span>
</span><span id="PolynomialRegression.__init__-88"><a href="#PolynomialRegression.__init__-88"><span class="linenos"> 88</span></a>
</span><span id="PolynomialRegression.__init__-89"><a href="#PolynomialRegression.__init__-89"><span class="linenos"> 89</span></a><span class="sd">        `n_iterations` : int, optional</span>
</span><span id="PolynomialRegression.__init__-90"><a href="#PolynomialRegression.__init__-90"><span class="linenos"> 90</span></a><span class="sd">        - The number of iterations, by default 1000</span>
</span><span id="PolynomialRegression.__init__-91"><a href="#PolynomialRegression.__init__-91"><span class="linenos"> 91</span></a><span class="sd">        - The number of iterations determines how many times the weights are updated</span>
</span><span id="PolynomialRegression.__init__-92"><a href="#PolynomialRegression.__init__-92"><span class="linenos"> 92</span></a><span class="sd">        - A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</span>
</span><span id="PolynomialRegression.__init__-93"><a href="#PolynomialRegression.__init__-93"><span class="linenos"> 93</span></a>
</span><span id="PolynomialRegression.__init__-94"><a href="#PolynomialRegression.__init__-94"><span class="linenos"> 94</span></a><span class="sd">        `degree` : Union[int, List[int], Dict[int, Union[int, List[int]]]], optional</span>
</span><span id="PolynomialRegression.__init__-95"><a href="#PolynomialRegression.__init__-95"><span class="linenos"> 95</span></a><span class="sd">        - The degree of the polynomial, by default 2</span>
</span><span id="PolynomialRegression.__init__-96"><a href="#PolynomialRegression.__init__-96"><span class="linenos"> 96</span></a><span class="sd">        - It can be a single integer, a list of integers or a dictionary of integers and lists of integers</span>
</span><span id="PolynomialRegression.__init__-97"><a href="#PolynomialRegression.__init__-97"><span class="linenos"> 97</span></a><span class="sd">        - If it is a single integer, then the polynomial features of all the features of the input array will be generated with the given degree from 1 to the given degree</span>
</span><span id="PolynomialRegression.__init__-98"><a href="#PolynomialRegression.__init__-98"><span class="linenos"> 98</span></a><span class="sd">        - If it is a list of integers, then the polynomial features of all the features of the input array will be generated with the given degrees</span>
</span><span id="PolynomialRegression.__init__-99"><a href="#PolynomialRegression.__init__-99"><span class="linenos"> 99</span></a><span class="sd">        - If it is a dictionary of integers and lists of integers, then for each key-value pair in the dictionary, the polynomial features of the features at the key index of the input array will be generated with the given degrees in the list</span>
</span><span id="PolynomialRegression.__init__-100"><a href="#PolynomialRegression.__init__-100"><span class="linenos">100</span></a>
</span><span id="PolynomialRegression.__init__-101"><a href="#PolynomialRegression.__init__-101"><span class="linenos">101</span></a><span class="sd">        `lambda_` : np.float64, optional</span>
</span><span id="PolynomialRegression.__init__-102"><a href="#PolynomialRegression.__init__-102"><span class="linenos">102</span></a><span class="sd">        - The regularization parameter, by default 0</span>
</span><span id="PolynomialRegression.__init__-103"><a href="#PolynomialRegression.__init__-103"><span class="linenos">103</span></a><span class="sd">        - The regularization parameter helps prevent overfitting by penalizing large weights</span>
</span><span id="PolynomialRegression.__init__-104"><a href="#PolynomialRegression.__init__-104"><span class="linenos">104</span></a><span class="sd">        - A higher regularization parameter will penalize large weights more, but a lower regularization parameter may not be enough to prevent overfitting</span>
</span><span id="PolynomialRegression.__init__-105"><a href="#PolynomialRegression.__init__-105"><span class="linenos">105</span></a>
</span><span id="PolynomialRegression.__init__-106"><a href="#PolynomialRegression.__init__-106"><span class="linenos">106</span></a><span class="sd">        `x_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="PolynomialRegression.__init__-107"><a href="#PolynomialRegression.__init__-107"><span class="linenos">107</span></a><span class="sd">        - The feature engineering for the input data, by default None</span>
</span><span id="PolynomialRegression.__init__-108"><a href="#PolynomialRegression.__init__-108"><span class="linenos">108</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="PolynomialRegression.__init__-109"><a href="#PolynomialRegression.__init__-109"><span class="linenos">109</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all input data</span>
</span><span id="PolynomialRegression.__init__-110"><a href="#PolynomialRegression.__init__-110"><span class="linenos">110</span></a>
</span><span id="PolynomialRegression.__init__-111"><a href="#PolynomialRegression.__init__-111"><span class="linenos">111</span></a><span class="sd">        `y_scalar` : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</span>
</span><span id="PolynomialRegression.__init__-112"><a href="#PolynomialRegression.__init__-112"><span class="linenos">112</span></a><span class="sd">        - The feature engineering for the output data, by default None</span>
</span><span id="PolynomialRegression.__init__-113"><a href="#PolynomialRegression.__init__-113"><span class="linenos">113</span></a><span class="sd">        - If a list is provided, the feature engineering will be applied in the order provided</span>
</span><span id="PolynomialRegression.__init__-114"><a href="#PolynomialRegression.__init__-114"><span class="linenos">114</span></a><span class="sd">        - If a single feature engineering is provided, it will be applied to all output data</span>
</span><span id="PolynomialRegression.__init__-115"><a href="#PolynomialRegression.__init__-115"><span class="linenos">115</span></a>
</span><span id="PolynomialRegression.__init__-116"><a href="#PolynomialRegression.__init__-116"><span class="linenos">116</span></a><span class="sd">        `debug` : bool, optional</span>
</span><span id="PolynomialRegression.__init__-117"><a href="#PolynomialRegression.__init__-117"><span class="linenos">117</span></a><span class="sd">        - Whether to print debug messages, by default True</span>
</span><span id="PolynomialRegression.__init__-118"><a href="#PolynomialRegression.__init__-118"><span class="linenos">118</span></a><span class="sd">        - Debug messages include the cost at each iteration</span>
</span><span id="PolynomialRegression.__init__-119"><a href="#PolynomialRegression.__init__-119"><span class="linenos">119</span></a>
</span><span id="PolynomialRegression.__init__-120"><a href="#PolynomialRegression.__init__-120"><span class="linenos">120</span></a><span class="sd">        `copy_x` : bool, optional</span>
</span><span id="PolynomialRegression.__init__-121"><a href="#PolynomialRegression.__init__-121"><span class="linenos">121</span></a><span class="sd">        - Whether to copy the input array, by default True</span>
</span><span id="PolynomialRegression.__init__-122"><a href="#PolynomialRegression.__init__-122"><span class="linenos">122</span></a><span class="sd">        - If False, the input array will be overwritten</span>
</span><span id="PolynomialRegression.__init__-123"><a href="#PolynomialRegression.__init__-123"><span class="linenos">123</span></a>
</span><span id="PolynomialRegression.__init__-124"><a href="#PolynomialRegression.__init__-124"><span class="linenos">124</span></a>
</span><span id="PolynomialRegression.__init__-125"><a href="#PolynomialRegression.__init__-125"><span class="linenos">125</span></a><span class="sd">        Degree</span>
</span><span id="PolynomialRegression.__init__-126"><a href="#PolynomialRegression.__init__-126"><span class="linenos">126</span></a><span class="sd">        ------</span>
</span><span id="PolynomialRegression.__init__-127"><a href="#PolynomialRegression.__init__-127"><span class="linenos">127</span></a>
</span><span id="PolynomialRegression.__init__-128"><a href="#PolynomialRegression.__init__-128"><span class="linenos">128</span></a><span class="sd">        Examples:</span>
</span><span id="PolynomialRegression.__init__-129"><a href="#PolynomialRegression.__init__-129"><span class="linenos">129</span></a>
</span><span id="PolynomialRegression.__init__-130"><a href="#PolynomialRegression.__init__-130"><span class="linenos">130</span></a><span class="sd">        ```python</span>
</span><span id="PolynomialRegression.__init__-131"><a href="#PolynomialRegression.__init__-131"><span class="linenos">131</span></a><span class="sd">        degree = 2</span>
</span><span id="PolynomialRegression.__init__-132"><a href="#PolynomialRegression.__init__-132"><span class="linenos">132</span></a><span class="sd">        # Generate polynomial features of degree 1 and 2 for all the features</span>
</span><span id="PolynomialRegression.__init__-133"><a href="#PolynomialRegression.__init__-133"><span class="linenos">133</span></a>
</span><span id="PolynomialRegression.__init__-134"><a href="#PolynomialRegression.__init__-134"><span class="linenos">134</span></a><span class="sd">        degree = [2, 3, 6]</span>
</span><span id="PolynomialRegression.__init__-135"><a href="#PolynomialRegression.__init__-135"><span class="linenos">135</span></a><span class="sd">        # Generate polynomial features of degree 2, 3 and 6 for all the features</span>
</span><span id="PolynomialRegression.__init__-136"><a href="#PolynomialRegression.__init__-136"><span class="linenos">136</span></a>
</span><span id="PolynomialRegression.__init__-137"><a href="#PolynomialRegression.__init__-137"><span class="linenos">137</span></a><span class="sd">        degree = {0: [2, 3, 6], 1: 2}</span>
</span><span id="PolynomialRegression.__init__-138"><a href="#PolynomialRegression.__init__-138"><span class="linenos">138</span></a><span class="sd">        # Generate polynomial features of degree 2, 3 and 6 for the first feature</span>
</span><span id="PolynomialRegression.__init__-139"><a href="#PolynomialRegression.__init__-139"><span class="linenos">139</span></a><span class="sd">        # Generate polynomial features of degree 1 and 2 for the second feature</span>
</span><span id="PolynomialRegression.__init__-140"><a href="#PolynomialRegression.__init__-140"><span class="linenos">140</span></a><span class="sd">        ```</span>
</span><span id="PolynomialRegression.__init__-141"><a href="#PolynomialRegression.__init__-141"><span class="linenos">141</span></a>
</span><span id="PolynomialRegression.__init__-142"><a href="#PolynomialRegression.__init__-142"><span class="linenos">142</span></a><span class="sd">        ---</span>
</span><span id="PolynomialRegression.__init__-143"><a href="#PolynomialRegression.__init__-143"><span class="linenos">143</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="PolynomialRegression.__init__-144"><a href="#PolynomialRegression.__init__-144"><span class="linenos">144</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="PolynomialRegression.__init__-145"><a href="#PolynomialRegression.__init__-145"><span class="linenos">145</span></a>            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-146"><a href="#PolynomialRegression.__init__-146"><span class="linenos">146</span></a>            <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-147"><a href="#PolynomialRegression.__init__-147"><span class="linenos">147</span></a>            <span class="n">lambda_</span><span class="o">=</span><span class="n">lambda_</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-148"><a href="#PolynomialRegression.__init__-148"><span class="linenos">148</span></a>            <span class="n">x_scalar</span><span class="o">=</span><span class="n">x_scalar</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-149"><a href="#PolynomialRegression.__init__-149"><span class="linenos">149</span></a>            <span class="n">y_scalar</span><span class="o">=</span><span class="n">y_scalar</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-150"><a href="#PolynomialRegression.__init__-150"><span class="linenos">150</span></a>            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-151"><a href="#PolynomialRegression.__init__-151"><span class="linenos">151</span></a>            <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
</span><span id="PolynomialRegression.__init__-152"><a href="#PolynomialRegression.__init__-152"><span class="linenos">152</span></a>        <span class="p">)</span>
</span><span id="PolynomialRegression.__init__-153"><a href="#PolynomialRegression.__init__-153"><span class="linenos">153</span></a>
</span><span id="PolynomialRegression.__init__-154"><a href="#PolynomialRegression.__init__-154"><span class="linenos">154</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_degree</span> <span class="o">=</span> <span class="n">degree</span>
</span><span id="PolynomialRegression.__init__-155"><a href="#PolynomialRegression.__init__-155"><span class="linenos">155</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_polynomial_features</span><span class="p">:</span> <span class="n">PolynomialFeatures</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


            <div class="docstring"><h2 id="parameters">Parameters</h2>

<p><code>learning_rate</code> : np.float64, optional</p>

<ul>
<li>The learning rate, by default 0.001</li>
<li>The learning rate determines how much the weights are updated at each iteration</li>
<li>A low learning rate will take longer to converge, but a high learning rate may overshoot the optimal solution</li>
</ul>

<p><code>n_iterations</code> : int, optional</p>

<ul>
<li>The number of iterations, by default 1000</li>
<li>The number of iterations determines how many times the weights are updated</li>
<li>A higher number of iterations will take longer to converge, but a lower number of iterations may not be enough to converge</li>
</ul>

<p><code>degree</code> : Union[int, List[int], Dict[int, Union[int, List[int]]]], optional</p>

<ul>
<li>The degree of the polynomial, by default 2</li>
<li>It can be a single integer, a list of integers or a dictionary of integers and lists of integers</li>
<li>If it is a single integer, then the polynomial features of all the features of the input array will be generated with the given degree from 1 to the given degree</li>
<li>If it is a list of integers, then the polynomial features of all the features of the input array will be generated with the given degrees</li>
<li>If it is a dictionary of integers and lists of integers, then for each key-value pair in the dictionary, the polynomial features of the features at the key index of the input array will be generated with the given degrees in the list</li>
</ul>

<p><code>lambda_</code> : np.float64, optional</p>

<ul>
<li>The regularization parameter, by default 0</li>
<li>The regularization parameter helps prevent overfitting by penalizing large weights</li>
<li>A higher regularization parameter will penalize large weights more, but a lower regularization parameter may not be enough to prevent overfitting</li>
</ul>

<p><code>x_scalar</code> : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</p>

<ul>
<li>The feature engineering for the input data, by default None</li>
<li>If a list is provided, the feature engineering will be applied in the order provided</li>
<li>If a single feature engineering is provided, it will be applied to all input data</li>
</ul>

<p><code>y_scalar</code> : Union[IFeatureEngineering, List[IFeatureEngineering]], optional</p>

<ul>
<li>The feature engineering for the output data, by default None</li>
<li>If a list is provided, the feature engineering will be applied in the order provided</li>
<li>If a single feature engineering is provided, it will be applied to all output data</li>
</ul>

<p><code>debug</code> : bool, optional</p>

<ul>
<li>Whether to print debug messages, by default True</li>
<li>Debug messages include the cost at each iteration</li>
</ul>

<p><code>copy_x</code> : bool, optional</p>

<ul>
<li>Whether to copy the input array, by default True</li>
<li>If False, the input array will be overwritten</li>
</ul>

<h2 id="degree">Degree</h2>

<p>Examples:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Generate polynomial features of degree 1 and 2 for all the features</span>

<span class="n">degree</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="c1"># Generate polynomial features of degree 2, 3 and 6 for all the features</span>

<span class="n">degree</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="c1"># Generate polynomial features of degree 2, 3 and 6 for the first feature</span>
<span class="c1"># Generate polynomial features of degree 1 and 2 for the second feature</span>
</code></pre>
</div>

<hr />
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#LinearRegression">LinearRegression</a></dt>
                                <dd id="PolynomialRegression.fit" class="function"><a href="#LinearRegression.fit">fit</a></dd>
                <dd id="PolynomialRegression.predict" class="function"><a href="#LinearRegression.predict">predict</a></dd>
                <dd id="PolynomialRegression.score" class="function"><a href="#LinearRegression.score">score</a></dd>

            </div>
            <div><dt>learnML.interfaces.iregression.IRegression</dt>
                                <dd id="PolynomialRegression.get_cost_history" class="function">get_cost_history</dd>
                <dd id="PolynomialRegression.get_parameter_history" class="function">get_parameter_history</dd>
                <dd id="PolynomialRegression.get_weights" class="function">get_weights</dd>
                <dd id="PolynomialRegression.get_intercept" class="function">get_intercept</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>